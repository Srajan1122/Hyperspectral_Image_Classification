{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_PAVIA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srajan1122/Hyperspectral_Image_Classification/blob/srajan/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Nc85IUnQUS-",
        "colab_type": "code",
        "outputId": "a9ee7c3f-8231-40be-8499-49f78e6b925a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXpp9_cwKqz1",
        "colab_type": "text"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVxnzfWvKN-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder \n",
        "from sklearn import preprocessing\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Flatten, Dropout, LSTM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erOp3hTTKuzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_dataset = io.loadmat('/content/drive/My Drive/Srajan/Internship/SEM4-LeadingindiaAI/Tasks/Datasets/PaviaC/Pavia.mat')\n",
        "for key, value in loaded_dataset.items():\n",
        "  if isinstance(value, type(np.array([1]))):\n",
        "    image = loaded_dataset[key]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjbphR_nK5O8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ground_truth_1 = io.loadmat('/content/drive/My Drive/Srajan/Internship/SEM4-LeadingindiaAI/Tasks/Datasets/PaviaC/Pavia_gt.mat')\n",
        "for key, value in ground_truth_1.items():\n",
        "  if isinstance(value, type(np.array([1]))):\n",
        "    ground_truth = ground_truth_1[key]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYIFKIPmLCFV",
        "colab_type": "text"
      },
      "source": [
        "## Resizing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnRRsjn8K_zG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_with_gt = np.dstack((image, ground_truth))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2hhElWJLF9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_output = image_with_gt.reshape(ground_truth.size, image.shape[2]+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKGD0bRxLJff",
        "colab_type": "text"
      },
      "source": [
        "## Data Visualization in pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AWkTHdDLOwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.DataFrame(final_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ctUP_zKLUpJ",
        "colab_type": "code",
        "outputId": "1a09f79f-eb52-4eb4-b409-f7ca8b9e7b41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "      <th>101</th>\n",
              "      <th>102</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>854</td>\n",
              "      <td>601</td>\n",
              "      <td>350</td>\n",
              "      <td>266</td>\n",
              "      <td>138</td>\n",
              "      <td>118</td>\n",
              "      <td>178</td>\n",
              "      <td>194</td>\n",
              "      <td>257</td>\n",
              "      <td>269</td>\n",
              "      <td>239</td>\n",
              "      <td>243</td>\n",
              "      <td>220</td>\n",
              "      <td>191</td>\n",
              "      <td>173</td>\n",
              "      <td>150</td>\n",
              "      <td>125</td>\n",
              "      <td>131</td>\n",
              "      <td>137</td>\n",
              "      <td>172</td>\n",
              "      <td>195</td>\n",
              "      <td>218</td>\n",
              "      <td>255</td>\n",
              "      <td>291</td>\n",
              "      <td>320</td>\n",
              "      <td>346</td>\n",
              "      <td>347</td>\n",
              "      <td>368</td>\n",
              "      <td>404</td>\n",
              "      <td>428</td>\n",
              "      <td>429</td>\n",
              "      <td>416</td>\n",
              "      <td>394</td>\n",
              "      <td>368</td>\n",
              "      <td>357</td>\n",
              "      <td>361</td>\n",
              "      <td>369</td>\n",
              "      <td>368</td>\n",
              "      <td>351</td>\n",
              "      <td>328</td>\n",
              "      <td>...</td>\n",
              "      <td>219</td>\n",
              "      <td>239</td>\n",
              "      <td>289</td>\n",
              "      <td>366</td>\n",
              "      <td>482</td>\n",
              "      <td>632</td>\n",
              "      <td>814</td>\n",
              "      <td>1005</td>\n",
              "      <td>1225</td>\n",
              "      <td>1464</td>\n",
              "      <td>1732</td>\n",
              "      <td>2044</td>\n",
              "      <td>2383</td>\n",
              "      <td>2716</td>\n",
              "      <td>2985</td>\n",
              "      <td>3203</td>\n",
              "      <td>3385</td>\n",
              "      <td>3538</td>\n",
              "      <td>3667</td>\n",
              "      <td>3696</td>\n",
              "      <td>3548</td>\n",
              "      <td>3608</td>\n",
              "      <td>3744</td>\n",
              "      <td>3792</td>\n",
              "      <td>3802</td>\n",
              "      <td>3815</td>\n",
              "      <td>3836</td>\n",
              "      <td>3827</td>\n",
              "      <td>3765</td>\n",
              "      <td>3752</td>\n",
              "      <td>3759</td>\n",
              "      <td>3773</td>\n",
              "      <td>3779</td>\n",
              "      <td>3752</td>\n",
              "      <td>3690</td>\n",
              "      <td>3671</td>\n",
              "      <td>3664</td>\n",
              "      <td>3636</td>\n",
              "      <td>3643</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>527</td>\n",
              "      <td>642</td>\n",
              "      <td>575</td>\n",
              "      <td>294</td>\n",
              "      <td>123</td>\n",
              "      <td>168</td>\n",
              "      <td>207</td>\n",
              "      <td>154</td>\n",
              "      <td>209</td>\n",
              "      <td>299</td>\n",
              "      <td>299</td>\n",
              "      <td>278</td>\n",
              "      <td>235</td>\n",
              "      <td>181</td>\n",
              "      <td>181</td>\n",
              "      <td>236</td>\n",
              "      <td>256</td>\n",
              "      <td>253</td>\n",
              "      <td>225</td>\n",
              "      <td>202</td>\n",
              "      <td>221</td>\n",
              "      <td>256</td>\n",
              "      <td>321</td>\n",
              "      <td>358</td>\n",
              "      <td>385</td>\n",
              "      <td>429</td>\n",
              "      <td>492</td>\n",
              "      <td>533</td>\n",
              "      <td>554</td>\n",
              "      <td>553</td>\n",
              "      <td>557</td>\n",
              "      <td>580</td>\n",
              "      <td>561</td>\n",
              "      <td>522</td>\n",
              "      <td>525</td>\n",
              "      <td>513</td>\n",
              "      <td>474</td>\n",
              "      <td>435</td>\n",
              "      <td>412</td>\n",
              "      <td>401</td>\n",
              "      <td>...</td>\n",
              "      <td>254</td>\n",
              "      <td>305</td>\n",
              "      <td>349</td>\n",
              "      <td>401</td>\n",
              "      <td>508</td>\n",
              "      <td>681</td>\n",
              "      <td>888</td>\n",
              "      <td>1076</td>\n",
              "      <td>1297</td>\n",
              "      <td>1577</td>\n",
              "      <td>1855</td>\n",
              "      <td>2117</td>\n",
              "      <td>2456</td>\n",
              "      <td>2772</td>\n",
              "      <td>3002</td>\n",
              "      <td>3205</td>\n",
              "      <td>3388</td>\n",
              "      <td>3526</td>\n",
              "      <td>3629</td>\n",
              "      <td>3665</td>\n",
              "      <td>3586</td>\n",
              "      <td>3653</td>\n",
              "      <td>3747</td>\n",
              "      <td>3813</td>\n",
              "      <td>3831</td>\n",
              "      <td>3829</td>\n",
              "      <td>3841</td>\n",
              "      <td>3885</td>\n",
              "      <td>3916</td>\n",
              "      <td>3907</td>\n",
              "      <td>3873</td>\n",
              "      <td>3902</td>\n",
              "      <td>3921</td>\n",
              "      <td>3861</td>\n",
              "      <td>3854</td>\n",
              "      <td>3882</td>\n",
              "      <td>3834</td>\n",
              "      <td>3725</td>\n",
              "      <td>3768</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>374</td>\n",
              "      <td>322</td>\n",
              "      <td>179</td>\n",
              "      <td>87</td>\n",
              "      <td>169</td>\n",
              "      <td>268</td>\n",
              "      <td>360</td>\n",
              "      <td>339</td>\n",
              "      <td>286</td>\n",
              "      <td>309</td>\n",
              "      <td>340</td>\n",
              "      <td>305</td>\n",
              "      <td>206</td>\n",
              "      <td>202</td>\n",
              "      <td>269</td>\n",
              "      <td>256</td>\n",
              "      <td>246</td>\n",
              "      <td>226</td>\n",
              "      <td>218</td>\n",
              "      <td>275</td>\n",
              "      <td>318</td>\n",
              "      <td>356</td>\n",
              "      <td>395</td>\n",
              "      <td>425</td>\n",
              "      <td>461</td>\n",
              "      <td>520</td>\n",
              "      <td>587</td>\n",
              "      <td>623</td>\n",
              "      <td>621</td>\n",
              "      <td>617</td>\n",
              "      <td>636</td>\n",
              "      <td>657</td>\n",
              "      <td>665</td>\n",
              "      <td>670</td>\n",
              "      <td>645</td>\n",
              "      <td>610</td>\n",
              "      <td>576</td>\n",
              "      <td>547</td>\n",
              "      <td>532</td>\n",
              "      <td>523</td>\n",
              "      <td>...</td>\n",
              "      <td>369</td>\n",
              "      <td>418</td>\n",
              "      <td>484</td>\n",
              "      <td>590</td>\n",
              "      <td>754</td>\n",
              "      <td>969</td>\n",
              "      <td>1201</td>\n",
              "      <td>1460</td>\n",
              "      <td>1716</td>\n",
              "      <td>2002</td>\n",
              "      <td>2319</td>\n",
              "      <td>2690</td>\n",
              "      <td>3055</td>\n",
              "      <td>3368</td>\n",
              "      <td>3666</td>\n",
              "      <td>3901</td>\n",
              "      <td>4082</td>\n",
              "      <td>4258</td>\n",
              "      <td>4372</td>\n",
              "      <td>4392</td>\n",
              "      <td>4231</td>\n",
              "      <td>4256</td>\n",
              "      <td>4419</td>\n",
              "      <td>4495</td>\n",
              "      <td>4501</td>\n",
              "      <td>4472</td>\n",
              "      <td>4486</td>\n",
              "      <td>4499</td>\n",
              "      <td>4453</td>\n",
              "      <td>4404</td>\n",
              "      <td>4443</td>\n",
              "      <td>4472</td>\n",
              "      <td>4428</td>\n",
              "      <td>4353</td>\n",
              "      <td>4306</td>\n",
              "      <td>4284</td>\n",
              "      <td>4318</td>\n",
              "      <td>4311</td>\n",
              "      <td>4321</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>706</td>\n",
              "      <td>520</td>\n",
              "      <td>560</td>\n",
              "      <td>572</td>\n",
              "      <td>425</td>\n",
              "      <td>243</td>\n",
              "      <td>271</td>\n",
              "      <td>272</td>\n",
              "      <td>258</td>\n",
              "      <td>276</td>\n",
              "      <td>299</td>\n",
              "      <td>313</td>\n",
              "      <td>320</td>\n",
              "      <td>336</td>\n",
              "      <td>299</td>\n",
              "      <td>274</td>\n",
              "      <td>322</td>\n",
              "      <td>361</td>\n",
              "      <td>358</td>\n",
              "      <td>377</td>\n",
              "      <td>387</td>\n",
              "      <td>396</td>\n",
              "      <td>415</td>\n",
              "      <td>486</td>\n",
              "      <td>564</td>\n",
              "      <td>624</td>\n",
              "      <td>668</td>\n",
              "      <td>680</td>\n",
              "      <td>696</td>\n",
              "      <td>728</td>\n",
              "      <td>753</td>\n",
              "      <td>721</td>\n",
              "      <td>700</td>\n",
              "      <td>713</td>\n",
              "      <td>690</td>\n",
              "      <td>642</td>\n",
              "      <td>592</td>\n",
              "      <td>560</td>\n",
              "      <td>542</td>\n",
              "      <td>547</td>\n",
              "      <td>...</td>\n",
              "      <td>384</td>\n",
              "      <td>418</td>\n",
              "      <td>481</td>\n",
              "      <td>568</td>\n",
              "      <td>693</td>\n",
              "      <td>865</td>\n",
              "      <td>1057</td>\n",
              "      <td>1259</td>\n",
              "      <td>1478</td>\n",
              "      <td>1714</td>\n",
              "      <td>1971</td>\n",
              "      <td>2261</td>\n",
              "      <td>2548</td>\n",
              "      <td>2818</td>\n",
              "      <td>3135</td>\n",
              "      <td>3377</td>\n",
              "      <td>3564</td>\n",
              "      <td>3731</td>\n",
              "      <td>3820</td>\n",
              "      <td>3814</td>\n",
              "      <td>3710</td>\n",
              "      <td>3770</td>\n",
              "      <td>3904</td>\n",
              "      <td>3976</td>\n",
              "      <td>3967</td>\n",
              "      <td>3973</td>\n",
              "      <td>4032</td>\n",
              "      <td>4078</td>\n",
              "      <td>4040</td>\n",
              "      <td>3992</td>\n",
              "      <td>3972</td>\n",
              "      <td>4006</td>\n",
              "      <td>4032</td>\n",
              "      <td>3975</td>\n",
              "      <td>3946</td>\n",
              "      <td>3954</td>\n",
              "      <td>3944</td>\n",
              "      <td>3936</td>\n",
              "      <td>3939</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1120</td>\n",
              "      <td>1027</td>\n",
              "      <td>592</td>\n",
              "      <td>414</td>\n",
              "      <td>407</td>\n",
              "      <td>463</td>\n",
              "      <td>417</td>\n",
              "      <td>365</td>\n",
              "      <td>332</td>\n",
              "      <td>334</td>\n",
              "      <td>356</td>\n",
              "      <td>327</td>\n",
              "      <td>296</td>\n",
              "      <td>325</td>\n",
              "      <td>346</td>\n",
              "      <td>308</td>\n",
              "      <td>262</td>\n",
              "      <td>262</td>\n",
              "      <td>292</td>\n",
              "      <td>312</td>\n",
              "      <td>335</td>\n",
              "      <td>394</td>\n",
              "      <td>430</td>\n",
              "      <td>450</td>\n",
              "      <td>491</td>\n",
              "      <td>570</td>\n",
              "      <td>611</td>\n",
              "      <td>616</td>\n",
              "      <td>631</td>\n",
              "      <td>659</td>\n",
              "      <td>686</td>\n",
              "      <td>705</td>\n",
              "      <td>691</td>\n",
              "      <td>667</td>\n",
              "      <td>624</td>\n",
              "      <td>584</td>\n",
              "      <td>570</td>\n",
              "      <td>549</td>\n",
              "      <td>530</td>\n",
              "      <td>517</td>\n",
              "      <td>...</td>\n",
              "      <td>349</td>\n",
              "      <td>365</td>\n",
              "      <td>398</td>\n",
              "      <td>505</td>\n",
              "      <td>677</td>\n",
              "      <td>877</td>\n",
              "      <td>1116</td>\n",
              "      <td>1410</td>\n",
              "      <td>1717</td>\n",
              "      <td>2015</td>\n",
              "      <td>2339</td>\n",
              "      <td>2670</td>\n",
              "      <td>3028</td>\n",
              "      <td>3415</td>\n",
              "      <td>3713</td>\n",
              "      <td>3928</td>\n",
              "      <td>4131</td>\n",
              "      <td>4296</td>\n",
              "      <td>4445</td>\n",
              "      <td>4508</td>\n",
              "      <td>4305</td>\n",
              "      <td>4232</td>\n",
              "      <td>4422</td>\n",
              "      <td>4554</td>\n",
              "      <td>4550</td>\n",
              "      <td>4524</td>\n",
              "      <td>4532</td>\n",
              "      <td>4578</td>\n",
              "      <td>4584</td>\n",
              "      <td>4555</td>\n",
              "      <td>4502</td>\n",
              "      <td>4485</td>\n",
              "      <td>4479</td>\n",
              "      <td>4445</td>\n",
              "      <td>4364</td>\n",
              "      <td>4290</td>\n",
              "      <td>4268</td>\n",
              "      <td>4235</td>\n",
              "      <td>4272</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 103 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    0     1    2    3    4    5    6    ...   96    97    98    99    100   101  102\n",
              "0   854   601  350  266  138  118  178  ...  3752  3690  3671  3664  3636  3643    0\n",
              "1   527   642  575  294  123  168  207  ...  3861  3854  3882  3834  3725  3768    0\n",
              "2   374   322  179   87  169  268  360  ...  4353  4306  4284  4318  4311  4321    0\n",
              "3   706   520  560  572  425  243  271  ...  3975  3946  3954  3944  3936  3939    0\n",
              "4  1120  1027  592  414  407  463  417  ...  4445  4364  4290  4268  4235  4272    0\n",
              "\n",
              "[5 rows x 103 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLWjsfqaLZs0",
        "colab_type": "text"
      },
      "source": [
        "## Droping the rows if ground truth value is zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlyctDjwLYkb",
        "colab_type": "code",
        "outputId": "05f01bca-ba3c-43c7-dfdf-6054833478c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Percentage of column which will be droped\",(data.size - data[data.iloc[:, -1] == 0].size)/data.size,\"%\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of column which will be droped 0.1890561992751774 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tJ0vUTCLhZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data[data.iloc[:, -1] != 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE5Gc8BTLiAN",
        "colab_type": "text"
      },
      "source": [
        "# Spliting the data into feature and target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ4dCIbILrwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHPv8SimL1Iu",
        "colab_type": "text"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aMaE8k8L0VV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.feature_selection import SelectKBest\n",
        "# from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
        "\n",
        "# X = SelectKBest(f_classif, k=int((image.shape[2]+1)*0.75)).fit_transform(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCO0t_-J0G6J",
        "colab_type": "text"
      },
      "source": [
        "# Feature Extraction \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIjIpV160KKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA \n",
        "\n",
        "pca = PCA(n_components = int((image.shape[2]+1)*0.80))\n",
        "X = pca.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fijfR_5DL9IK",
        "colab_type": "text"
      },
      "source": [
        "# OneHotEncoding in target column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QoUCdAwMBAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# onehotencoder = OneHotEncoder() \n",
        "# y = onehotencoder.fit_transform(np.array(y).reshape(-1,1)).toarray() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlNWTtSVMEjl",
        "colab_type": "text"
      },
      "source": [
        "# Standardizing the feature columna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPshPrqEMJvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = preprocessing.scale(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRtV7aDDqr5a",
        "colab_type": "text"
      },
      "source": [
        "# Spliting the data into training and testing set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DattLTVzqr5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.90, random_state=1)#0.25 0.15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OngDFGdDdPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number = int(X_test.shape[0]/2)\n",
        "\n",
        "xx_test = X_test[:number, :]\n",
        "xx_val = X_test[number:, :]\n",
        "\n",
        "if len(y_test.shape) > 1:\n",
        "  loss = tensorflow.keras.losses.categorical_crossentropy\n",
        "  metrics=['accuracy']\n",
        "  yy_test = y_test[:number, :]\n",
        "  yy_val = y_test[number:, :]\n",
        "else:\n",
        "  loss = tensorflow.keras.losses.sparse_categorical_crossentropy\n",
        "  metrics=['sparse_categorical_accuracy']\n",
        "  y_test = [x - 1 for x in y_test]\n",
        "  y_train = [x - 1 for x in y_train]\n",
        "  yy_test = y_test[:number]\n",
        "  yy_val = y_test[number:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M33_KnJNu7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "feature = X.shape[1]\n",
        "\n",
        "# if K.image_data_format() == 'channels_first':\n",
        "#     X_train = X_train.reshape(X_train.shape[0], 1, feature)\n",
        "#     xx_test = xx_test.reshape(xx_test.shape[0], 1, feature)\n",
        "#     xx_val = xx_val.reshape(xx_val.shape[0], 1, feature)\n",
        "#     input_shape = (1, feature)\n",
        "# else:\n",
        "#     X_train = X_train.reshape(X_train.shape[0], feature, 1)\n",
        "#     xx_test = xx_test.reshape(xx_test.shape[0], feature, 1)\n",
        "#     xx_val = xx_val.reshape(xx_val.shape[0], feature, 1)\n",
        "#     input_shape = (feature, 1)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, feature)\n",
        "xx_test = xx_test.reshape(xx_test.shape[0], 1, feature)\n",
        "xx_val = xx_val.reshape(xx_val.shape[0], 1, feature)\n",
        "input_shape = (1, feature)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQLkUnZ_YsYO",
        "colab_type": "text"
      },
      "source": [
        "# Genetic Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-9MDtAugFbk",
        "colab_type": "code",
        "outputId": "b4d4c246-e87c-4ebb-cc51-034a28d07715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install pyeasyga"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyeasyga in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pyeasyga) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bAr5dYIYrxF",
        "colab_type": "code",
        "outputId": "9de89314-2f48-4457-9ea6-c3562ae92dcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from pyeasyga import pyeasyga\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import keras\n",
        "import time\n",
        "\n",
        "count = 1\n",
        "\n",
        "def initilialize_population():\n",
        "    filter_1 = list(x for x in range(70, 120, 5))\n",
        "\n",
        "    population = [filter_1]\n",
        "\n",
        "    return list(population)\n",
        "\n",
        "def create_individual(data):\n",
        "  choice = []\n",
        "  for i in range(len(data)):\n",
        "    choice.append(random.choice(list(range(len(data[i])))))\n",
        "  return choice\n",
        "\n",
        "def fitness_function(individual, data):\n",
        "  global count\n",
        "  print('Individual no', count)\n",
        "  count += 1\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(data[0][individual[0]], input_shape=input_shape, return_sequences=False))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Dense(9, activation='softmax'))\n",
        "\n",
        "  model.compile(loss=loss,\n",
        "                optimizer='adam',\n",
        "                metrics=metrics)\n",
        "\n",
        "  model.fit(X_train, np.array(y_train),\n",
        "            batch_size=128,\n",
        "            epochs=20,\n",
        "            verbose=1,\n",
        "            validation_data=(xx_val,np.array(yy_val)))\n",
        "\n",
        "\n",
        "  score = model.evaluate(xx_test, np.array(yy_test), verbose=1)[1]\n",
        "  # prediction = model.predict(X_test)\n",
        "  # score = accuracy_score(y_test, prediction)\n",
        "  print('Score is', score)\n",
        "  return score\n",
        "  \n",
        "data = initilialize_population()\n",
        "ga = pyeasyga.GeneticAlgorithm(seed_data=data,\n",
        "                               population_size=2,\n",
        "                               generations=2,\n",
        "                               crossover_probability=0.8,\n",
        "                               mutation_probability=0.4,\n",
        "                               elitism=True,\n",
        "                               maximise_fitness=True)\n",
        "ga.create_individual = create_individual\n",
        "ga.fitness_function = fitness_function\n",
        "\n",
        "start = time.time()\n",
        "ga.run()\n",
        "end = time.time()\n",
        "print('Time taken ------>', end-start)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Individual no 1\n",
            "Epoch 1/20\n",
            "116/116 [==============================] - 2s 21ms/step - loss: 1.7654 - sparse_categorical_accuracy: 0.5797 - val_loss: 1.1822 - val_sparse_categorical_accuracy: 0.8303\n",
            "Epoch 2/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.7377 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.4132 - val_sparse_categorical_accuracy: 0.9348\n",
            "Epoch 3/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.2918 - sparse_categorical_accuracy: 0.9524 - val_loss: 0.1958 - val_sparse_categorical_accuracy: 0.9659\n",
            "Epoch 4/20\n",
            "116/116 [==============================] - 2s 18ms/step - loss: 0.1588 - sparse_categorical_accuracy: 0.9721 - val_loss: 0.1250 - val_sparse_categorical_accuracy: 0.9738\n",
            "Epoch 5/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.1066 - sparse_categorical_accuracy: 0.9801 - val_loss: 0.0954 - val_sparse_categorical_accuracy: 0.9768\n",
            "Epoch 6/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0811 - sparse_categorical_accuracy: 0.9843 - val_loss: 0.0801 - val_sparse_categorical_accuracy: 0.9790\n",
            "Epoch 7/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0666 - sparse_categorical_accuracy: 0.9853 - val_loss: 0.0710 - val_sparse_categorical_accuracy: 0.9804\n",
            "Epoch 8/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0561 - sparse_categorical_accuracy: 0.9880 - val_loss: 0.0656 - val_sparse_categorical_accuracy: 0.9806\n",
            "Epoch 9/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0486 - sparse_categorical_accuracy: 0.9894 - val_loss: 0.0617 - val_sparse_categorical_accuracy: 0.9812\n",
            "Epoch 10/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0424 - sparse_categorical_accuracy: 0.9902 - val_loss: 0.0589 - val_sparse_categorical_accuracy: 0.9817\n",
            "Epoch 11/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0378 - sparse_categorical_accuracy: 0.9916 - val_loss: 0.0566 - val_sparse_categorical_accuracy: 0.9820\n",
            "Epoch 12/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0339 - sparse_categorical_accuracy: 0.9933 - val_loss: 0.0552 - val_sparse_categorical_accuracy: 0.9823\n",
            "Epoch 13/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0308 - sparse_categorical_accuracy: 0.9935 - val_loss: 0.0536 - val_sparse_categorical_accuracy: 0.9829\n",
            "Epoch 14/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0273 - sparse_categorical_accuracy: 0.9945 - val_loss: 0.0529 - val_sparse_categorical_accuracy: 0.9828\n",
            "Epoch 15/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0249 - sparse_categorical_accuracy: 0.9944 - val_loss: 0.0519 - val_sparse_categorical_accuracy: 0.9832\n",
            "Epoch 16/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0226 - sparse_categorical_accuracy: 0.9956 - val_loss: 0.0516 - val_sparse_categorical_accuracy: 0.9831\n",
            "Epoch 17/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0194 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0511 - val_sparse_categorical_accuracy: 0.9837\n",
            "Epoch 18/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0185 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0509 - val_sparse_categorical_accuracy: 0.9834\n",
            "Epoch 19/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0168 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0507 - val_sparse_categorical_accuracy: 0.9837\n",
            "Epoch 20/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0151 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0503 - val_sparse_categorical_accuracy: 0.9837\n",
            "2084/2084 [==============================] - 6s 3ms/step - loss: 0.0489 - sparse_categorical_accuracy: 0.9842\n",
            "Score is 0.9842352867126465\n",
            "Individual no 2\n",
            "Epoch 1/20\n",
            "116/116 [==============================] - 2s 20ms/step - loss: 1.5897 - sparse_categorical_accuracy: 0.6761 - val_loss: 0.8876 - val_sparse_categorical_accuracy: 0.8819\n",
            "Epoch 2/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.5063 - sparse_categorical_accuracy: 0.9264 - val_loss: 0.2735 - val_sparse_categorical_accuracy: 0.9522\n",
            "Epoch 3/20\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.1962 - sparse_categorical_accuracy: 0.9654 - val_loss: 0.1445 - val_sparse_categorical_accuracy: 0.9710\n",
            "Epoch 4/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.1155 - sparse_categorical_accuracy: 0.9775 - val_loss: 0.1020 - val_sparse_categorical_accuracy: 0.9759\n",
            "Epoch 5/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0822 - sparse_categorical_accuracy: 0.9828 - val_loss: 0.0827 - val_sparse_categorical_accuracy: 0.9786\n",
            "Epoch 6/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0646 - sparse_categorical_accuracy: 0.9860 - val_loss: 0.0717 - val_sparse_categorical_accuracy: 0.9800\n",
            "Epoch 7/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0526 - sparse_categorical_accuracy: 0.9891 - val_loss: 0.0652 - val_sparse_categorical_accuracy: 0.9813\n",
            "Epoch 8/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0448 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0609 - val_sparse_categorical_accuracy: 0.9817\n",
            "Epoch 9/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0371 - sparse_categorical_accuracy: 0.9928 - val_loss: 0.0579 - val_sparse_categorical_accuracy: 0.9824\n",
            "Epoch 10/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0338 - sparse_categorical_accuracy: 0.9929 - val_loss: 0.0557 - val_sparse_categorical_accuracy: 0.9827\n",
            "Epoch 11/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0288 - sparse_categorical_accuracy: 0.9940 - val_loss: 0.0544 - val_sparse_categorical_accuracy: 0.9830\n",
            "Epoch 12/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0254 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.0533 - val_sparse_categorical_accuracy: 0.9831\n",
            "Epoch 13/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0219 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.0526 - val_sparse_categorical_accuracy: 0.9833\n",
            "Epoch 14/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0192 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.0520 - val_sparse_categorical_accuracy: 0.9834\n",
            "Epoch 15/20\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.0166 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0518 - val_sparse_categorical_accuracy: 0.9835\n",
            "Epoch 16/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0148 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0514 - val_sparse_categorical_accuracy: 0.9838\n",
            "Epoch 17/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0134 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0509 - val_sparse_categorical_accuracy: 0.9840\n",
            "Epoch 18/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0117 - sparse_categorical_accuracy: 0.9988 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9837\n",
            "Epoch 19/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0099 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.0511 - val_sparse_categorical_accuracy: 0.9840\n",
            "Epoch 20/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0087 - sparse_categorical_accuracy: 0.9991 - val_loss: 0.0510 - val_sparse_categorical_accuracy: 0.9842\n",
            "2084/2084 [==============================] - 6s 3ms/step - loss: 0.0507 - sparse_categorical_accuracy: 0.9840\n",
            "Score is 0.9839802980422974\n",
            "Individual no 3\n",
            "Epoch 1/20\n",
            "116/116 [==============================] - 3s 23ms/step - loss: 1.7530 - sparse_categorical_accuracy: 0.5843 - val_loss: 1.1696 - val_sparse_categorical_accuracy: 0.8220\n",
            "Epoch 2/20\n",
            "116/116 [==============================] - 2s 19ms/step - loss: 0.7291 - sparse_categorical_accuracy: 0.8803 - val_loss: 0.4054 - val_sparse_categorical_accuracy: 0.9355\n",
            "Epoch 3/20\n",
            "116/116 [==============================] - 2s 19ms/step - loss: 0.2845 - sparse_categorical_accuracy: 0.9541 - val_loss: 0.1935 - val_sparse_categorical_accuracy: 0.9650\n",
            "Epoch 4/20\n",
            "116/116 [==============================] - 2s 19ms/step - loss: 0.1557 - sparse_categorical_accuracy: 0.9731 - val_loss: 0.1248 - val_sparse_categorical_accuracy: 0.9738\n",
            "Epoch 5/20\n",
            "116/116 [==============================] - 2s 18ms/step - loss: 0.1067 - sparse_categorical_accuracy: 0.9793 - val_loss: 0.0956 - val_sparse_categorical_accuracy: 0.9775\n",
            "Epoch 6/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0826 - sparse_categorical_accuracy: 0.9835 - val_loss: 0.0803 - val_sparse_categorical_accuracy: 0.9794\n",
            "Epoch 7/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0677 - sparse_categorical_accuracy: 0.9854 - val_loss: 0.0709 - val_sparse_categorical_accuracy: 0.9810\n",
            "Epoch 8/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0577 - sparse_categorical_accuracy: 0.9868 - val_loss: 0.0650 - val_sparse_categorical_accuracy: 0.9817\n",
            "Epoch 9/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0491 - sparse_categorical_accuracy: 0.9895 - val_loss: 0.0611 - val_sparse_categorical_accuracy: 0.9824\n",
            "Epoch 10/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0432 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.0580 - val_sparse_categorical_accuracy: 0.9828\n",
            "Epoch 11/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0376 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.0558 - val_sparse_categorical_accuracy: 0.9832\n",
            "Epoch 12/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0340 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0543 - val_sparse_categorical_accuracy: 0.9835\n",
            "Epoch 13/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0306 - sparse_categorical_accuracy: 0.9934 - val_loss: 0.0529 - val_sparse_categorical_accuracy: 0.9836\n",
            "Epoch 14/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0272 - sparse_categorical_accuracy: 0.9933 - val_loss: 0.0518 - val_sparse_categorical_accuracy: 0.9839\n",
            "Epoch 15/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0242 - sparse_categorical_accuracy: 0.9946 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9837\n",
            "Epoch 16/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0221 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.0510 - val_sparse_categorical_accuracy: 0.9839\n",
            "Epoch 17/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0209 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0506 - val_sparse_categorical_accuracy: 0.9840\n",
            "Epoch 18/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0181 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0505 - val_sparse_categorical_accuracy: 0.9841\n",
            "Epoch 19/20\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.0172 - sparse_categorical_accuracy: 0.9970 - val_loss: 0.0500 - val_sparse_categorical_accuracy: 0.9841\n",
            "Epoch 20/20\n",
            "116/116 [==============================] - 2s 19ms/step - loss: 0.0149 - sparse_categorical_accuracy: 0.9976 - val_loss: 0.0499 - val_sparse_categorical_accuracy: 0.9843\n",
            "2084/2084 [==============================] - 6s 3ms/step - loss: 0.0486 - sparse_categorical_accuracy: 0.9840\n",
            "Score is 0.9839653372764587\n",
            "Individual no 4\n",
            "Epoch 1/20\n",
            "116/116 [==============================] - 2s 21ms/step - loss: 1.7459 - sparse_categorical_accuracy: 0.6055 - val_loss: 1.1536 - val_sparse_categorical_accuracy: 0.8304\n",
            "Epoch 2/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.7232 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.4196 - val_sparse_categorical_accuracy: 0.9223\n",
            "Epoch 3/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.3008 - sparse_categorical_accuracy: 0.9444 - val_loss: 0.2071 - val_sparse_categorical_accuracy: 0.9597\n",
            "Epoch 4/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.1666 - sparse_categorical_accuracy: 0.9703 - val_loss: 0.1323 - val_sparse_categorical_accuracy: 0.9741\n",
            "Epoch 5/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.1129 - sparse_categorical_accuracy: 0.9779 - val_loss: 0.1002 - val_sparse_categorical_accuracy: 0.9773\n",
            "Epoch 6/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0856 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.0834 - val_sparse_categorical_accuracy: 0.9792\n",
            "Epoch 7/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0698 - sparse_categorical_accuracy: 0.9847 - val_loss: 0.0737 - val_sparse_categorical_accuracy: 0.9805\n",
            "Epoch 8/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0583 - sparse_categorical_accuracy: 0.9878 - val_loss: 0.0675 - val_sparse_categorical_accuracy: 0.9810\n",
            "Epoch 9/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0504 - sparse_categorical_accuracy: 0.9878 - val_loss: 0.0629 - val_sparse_categorical_accuracy: 0.9819\n",
            "Epoch 10/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0442 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.0597 - val_sparse_categorical_accuracy: 0.9824\n",
            "Epoch 11/20\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.0386 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.0572 - val_sparse_categorical_accuracy: 0.9829\n",
            "Epoch 12/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0351 - sparse_categorical_accuracy: 0.9924 - val_loss: 0.0552 - val_sparse_categorical_accuracy: 0.9832\n",
            "Epoch 13/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0319 - sparse_categorical_accuracy: 0.9926 - val_loss: 0.0540 - val_sparse_categorical_accuracy: 0.9834\n",
            "Epoch 14/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0285 - sparse_categorical_accuracy: 0.9935 - val_loss: 0.0531 - val_sparse_categorical_accuracy: 0.9835\n",
            "Epoch 15/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0249 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0520 - val_sparse_categorical_accuracy: 0.9837\n",
            "Epoch 16/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0223 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.0519 - val_sparse_categorical_accuracy: 0.9835\n",
            "Epoch 17/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0210 - sparse_categorical_accuracy: 0.9959 - val_loss: 0.0510 - val_sparse_categorical_accuracy: 0.9839\n",
            "Epoch 18/20\n",
            "116/116 [==============================] - 2s 17ms/step - loss: 0.0188 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0507 - val_sparse_categorical_accuracy: 0.9838\n",
            "Epoch 19/20\n",
            "116/116 [==============================] - 2s 16ms/step - loss: 0.0169 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0505 - val_sparse_categorical_accuracy: 0.9839\n",
            "Epoch 20/20\n",
            "116/116 [==============================] - 2s 19ms/step - loss: 0.0154 - sparse_categorical_accuracy: 0.9972 - val_loss: 0.0502 - val_sparse_categorical_accuracy: 0.9841\n",
            "2084/2084 [==============================] - 7s 3ms/step - loss: 0.0488 - sparse_categorical_accuracy: 0.9843\n",
            "Score is 0.9843403100967407\n",
            "Time taken ------> 196.32330417633057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU62XsCXnOj4",
        "colab_type": "code",
        "outputId": "aadcea26-6abf-4b20-b94c-1a5aa3d680ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "best_parameters = ga.best_individual()[1]\n",
        "for index,i in enumerate(data):\n",
        "  print(i[best_parameters[index]])\n",
        "\n",
        "print(ga.best_individual()[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70\n",
            "0.9843403100967407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5feYcZI8Xqf",
        "colab_type": "text"
      },
      "source": [
        "# Building RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZfW_PApTWrB",
        "colab_type": "code",
        "outputId": "64ca3ccf-bd26-4329-abdd-4a6fd7570658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# design network\n",
        "model = Sequential()\n",
        "model.add(LSTM(data[0][best_parameters[0]], input_shape=input_shape, return_sequences=False))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(9, activation='softmax'))\n",
        "model.compile(loss=loss, optimizer='adam', metrics=metrics)\n",
        "model.summary()\n",
        "\n",
        "# fit network\n",
        "history = model.fit(X_train, np.array(y_train), validation_data=(xx_val, np.array(yy_val)), \n",
        "                    epochs=25,verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4 (LSTM)                (None, 70)                42840     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 70)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 9)                 639       \n",
            "=================================================================\n",
            "Total params: 43,479\n",
            "Trainable params: 43,479\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "463/463 [==============================] - 8s 17ms/step - loss: 0.9780 - sparse_categorical_accuracy: 0.7897 - val_loss: 0.2136 - val_sparse_categorical_accuracy: 0.9616\n",
            "Epoch 2/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.1339 - sparse_categorical_accuracy: 0.9717 - val_loss: 0.0863 - val_sparse_categorical_accuracy: 0.9781\n",
            "Epoch 3/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0707 - sparse_categorical_accuracy: 0.9832 - val_loss: 0.0644 - val_sparse_categorical_accuracy: 0.9817\n",
            "Epoch 4/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0501 - sparse_categorical_accuracy: 0.9871 - val_loss: 0.0563 - val_sparse_categorical_accuracy: 0.9828\n",
            "Epoch 5/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0394 - sparse_categorical_accuracy: 0.9897 - val_loss: 0.0525 - val_sparse_categorical_accuracy: 0.9833\n",
            "Epoch 6/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0313 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.0500 - val_sparse_categorical_accuracy: 0.9838\n",
            "Epoch 7/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0243 - sparse_categorical_accuracy: 0.9945 - val_loss: 0.0486 - val_sparse_categorical_accuracy: 0.9841\n",
            "Epoch 8/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0189 - sparse_categorical_accuracy: 0.9953 - val_loss: 0.0489 - val_sparse_categorical_accuracy: 0.9841\n",
            "Epoch 9/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0161 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.0491 - val_sparse_categorical_accuracy: 0.9841\n",
            "Epoch 10/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0123 - sparse_categorical_accuracy: 0.9974 - val_loss: 0.0488 - val_sparse_categorical_accuracy: 0.9841\n",
            "Epoch 11/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0121 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0496 - val_sparse_categorical_accuracy: 0.9842\n",
            "Epoch 12/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0507 - val_sparse_categorical_accuracy: 0.9843\n",
            "Epoch 13/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0501 - val_sparse_categorical_accuracy: 0.9846\n",
            "Epoch 14/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0074 - sparse_categorical_accuracy: 0.9987 - val_loss: 0.0515 - val_sparse_categorical_accuracy: 0.9846\n",
            "Epoch 15/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9996 - val_loss: 0.0517 - val_sparse_categorical_accuracy: 0.9851\n",
            "Epoch 16/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0049 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.0527 - val_sparse_categorical_accuracy: 0.9851\n",
            "Epoch 17/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0044 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.0546 - val_sparse_categorical_accuracy: 0.9847\n",
            "Epoch 18/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0035 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.0548 - val_sparse_categorical_accuracy: 0.9848\n",
            "Epoch 19/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0037 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.0567 - val_sparse_categorical_accuracy: 0.9844\n",
            "Epoch 20/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.0572 - val_sparse_categorical_accuracy: 0.9844\n",
            "Epoch 21/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.0578 - val_sparse_categorical_accuracy: 0.9844\n",
            "Epoch 22/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0026 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.0575 - val_sparse_categorical_accuracy: 0.9845\n",
            "Epoch 23/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0021 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.0592 - val_sparse_categorical_accuracy: 0.9847\n",
            "Epoch 24/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.0607 - val_sparse_categorical_accuracy: 0.9847\n",
            "Epoch 25/25\n",
            "463/463 [==============================] - 8s 16ms/step - loss: 0.0015 - sparse_categorical_accuracy: 0.9999 - val_loss: 0.0608 - val_sparse_categorical_accuracy: 0.9846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhNCqRoLyP_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cf6bd8e8-0b38-4267-8a37-89937ad9eef3"
      },
      "source": [
        "score = model.evaluate(xx_test, np.array(yy_test), verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2084/2084 [==============================] - 6s 3ms/step - loss: 0.0602 - sparse_categorical_accuracy: 0.9847\n",
            "Test loss: 0.06022864952683449\n",
            "Test accuracy: 0.9846853017807007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRjH7zIgyqZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if len(np.array(y_test).shape) == 1:\n",
        "  y_test = [x+1 for x in y_test]\n",
        "  y_train = [x+1 for x in y_train]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLzZL5wJTZg1",
        "colab_type": "code",
        "outputId": "b07b471f-7fd8-4b30-c999-2f54be16af7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "pred = X.reshape((X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "\n",
        "\n",
        "Y_pred_test = model.predict(pred)\n",
        "y_pred_test = np.argmax(Y_pred_test, axis=1)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "print(accuracy_score(y, y_pred_test)*100)\n",
        "\n",
        "#= summarize history for accuracy\n",
        "plt.plot(history.history['sparse_categorical_accuracy'])\n",
        "plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4279388735892867\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZxkZX3v8c+3qrunl9kXQWaAGQwY0BjQETWK4nUDXNCQEEW8kpsEjZqg0VwhV5Fwr4n3vozX676FiMoiwY0YEgMK5nrByLCIrM6I4PSwOMx0DdNrbb/7xznVfbqne+b00DXV0/V9vyjqrFW/UzV9fvU8zznPo4jAzMxsXwqtDsDMzA4OThhmZpaLE4aZmeXihGFmZrk4YZiZWS5OGGZmlosThhkg6cuS/kfObR+U9PJmx2Q23zhhmJlZLk4YZguIpI5Wx2ALlxOGHTTSqqC/lHSnpCFJfy/pEEn/Imm3pOslrchs/zpJd0sqSbpR0rGZdSdIui3d7+tA95T3eo2kO9J9b5L0rJwxvlrS7ZKekLRV0kVT1r8ofb1Suv6cdHmPpL+T9JCkXZJ+lC47WVL/NJ/Dy9PpiyRdLelrkp4AzpF0oqSb0/d4RNKnJHVl9n+GpOsk7ZT0mKS/knSopGFJqzLbPVvSdkmdeY7dFj4nDDvYnAG8AjgGeC3wL8BfAWtI/j3/OYCkY4ArgHen664F/klSV3ry/DbwVWAl8I/p65LuewJwCfA2YBXweeAaSYtyxDcE/GdgOfBq4E8lvT593SPTeD+ZxnQ8cEe630eB5wC/k8b0X4F6zs/kdODq9D0vA2rAe4DVwAuAlwHvSGNYAlwP/CtwGPAbwPcj4lHgRuDMzOu+BbgyIio547AFzgnDDjafjIjHImIb8H+B/4iI2yNiFPgWcEK63R8A/xwR16UnvI8CPSQn5OcDncDHI6ISEVcDt2Te41zg8xHxHxFRi4hLgbF0v72KiBsj4mcRUY+IO0mS1kvS1WcB10fEFen77oiIOyQVgP8CnBcR29L3vCkixnJ+JjdHxLfT9xyJiFsj4scRUY2IB0kSXiOG1wCPRsTfRcRoROyOiP9I110KnA0gqQi8iSSpmgFOGHbweSwzPTLN/OJ0+jDgocaKiKgDW4G16bptMbnnzYcy00cC702rdEqSSsDh6X57Jel5km5Iq3J2AW8n+aVP+hq/mGa31SRVYtOty2PrlBiOkfRdSY+m1VR/kyMGgO8Ax0naQFKK2xURP9nPmGwBcsKwhephkhM/AJJEcrLcBjwCrE2XNRyRmd4KfDgilmcevRFxRY73vRy4Bjg8IpYBnwMa77MVeNo0+zwOjM6wbgjozRxHkaQ6K2tql9OfBe4Djo6IpSRVdtkYjpou8LSUdhVJKeMtuHRhUzhh2EJ1FfBqSS9LG23fS1KtdBNwM1AF/lxSp6TfBU7M7PtF4O1paUGS+tLG7CU53ncJsDMiRiWdSFIN1XAZ8HJJZ0rqkLRK0vFp6ecS4GOSDpNUlPSCtM3k50B3+v6dwAeAfbWlLAGeAAYl/Sbwp5l13wWeKundkhZJWiLpeZn1XwHOAV6HE4ZN4YRhC1JE3E/yS/mTJL/gXwu8NiLKEVEGfpfkxLiTpL3jm5l9NwF/AnwKGAC2pNvm8Q7gYkm7gQtJElfjdX8FnEaSvHaSNHj/drr6fcDPSNpSdgL/EyhExK70Nb9EUjoaAiZdNTWN95Ekqt0kye/rmRh2k1Q3vRZ4FNgMvDSz/v+RNLbfFhHZajoz5AGUzCxL0g+AyyPiS62OxeYXJwwzGyfpucB1JG0wu1sdj80vrpIyMwAkXUpyj8a7nSxsOi5hmJlZLi5hmJlZLgumo7LVq1fH+vXrWx2GmdlB5dZbb308Iqbe2zOtBZMw1q9fz6ZNm1odhpnZQUVS7sunXSVlZma5OGGYmVkuThhmZpbLgmnDmE6lUqG/v5/R0dFWh9J03d3drFu3js5Oj3VjZs2xoBNGf38/S5YsYf369UzumHRhiQh27NhBf38/GzZsaHU4ZrZANa1KStIlkn4t6a4Z1kvSJyRtUTLk5rMz694qaXP6eOv+xjA6OsqqVasWdLIAkMSqVavaoiRlZq3TzDaMLwOn7GX9qcDR6eNckj78kbQS+BDwPJIupz+kzDjNs7XQk0VDuxynmbVO06qkIuLfJa3fyyanA19JRz37saTlkp4KnAxcFxE7ASRdR5J48gxeY9ZWavXgiZEKpZEKI+UanUXRUSzQURCdxQIdRdFZSJ4b04XCgf1xERFEQD2CACIgSJY1puuRbtdYn+4T6f71dLv0v+S1MusjoFoPKrU6lVqdai2o1utUakG1FlTqybLs+tp87RYpoBZBPYJ6PajVk+Ovp8tqdSbWpZ/NoUu7Oet5R+z7tZ+kVrZhrGXy0JL96bKZlu9B0rkkpROOOKL5H9b+KJVKXH755bzjHe+Y1X6nnXYal19+OcuXL29SZDYbo5UaA8NldgyWGRqr5jqBZU+Ks1WLYPdoldJwmV0jFUrDSVKYND9c5onR6qxfu1jQeEKZbe6I9H+Tjzk5aTHDyd+a74Qjli/4hPGkRcQXgC8AbNy4cV7+0yyVSnzmM5/ZI2FUq1U6Omb++K+99tpmh7agVGt1nhitUq7W019hycmsNj4dmWnSX21BpRaUhsvsHCqzc7jMzsH0eajMwFCZHenzULnWsmMrCJb1dLK8t4tlPZ2s7OviqNV94/PJuk56u4qZX9kx5Vd2nWo9KFfrVMd/bSefwWxJUJBQZhqBEAUlyxrTpNsVpHR5un58fvI+jZrV7PaFQvIae30tGC9RdRQK4yWtzkJa4iqKrinrG68zHxULoighaWK6AEUlcRcmTR+4g2hlwthGMsZyw7p02TaSaqns8hsPWFRz7Pzzz+cXv/gFxx9/PJ2dnXR3d7NixQruu+8+fv7zn/P617+erVu3Mjo6ynnnnce5554LTHR1Mjg4yKmnnsqLXvQibrrpJtauXct3vvMdenp6Wnxkcy8iGCrX2DE4Nn6i3jVS4YmRCrtGqsn0aIVdI5Xx5U+k03N1Qu/pLLKyr4uVfV2s6OviqDWLWdHbxarFXazoTZYv6e6YdIKb6QQ28ZxsOxsSLO3uZFlvJ0sWdRzwaiSz6bQyYVwDvEvSlSQN3Lsi4hFJ3wP+JtPQ/Urggif7Zn/9T3dzz8NPPNmXmeS4w5byodc+Y6/bfOQjH+Guu+7ijjvu4MYbb+TVr341d9111/jlr5dccgkrV65kZGSE5z73uZxxxhmsWrVq0mts3ryZK664gi9+8YuceeaZfOMb3+Dss8+e02Nphlo9GBxNTvSlkeTX+o7BMjuHxtgxWObxwTI7hsbYmS5/fHCMsWp9xtfr6yqyrKeTpenj8JW9yXx3Z7q8g0UdRYqF5GRdTH+JFdJfaYXGLzIlv+AKadXM8p4uVi7uYmVvFz1dxQP4CZkdXJqWMCRdQVJSWC2pn+TKp06AiPgccC3J+MZbgGHgD9N1OyX9d5KxjQEubjSALwQnnnjipHslPvGJT/Ctb30LgK1bt7J58+Y9EsaGDRs4/vjjAXjOc57Dgw8+eMDizRoaq/LLx4d4aMcwO4bGxn/dJ7/2qxPTaSlgcKw6Yx12V0eB1X1drFq8iFWLuzj6KUtYtbiLVZllKzJVLku7O+goumMCs1Zq5lVSb9rH+gDeOcO6S4BL5jKefZUEDpS+vr7x6RtvvJHrr7+em2++md7eXk4++eRp76VYtGjR+HSxWGRkZKRp8Y1Wajy4Y4gHHx/il48Pp89D/HLHENt3j+2xfU9nkaU9HeMn9qcu6+Y3D10yXgrInvBXLV7E6sVJQujrKvpSYLODzEHd6H0wWLJkCbt3Tz/a5a5du1ixYgW9vb3cd999/PjHPz5gcY1WatzzyBP8rH8X9z+2m19uH+LBHUM8smtywlq9eBEbVvdy8jFrWL+6jw2r+1i/qo81SxaNVwGZWXtwwmiyVatW8cIXvpBnPvOZ9PT0cMghh4yvO+WUU/jc5z7Hsccey9Of/nSe//znNyWGSq3O/Y/u5s7+XfxsW4mfbt3Fzx/bTbWe1Bct7+1kw+o+XnDUqvGksGF1H0eu6mVJt/umMrPEghnTe+PGjTF1AKV7772XY489tkURHXj33nsvxzz9N/nF9kHu7N/Fnf0l7uzfxT2PPEE5bUxe1tPJs9YtSx/Leda6ZRy6tNvVQ2ZtStKtEbExz7YuYRzEIoLRap2Rco3RSo3tu8c446LvMZxeYtrXVeSZa5dxzu+s57fWLuO31y3n8JU9Tg5mtl+cMA4S9QhGKzVGKjVGyzVGKnVGK7XxG68KaRI4c+PhSXI4fBlHrV7s6/fNbM44YcxT5WqN3aNVRsppkqjUk64oSO4h6OkssqovuW+gu7PIoo4C9z2xiItObJ8qODM7sJww5ol6BMNjVXaPVnlitMpYNalW6igU6Okqsqa7g57OIt1dRbqKBVcrmdkB54TRQpVand2jVXaPVhgcrVKLQBJ9XUVW9vWwpLuDRR1ODgelCKhVoDaWPNezXZfE5O2mXV6H6hhUR5NHZXRieqb5WjnZj0Y3sPWJ1xqfj8nThQ7oWATFRdDRDR1d6XNj2ZTlxUUTsUZMea5PsyySfk6Ki6DYlbxOcVHmOV1e7IJiJ/O2c6esiOT7rFegXk2/3+qe0435hvFjU2Zee65rLFchfTQ620rn91hXSD67nv0eBSI3J4wDKCIYLtfGk8RIJTmJdBYLSZ9B3Z0sXtRBcS7bHWoVqAwnJ5TKMFRG0sfwxHN1LDnZ1MrpSW5v05XMiQkmneSSg8zOTAlmmn/ojelJ6wqT/5imvtaMJ9nGSSvzqNfS6VpmPibPZ09w46+f6WZ26rqopZ9ZIyGUoVrOfFbp40ArdEw5oWjKPJPXoYljqY5mvtNWUZpUFkFhuvt7pvxdTJdcxv9tTPfdMc26dH7a/aZ5nagniWC+WbsR/uT7TX8bJ4wmK5VKXHbZZZxx9h+xY2iMWj0QoreryKHLulnS3Ul3RyH5U4ga1Megkvw6+fgnP8W557yZ3p6ezEkw9pwmnd79CPyfN05OCk/2H3ehc+LX3/gvwQ5Q5g96jz9cTb9u6gk9+2t3j2NL18/0WjMtVyGJTQUoFKbMFzPzmpif9Ktuul96mWcB6oTuZROfR8ei9PPJ/oqe8ph6AsxzLB3dE4/O7mnme5L37uxJ3rvwJLtOqVXTEstYkggb0+OP0UwiVCYBaYbPMX2OmEii2R8njenG+9UqE8tmXSKLGX7BZ2Kcad2k+b2tS//NFDqSv4tCMfneCx3JY3w6s67xb282SWrS30a2ZFif/m+FgN7VHAhOGE22Y+cAn/jUp3nl6b/HIV11+jqCRcWgUK9CuQqjleQPtV5l6i/yj3/yM5x92u/QuzItau6tSFooJv9Q152YnEA6e6c8T7csfe7IVg2kiaHQefBUEdjcKHZAcTEsWtzqSGyecsJohgiojlIb3c373/MufvXLB/j9V72YV7z4eTxl9Uqu+qfrGCtXeMNpr+CvL/gLhsaCM//oPPoffpRarc4HL/ivPLZ9Bw8/9jgvfdN5rF69mht+8IN9n7x/XYYzvnhgjtHM2k77JIx/OR8e/dncvuahvwWnfiSZrpahvBvGdsPYINQrFIG/ueDPuPfnW7jjlpv5tx/exNXf/A4/ue1nBPC6172Of797G9u3b+ewI47in7+X1EHu2rWLZcuW8bFPfIobbriB1asPTHHTzGxv2idhzLmkFEHpV0mCqKU9uRY6qBT7+HWtk5FCL/WVS1GxE3pX8m/fv5F/u+46Tnj2swEYHBxk8+bNnHTSSbz3ve/l/e9/P695zWs46aSTWnhcZmbTa5+E0SgJzIWhx2FXOuz4yAB0LYa+1cSiJTw+Kh7ZNUpvV5EjV/WxbWyip9qI4IILLuBtb3vbHi952223ce211/KBD3yAl73sZVx44YVzF6+Z2Rxon4QxV8Z2J8li0RJY8tSk4ViiHsHDpRF2Do2xrKeTw1f0UihoUvfmr3rVq/jgBz/Im9/8ZhYvXsy2bdvo7OykWq2ycuVKzj77bJYvX86XvvQlYKJrdFdJmdl84IQxG9Ux2PnL5LLGFRvGL5Ws1uv8ascwg2NVnrJkEYdken/Ndm9+6qmnctZZZ/GCF7wAgMWLF/O1r32NLVu28Jd/+ZcUCgU6Ozv57Gc/C8C5557LKaecwmGHHcYNN9zQmmM2M0u5e/O86jV4fHNyjfiaY5KkQdLn0y8fH6Zcq7N2eQ8r+7rm5v32Q7t1525mT567N59rEVB6CKojsPJp48liaKzKQzuGCYINq/pY3O2P08wWLp/h8hh8DEZ3wdLDoHspAKXhMlsHRugsivWrFtPd6aFKzWxhW/AJI9IO/fbbSCnpcqNnBfQ9BYDB0Qq/2jlMX1cHR67qpaP4JLtkmAMLpWrRzOav1p/pmqi7u5sdO3bs/8m0MpJURXX2wrIjxu+0Hk47DVy/ev4kix07dtDd3d3qUMxsAVvQJYx169bR39/P9u3bZ79zvZ5URVGHxYfC4/ePr9o1UmFwrErn7p65C/ZJ6u7uZt26da0Ow8wWsAWdMDo7O9mwYcPsd6xV4bIz4KGb4Jx/hsOfOWn1+6++kxvu38lP/tvL5yhSM7P5b0EnjP123YXwwI3wuk/B4SfusXpguMyK3tZdPmtm1gqtr4Cfb+64HH78aXje2+HZb5l2k9JwheW9nQc4MDOz1nLCyOrfBP/0btjwYnjl/5hxM5cwzKwdOWE0PPEIXPlmWHIo/P6lyeBBMxgYrrCizyUMM2svbsOAZLzrr5+ddCz4lm9C78oZN40ISsNllruEYWZtxgkjAr77Hti2Cc78KhzyjL1uPjhWpVoPVrgNw8zajKukHt8Md38TXnI+HPe6fW5eGq4AuIRhZm3HJYw1x8Dbf5R0KpjDeMLocQnDzNqLEwbA6qNzbzowXAZgRQu7MTczawVXSc3SeMJwG4aZtRknjFlyG4aZtSsnjFlqlDDchmFm7cYJY5ZKwxWWdHfMi27NzcwOJJ/1ZsndgphZu2pqwpB0iqT7JW2RdP4064+U9H1Jd0q6UdK6zLqapDvSxzXNjHM2BoYrbvA2s7bUtMtqJRWBTwOvAPqBWyRdExH3ZDb7KPCViLhU0n8C/hZodBE7EhHHNyu+/VVyCcPM2lQzSxgnAlsi4oGIKANXAqdP2eY44Afp9A3TrJ93kioplzDMrP00M2GsBbZm5vvTZVk/BX43nX4DsETSqnS+W9ImST+W9Prp3kDSuek2m/ZrGNb9UBqq+JJaM2tLrW70fh/wEkm3Ay8BtgG1dN2REbEROAv4uKQ9+u6IiC9ExMaI2LhmzZqmB1up1dk9VnWVlJm1pWZ2DbINODwzvy5dNi4iHiYtYUhaDJwREaV03bb0+QFJNwInAL9oYrz71Lhpz2NhmFk7amYJ4xbgaEkbJHUBbwQmXe0kabWkRgwXAJeky1dIWtTYBnghkG0sb4lS46Y9lzDMrA01LWFERBV4F/A94F7gqoi4W9LFkhr9iJ8M3C/p58AhwIfT5ccCmyT9lKQx/CNTrq5qiYFGCcON3mbWhpraW21EXAtcO2XZhZnpq4Grp9nvJuC3mhnb/pjoeNAlDDNrP61u9D6oTFRJuYRhZu3HCWMWJqqkXMIws/bjhDELA8NluooFeruKrQ7FzOyAc8KYheSmvU4ktToUM7MDzgljFtxTrZm1MyeMWSgNV9zgbWZtywljFlzCMLN25oQxCwPDFXcLYmZtywkjp4igNFx2tyBm1racMHIaHKtSrYe7BTGztuWEkVOjp1qXMMysXTlh5OR+pMys3Tlh5OSeas2s3Tlh5OSxMMys3Tlh5DQw1KiScgnDzNqTE0ZOjSqpZT1OGGbWnpwwcioNl1na3UFH0R+ZmbUnn/1ySu7ydvuFmbUvJ4ycSiMVlrs6yszamBNGTu4WxMzanRNGTklPtS5hmFn7csLIKRltzyUMM2tfThg5VGp1do9V3S2ImbU1J4wcGh0PeiwMM2tnThg5uFsQMzMnjFzc8aCZWc6EIembkl4tqS0TjLs2NzPLX8L4DHAWsFnSRyQ9vYkxzTsTVVIuYZhZ+8qVMCLi+oh4M/Bs4EHgekk3SfpDSQv+LDpRJeUShpm1r9xVTJJWAecAfwzcDvwfkgRyXVMim0cGhst0FQv0dhVbHYqZWct05NlI0reApwNfBV4bEY+kq74uaVOzgpsvkpv2OpHU6lDMzFomV8IAPhERN0y3IiI2zmE881LSLYiro8ysveWtkjpO0vLGjKQVkt7RpJjmndJwxQ3eZtb28iaMP4mIUmMmIgaAP2lOSPOPSxhmZvkTRlGZCnxJRaBtzqDJ4EkuYZhZe8vbhvGvJA3cn0/n35YuW/AiwmNhmJmRP2G8nyRJ/Gk6fx3wpaZENM8MjlWp1sPdgphZ28uVMCKiDnw2fbSVRk+1LmGYWbvL25fU0ZKulnSPpAcajxz7nSLpfklbJJ0/zfojJX1f0p2SbpS0LrPurZI2p4+3zu6w5o77kTIzS+Rt9P4HktJFFXgp8BXga3vbIW0Y/zRwKnAc8CZJx03Z7KPAVyLiWcDFwN+m+64EPgQ8DzgR+JCkFTljnVPuqdbMLJE3YfRExPcBRcRDEXER8Op97HMisCUiHoiIMnAlcPqUbY4DfpBO35BZ/yrguojYmV7Cex1wSs5Y55THwjAzS+RNGGNp1+abJb1L0huAxfvYZy2wNTPfny7L+inwu+n0G4AlaZ9VefZF0rmSNknatH379pyHMjsDQ40qKZcwzKy95U0Y5wG9wJ8DzwHOBuaiXeF9wEsk3Q68BNgG1PLuHBFfiIiNEbFxzZo1cxDOnhpVUst6nDDMrL3t8yqptC3iDyLifcAg8Ic5X3sbcHhmfl26bFxEPExawpC0GDgjIkqStgEnT9n3xpzvO6dKw2WWdnfQUWzLsaPMzMbt8ywYETXgRfvx2rcAR0vaIKkLeCNwTXYDSaszo/hdAFySTn8PeGXaZ9UK4JXpsgMuucvb7RdmZnlv3Ltd0jXAPwJDjYUR8c2ZdoiIqqR3kZzoi8AlEXG3pIuBTRFxDUkp4m8lBfDvwDvTfXdK+u8kSQfg4ojYObtDmxsDvsvbzAzInzC6gR3Af8osC2DGhAEQEdcC105ZdmFm+mrg6hn2vYSJEkfLlIYrrFrshGFmlvdO77ztFgvOwHCZ33jKvi4IMzNb+PKOuPcPJCWKSSLiv8x5RPOMx8IwM0vkrZL6bma6m+SeiYfnPpz5pVytMzhWdbcgZmbkr5L6RnZe0hXAj5oS0TxSGvFNe2ZmDft7c8HRwFPmMpD5yD3VmplNyNuGsZvJbRiPkoyRsaBNdAvihGFmlrdKakmzA5mPBsZLGK6SMjPLOx7GGyQty8wvl/T65oU1P+waafRU64RhZpa3DeNDEbGrMRMRJZLxKha0ibEwXCVlZpY3YUy3Xd5Lcg9aA8NluooFeruKrQ7FzKzl8iaMTZI+Julp6eNjwK3NDGw+KA0lN+1JanUoZmYtlzdh/BlQBr5OMnLeKGlHgQvZwHDZ1VFmZqm8V0kNAec3OZZ5x92CmJlNyHuV1HWSlmfmV0hqyfgUB5JLGGZmE/JWSa1Or4wCICIGaIM7vZPBk1zCMDOD/AmjLumIxoyk9UzTe+1CEhGUPHiSmdm4vJfG/jfgR5J+CAg4CTi3aVHNA4NjVar1cMeDZmapvI3e/yppI0mSuB34NjDSzMBazR0PmplNlrfzwT8GzgPWAXcAzwduZvKQrQvKwLA7HjQzy8rbhnEe8FzgoYh4KXACUNr7Lge3iW5BXCVlZgb5E8ZoRIwCSFoUEfcBT29eWK1XGm50POgShpkZ5G/07k/vw/g2cJ2kAeCh5oXVehNjYbiEYWYG+Ru935BOXiTpBmAZ8K9Ni2oeaFRJLetxwjAzg/3ocTYiftiMQOab0nCZpd0ddBT3dxRbM7OFxWfDGSR3ebv9wsyswQljBgO+y9vMbBInjBmUhitu8DYzy3DCmIF7qjUzm8wJYwYeC8PMbDInjGmUq3UGx6ouYZiZZThhTKM04pv2zMymcsKYhnuqNTPbkxPGNCa6BXHCMDNrcMKYxsB4CcNVUmZmDU4Y02j0VOs7vc3MJjhhTMNjYZiZ7ckJYxql4TJdHQV6OoutDsXMbN5wwphGcpd3J5JaHYqZ2bzR1IQh6RRJ90vaIun8adYfIekGSbdLulPSaeny9ZJGJN2RPj7XzDinGhiu+AopM7MpZj0eRl6SisCngVcA/cAtkq6JiHsym30AuCoiPivpOOBaYH267hcRcXyz4tub0nDZV0iZmU3RzBLGicCWiHggIsrAlcDpU7YJYGk6vQx4uInx5OYShpnZnpqZMNYCWzPz/emyrIuAsyX1k5Qu/iyzbkNaVfVDSSdN9waSzpW0SdKm7du3z1ngLmGYme2p1Y3ebwK+HBHrgNOAr0oqAI8AR0TECcBfAJdLWjp154j4QkRsjIiNa9asmZOAIiLtqdYlDDOzrGYmjG3A4Zn5demyrD8CrgKIiJuBbmB1RIxFxI50+a3AL4BjmhjruMGxKtV6+B4MM7MpmpkwbgGOlrRBUhfwRuCaKdv8CngZgKRjSRLGdklr0kZzJB0FHA080MRYx7njQTOz6TXtKqmIqEp6F/A9oAhcEhF3S7oY2BQR1wDvBb4o6T0kDeDnRERIejFwsaQKUAfeHhE7mxVr1sCwOx40M5tO0xIGQERcS9KYnV12YWb6HuCF0+z3DeAbzYxtJu4WxMxseq1u9J53Gh0PukrKzGwyJ4wpJsbCcAnDzCzLCWOKRpXUsh4nDDOzLCeMKUrDZZZ2d9BR9EdjZpbls+IUA8MVD5xkZjYNJ4wpBobLbvA2M5uGE8YUpeGKG7zNzKbhhDFFMniSSxhmZlM5YUyRdDzoEoaZ2VROGBnlap3BsapLGGZm03DCyCiN+KY9M7OZOGFkuKdaM7OZOWFkTHQL4oRhZjaVE0bGwHgJw1VSZmZTOWFkNHqq9Z3eZmZ7csLI8FgYZmYzc8LIKA2X6eoo0NNZbHUoZmbzjhNGRnKXdyeSWh2Kmdm844qCj00AAAffSURBVISRMTBc8RVSZmYzcMLIKA2XfYWUmdkMnDAyXMIwM5uZE0ZGyWNhmJnNyAkjFREeC8PMbC+cMFK7x6pU6+EqKTOzGThhpEpD7hbEzGxvnDBSA8PueNDMbG+cMFLjCaPPJQwzs+k4YaQ8FoaZ2d45YaRcJWVmtndOGKlGT7VLuztaHImZ2fzkhJEqDZdZ2t1BR9EfiZnZdHx2TJWGKx44ycxsL5wwUgPuFsTMbK+cMFLuFsTMbO+cMFLJ4EkuYZiZzcQJI1UarrhbEDOzvXDCAMrVOoNjVZcwzMz2wgkDKI00btpzCcPMbCZNTRiSTpF0v6Qtks6fZv0Rkm6QdLukOyWdlll3Qbrf/ZJe1cw43S2Imdm+Ne22ZklF4NPAK4B+4BZJ10TEPZnNPgBcFRGflXQccC2wPp1+I/AM4DDgeknHREStGbEODLlbEDOzfWlmCeNEYEtEPBARZeBK4PQp2wSwNJ1eBjycTp8OXBkRYxHxS2BL+npNMTDssTDMzPalmQljLbA1M9+fLsu6CDhbUj9J6eLPZrEvks6VtEnSpu3bt+93oKXxrs1dwjAzm0mrG73fBHw5ItYBpwFflZQ7poj4QkRsjIiNa9as2e8gGiUMN3qbmc2smV2zbgMOz8yvS5dl/RFwCkBE3CypG1idc985Uxou09VRoKez2Ky3MDM76DWzhHELcLSkDZK6SBqxr5myza+AlwFIOhboBran271R0iJJG4CjgZ80K9DkLu9OJDXrLczMDnpNK2FERFXSu4DvAUXgkoi4W9LFwKaIuAZ4L/BFSe8haQA/JyICuFvSVcA9QBV4Z7OukIKkSspXSJmZ7V1TRwuKiGtJGrOzyy7MTN8DvHCGfT8MfLiZ8TWUhsu+QsrMbB9a3eg9L7iEYWa2b04YNEoYThhmZnvT9gkjIjwWhplZDm2fMHaPVanWw1VSZmb70PYJo1YLXvOsp/L0Q5e0OhQzs3mtqVdJHQxW9HXxqbOe3eowzMzmvbYvYZiZWT5OGGZmlosThpmZ5eKEYWZmuThhmJlZLk4YZmaWixOGmZnl4oRhZma5KBl+4uAnaTvw0JN4idXA43MUzsHGx96+2vn42/nYYeL4j4yIXGNcL5iE8WRJ2hQRG1sdRyv42Nvz2KG9j7+djx327/hdJWVmZrk4YZiZWS5OGBO+0OoAWsjH3r7a+fjb+dhhP47fbRhmZpaLSxhmZpaLE4aZmeXS9glD0imS7pe0RdL5rY7nQJP0oKSfSbpD0qZWx9NMki6R9GtJd2WWrZR0naTN6fOKVsbYTDMc/0WStqXf/x2STmtljM0i6XBJN0i6R9Ldks5Lly/4738vxz7r776t2zAkFYGfA68A+oFbgDdFxD0tDewAkvQgsDEiFvwNTJJeDAwCX4mIZ6bL/hewMyI+kv5gWBER729lnM0yw/FfBAxGxEdbGVuzSXoq8NSIuE3SEuBW4PXAOSzw738vx34ms/zu272EcSKwJSIeiIgycCVweotjsiaJiH8Hdk5ZfDpwaTp9Kckf0oI0w/G3hYh4JCJuS6d3A/cCa2mD738vxz5r7Z4w1gJbM/P97OcHeRAL4N8k3Srp3FYH0wKHRMQj6fSjwCGtDKZF3iXpzrTKasFVyUwlaT1wAvAftNn3P+XYYZbffbsnDIMXRcSzgVOBd6bVFm0pkvrZdquj/SzwNOB44BHg71obTnNJWgx8A3h3RDyRXbfQv/9pjn3W3327J4xtwOGZ+XXpsrYREdvS518D3yKppmsnj6V1vI263l+3OJ4DKiIei4haRNSBL7KAv39JnSQnzMsi4pvp4rb4/qc79v357ts9YdwCHC1pg6Qu4I3ANS2O6YCR1Jc2giGpD3glcNfe91pwrgHemk6/FfhOC2M54Bony9QbWKDfvyQBfw/cGxEfy6xa8N//TMe+P999W18lBZBeSvZxoAhcEhEfbnFIB4yko0hKFQAdwOUL+fglXQGcTNKt82PAh4BvA1cBR5B0j39mRCzIhuEZjv9kkiqJAB4E3pap018wJL0I+L/Az4B6uvivSOryF/T3v5djfxOz/O7bPmGYmVk+7V4lZWZmOTlhmJlZLk4YZmaWixOGmZnl4oRhZma5OGGYzQOSTpb03VbHYbY3ThhmZpaLE4bZLEg6W9JP0vEDPi+pKGlQ0v9Oxxr4vqQ16bbHS/px2rnbtxqdu0n6DUnXS/qppNskPS19+cWSrpZ0n6TL0jt0zeYNJwyznCQdC/wB8MKIOB6oAW8G+oBNEfEM4Ickd1ADfAV4f0Q8i+Qu28byy4BPR8RvA79D0vEbJL2Ivhs4DjgKeGHTD8psFjpaHYDZQeRlwHOAW9If/z0kndXVga+n23wN+KakZcDyiPhhuvxS4B/TvrvWRsS3ACJiFCB9vZ9ERH86fwewHvhR8w/LLB8nDLP8BFwaERdMWih9cMp2+9vfzlhmuob/Pm2ecZWUWX7fB35P0lNgfDzoI0n+jn4v3eYs4EcRsQsYkHRSuvwtwA/TEc/6Jb0+fY1FknoP6FGY7Sf/gjHLKSLukfQBkhEKC0AFeCcwBJyYrvs1STsHJN1lfy5NCA8Af5gufwvweUkXp6/x+wfwMMz2m3urNXuSJA1GxOJWx2HWbK6SMjOzXFzCMDOzXFzCMDOzXJwwzMwsFycMMzPLxQnDzMxyccIwM7Nc/j9O90yfSLjInQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSbfsGcrYMnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}