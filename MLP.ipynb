{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "MLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srajan1122/Hyperspectral_Image_Classification/blob/srajan/MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPaR_PMpqr4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder \n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_Hm1EnarlHU",
        "colab_type": "code",
        "outputId": "4b486601-2a11-4ba0-bc4e-5dd612d3245d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv6E_d9vk2r8",
        "colab_type": "text"
      },
      "source": [
        "# Genetic Algorithm for Optimizing the parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DxeZjNPxWbLT",
        "colab": {}
      },
      "source": [
        "import random\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "class POGA:\n",
        "  def __init__(self, numberOfParents, X_train, X_test, y_train, y_test, numParents, generationNumber):\n",
        "    self.score_list = []\n",
        "    self.population_list = []\n",
        "    self.start_population = self.initilialize_population(numberOfParents)\n",
        "    \n",
        "    for i in range(generationNumber):\n",
        "      print('Generation',i+1, 'started')\n",
        "      self.score = self.train_population(self.start_population, X_train, X_test, y_train, y_test)\n",
        "      self.score_list.append(self.score.copy())\n",
        "\n",
        "      self.best_parents = self.new_parents_selection(self.start_population, self.score, numParents)\n",
        "    \n",
        "      self.childrens = self.crossover_uniform(self.best_parents,\n",
        "                                              (len(self.start_population)-len(self.best_parents),len(self.start_population[0]))\n",
        "                                              )                                  \n",
        "      \n",
        "      self.mutated_childrens = self.mutation(self.childrens, 5)\n",
        "\n",
        "      self.start_population = self.best_parents + self.mutated_childrens\n",
        "      self.population_list.append(self.start_population)\n",
        "      print('Generation',i+1, 'finished')\n",
        "\n",
        "\n",
        "  def initilialize_population(self, numberOfParents):\n",
        "    hidden_layer_sizes = []\n",
        "    alpha =[]\n",
        "    batch_size = []\n",
        "    learning_rate_init = []\n",
        "    n_iter_no_change = []\n",
        "    # beta_1 beta_2 epsilon\n",
        "\n",
        "    for i in range(numberOfParents):\n",
        "\n",
        "      hidden_layer = []\n",
        "      for i in range(5):\n",
        "        hidden_layer.append(random.randrange(16, 150))\n",
        "\n",
        "      hidden_layer_sizes.append(hidden_layer)\n",
        "      alpha.append(random.choice(np.logspace(-5, 5, 11)))\n",
        "      batch_size.append(random.randrange(200, 1000, 10)) \n",
        "      learning_rate_init.append(random.choice(np.logspace(-1,-5, 5)))\n",
        "      n_iter_no_change.append(random.randrange(1, 500, 10))\n",
        "\n",
        "    population = zip(hidden_layer_sizes,\n",
        "                     alpha,\n",
        "                     batch_size,\n",
        "                     learning_rate_init,\n",
        "                     n_iter_no_change)\n",
        "    return list(population)\n",
        "\n",
        "  def train_population(self, population, X_train, X_test, y_train, y_test ):\n",
        "    Fscore = []\n",
        "    for i in list(population):\n",
        "      model = MLPClassifier(\n",
        "                      hidden_layer_sizes=i[0],\n",
        "                      activation='relu',\n",
        "                      solver='adam',\n",
        "                      alpha=i[1],\n",
        "                      batch_size=i[2],\n",
        "                      learning_rate='constant',\n",
        "                      learning_rate_init=i[3],\n",
        "                      power_t=0.5,\n",
        "                      max_iter=1000,\n",
        "                      shuffle=True,\n",
        "                      random_state=1,\n",
        "                      tol=0.0001,\n",
        "                      verbose=False,\n",
        "                      warm_start=False,\n",
        "                      momentum=0.9,\n",
        "                      nesterovs_momentum=True,\n",
        "                      early_stopping=False,\n",
        "                      validation_fraction=0.18,#0.33 0.18\n",
        "                      beta_1=0.9,\n",
        "                      beta_2=0.999,\n",
        "                      epsilon=1e-08,\n",
        "                      n_iter_no_change=i[4],\n",
        "                      max_fun=15000)\n",
        "      model.fit(X_train, y_train)\n",
        "      prediction = model.predict(X_test)\n",
        "      Fscore.append(f1_score(y_test, prediction, average=\"weighted\"))\n",
        "\n",
        "    return Fscore\n",
        "\n",
        "  def new_parents_selection(self, population, fitness, numParents):\n",
        "    new_parents = []\n",
        "    for i in range(numParents):\n",
        "      max_fitness_index = fitness.index(max(fitness))\n",
        "      new_parents.append(population[max_fitness_index])\n",
        "      fitness[max_fitness_index] = -1\n",
        "    return new_parents\n",
        "\n",
        "  def crossover_uniform(self, parents, children_size):\n",
        "    crossoverPointIndex = np.arange(0, np.uint8(children_size[1]), 1, dtype= np.uint8)\n",
        "    crossoverPointIndex1 = np.random.randint(0, np.uint8(children_size[1]), np.uint8(children_size[1]/2))\n",
        "    crossoverPointIndex2 = np.array(list(set(crossoverPointIndex) - set(crossoverPointIndex1)))\n",
        "\n",
        "    children = [[0]*children_size[1]]*children_size[0]\n",
        "\n",
        "    for i in range(children_size[0]):\n",
        "      parent1_index = i%len(parents)\n",
        "      parent2_index = (i+1)%len(parents)\n",
        "      for j in crossoverPointIndex1:\n",
        "        children[i][j] = parents[parent1_index][j]\n",
        "      for j in crossoverPointIndex2:\n",
        "        children[i][j] = parents[parent1_index][j]\n",
        "\n",
        "    return children\n",
        "\n",
        "  def mutation(self, crossover, numberOfParameters):\n",
        "    minMaxValue = np.zeros((numberOfParameters, 2))\n",
        "\n",
        "    minMaxValue[0:] = [16, 150] # hidden_layer_sizes\n",
        "    minMaxValue[1:] = [0.00001, 10000] # alpha\n",
        "    minMaxValue[2:] = [200, 1000] # batch_size\n",
        "    minMaxValue[3:] = [0.000001, 0.1] # learning_rate_init\n",
        "    minMaxValue[4:] = [1,500] # n_iter_no_change\n",
        "\n",
        "    parameterSelect = random.randint(0, numberOfParameters-1)\n",
        "    if parameterSelect == 0:\n",
        "      mutationValue = random.choice(list(range(-30,40,10)))\n",
        "    elif parameterSelect == 1:\n",
        "      mutationValue = random.choice([0.1,10])\n",
        "    elif parameterSelect == 2:\n",
        "      mutationValue = random.randint(-50, 30)\n",
        "    elif parameterSelect == 3:\n",
        "      mutationValue = random.choice([0.1,10])\n",
        "    elif parameterSelect == 4:\n",
        "      mutationValue = random.randint(-50, 50)\n",
        "\n",
        "    for i in crossover:\n",
        "      if parameterSelect == 2 or parameterSelect == 4:\n",
        "        i[parameterSelect] = i[parameterSelect] + mutationValue\n",
        "      elif parameterSelect == 1 or parameterSelect == 3:\n",
        "        i[parameterSelect] = i[parameterSelect] * mutationValue\n",
        "      elif parameterSelect == 0:\n",
        "        for j in range(len(i[parameterSelect])):\n",
        "          if(random.choice([True,False])):\n",
        "            i[parameterSelect][j] = i[parameterSelect][j] + mutationValue\n",
        "            if i[parameterSelect][j]  < minMaxValue[parameterSelect, 0]:\n",
        "               i[parameterSelect][j] = minMaxValue[parameterSelect, 0]\n",
        "            if i[parameterSelect][j]  > minMaxValue[parameterSelect, 1]:\n",
        "               i[parameterSelect][j] = minMaxValue[parameterSelect, 1]\n",
        "        return crossover\n",
        "\n",
        "      if i[parameterSelect] < minMaxValue[parameterSelect, 0]:\n",
        "        i[parameterSelect] = minMaxValue[parameterSelect, 0]\n",
        "      elif i[parameterSelect] > minMaxValue[parameterSelect, 1]:\n",
        "        i[parameterSelect] = minMaxValue[parameterSelect, 1]\n",
        "\n",
        "    return crossover\n",
        "  \n",
        "  def best_parameters(self):\n",
        "    best_index = self.score_list[-1].index(max(self.score_list[-1]))\n",
        "    parameters = self.population_list[-1][best_index]\n",
        "    best_parameters = {}\n",
        "    best_parameters['hidden_layer_sizes'] = parameters[0]\n",
        "    best_parameters['alpha'] = parameters[1]\n",
        "    best_parameters['batch_size'] = parameters[2]\n",
        "    best_parameters['learning_rate_init'] = parameters[3]\n",
        "    best_parameters['n_iter_no_change'] = parameters[4]\n",
        "\n",
        "    return best_parameters\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iagvBXJrA6z",
        "colab_type": "code",
        "outputId": "a2e16a58-bdb3-4111-970a-efc7be0d2072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import random\n",
        "alphas = np.logspace(-5, 5, 11)\n",
        "learning = np.logspace(-1,-5, 5)\n",
        "tol = np.logspace(-4,-5, 2)\n",
        "hidden_layer = []\n",
        "for i in range(5):\n",
        "  hidden_layer.append(random.randrange(16, 150))\n",
        "\n",
        "learning"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm2wKCIeqr4a",
        "colab_type": "text"
      },
      "source": [
        "## Loading DataSet\n",
        "### Dataset include image and a ground truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dtzTWYbqr4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_dataset = io.loadmat('/content/drive/My Drive/Srajan/Internship/SEM4-LeadingindiaAI/Tasks/Datasets/IndianPines/Indian_pines_corrected.mat')\n",
        "image = loaded_dataset['indian_pines_corrected']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o91U13klqr4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ground_truth = io.loadmat('/content/drive/My Drive/Srajan/Internship/SEM4-LeadingindiaAI/Tasks/Datasets/IndianPines/Indian_pines_gt.mat')\n",
        "ground_truth = ground_truth['indian_pines_gt']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_ctG247SqUA",
        "colab_type": "text"
      },
      "source": [
        "### Class Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BX_iYn1SpDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_values = [\"Alfalfa\", \"Corn-notill\", \"Corn-mintill\",\n",
        "                        \"Corn\", \"Grass-pasture\", \"Grass-trees\",\n",
        "                        \"Grass-pasture-mowed\", \"Hay-windrowed\", \"Oats\",\n",
        "                        \"Soybean-notill\", \"Soybean-mintill\", \"Soybean-clean\",\n",
        "                        \"Wheat\", \"Woods\", \"Buildings-Grass-Trees-Drives\",\n",
        "                        \"Stone-Steel-Towers\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEmg8p8eqr4q",
        "colab_type": "text"
      },
      "source": [
        "### Resizing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM_fTNbcqr4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_with_gt = np.dstack((image, ground_truth))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9Zi3M51qr41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_output = image_with_gt.reshape(ground_truth.size, image.shape[2]+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wuvox2x0qr47",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing data in pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1vjwrxOqr4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.DataFrame(final_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPO3FjPSqr5H",
        "colab_type": "code",
        "outputId": "261fdb94-6c8f-420d-857b-ce5abb13cea6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>161</th>\n",
              "      <th>162</th>\n",
              "      <th>163</th>\n",
              "      <th>164</th>\n",
              "      <th>165</th>\n",
              "      <th>166</th>\n",
              "      <th>167</th>\n",
              "      <th>168</th>\n",
              "      <th>169</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "      <th>200</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3172</td>\n",
              "      <td>4142</td>\n",
              "      <td>4506</td>\n",
              "      <td>4279</td>\n",
              "      <td>4782</td>\n",
              "      <td>5048</td>\n",
              "      <td>5213</td>\n",
              "      <td>5106</td>\n",
              "      <td>5053</td>\n",
              "      <td>4750</td>\n",
              "      <td>4816</td>\n",
              "      <td>4769</td>\n",
              "      <td>4610</td>\n",
              "      <td>4805</td>\n",
              "      <td>4828</td>\n",
              "      <td>4861</td>\n",
              "      <td>4767</td>\n",
              "      <td>4624</td>\n",
              "      <td>4549</td>\n",
              "      <td>4463</td>\n",
              "      <td>4462</td>\n",
              "      <td>4446</td>\n",
              "      <td>4445</td>\n",
              "      <td>4336</td>\n",
              "      <td>4381</td>\n",
              "      <td>4319</td>\n",
              "      <td>4207</td>\n",
              "      <td>4305</td>\n",
              "      <td>4311</td>\n",
              "      <td>3991</td>\n",
              "      <td>4168</td>\n",
              "      <td>3942</td>\n",
              "      <td>4061</td>\n",
              "      <td>4362</td>\n",
              "      <td>4318</td>\n",
              "      <td>4252</td>\n",
              "      <td>4869</td>\n",
              "      <td>5284</td>\n",
              "      <td>5055</td>\n",
              "      <td>3591</td>\n",
              "      <td>...</td>\n",
              "      <td>1396</td>\n",
              "      <td>1381</td>\n",
              "      <td>1396</td>\n",
              "      <td>1381</td>\n",
              "      <td>1353</td>\n",
              "      <td>1346</td>\n",
              "      <td>1341</td>\n",
              "      <td>1332</td>\n",
              "      <td>1324</td>\n",
              "      <td>1310</td>\n",
              "      <td>1318</td>\n",
              "      <td>1330</td>\n",
              "      <td>1310</td>\n",
              "      <td>1292</td>\n",
              "      <td>1280</td>\n",
              "      <td>1275</td>\n",
              "      <td>1266</td>\n",
              "      <td>1264</td>\n",
              "      <td>1233</td>\n",
              "      <td>1241</td>\n",
              "      <td>1232</td>\n",
              "      <td>1215</td>\n",
              "      <td>1215</td>\n",
              "      <td>1187</td>\n",
              "      <td>1168</td>\n",
              "      <td>1171</td>\n",
              "      <td>1150</td>\n",
              "      <td>1134</td>\n",
              "      <td>1123</td>\n",
              "      <td>1135</td>\n",
              "      <td>1094</td>\n",
              "      <td>1090</td>\n",
              "      <td>1112</td>\n",
              "      <td>1090</td>\n",
              "      <td>1062</td>\n",
              "      <td>1069</td>\n",
              "      <td>1057</td>\n",
              "      <td>1020</td>\n",
              "      <td>1020</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2580</td>\n",
              "      <td>4266</td>\n",
              "      <td>4502</td>\n",
              "      <td>4426</td>\n",
              "      <td>4853</td>\n",
              "      <td>5249</td>\n",
              "      <td>5352</td>\n",
              "      <td>5353</td>\n",
              "      <td>5347</td>\n",
              "      <td>5065</td>\n",
              "      <td>5141</td>\n",
              "      <td>5100</td>\n",
              "      <td>4994</td>\n",
              "      <td>5172</td>\n",
              "      <td>5290</td>\n",
              "      <td>5289</td>\n",
              "      <td>5217</td>\n",
              "      <td>5053</td>\n",
              "      <td>5033</td>\n",
              "      <td>4939</td>\n",
              "      <td>4931</td>\n",
              "      <td>4941</td>\n",
              "      <td>4902</td>\n",
              "      <td>4824</td>\n",
              "      <td>4859</td>\n",
              "      <td>4805</td>\n",
              "      <td>4698</td>\n",
              "      <td>4794</td>\n",
              "      <td>4806</td>\n",
              "      <td>4452</td>\n",
              "      <td>4628</td>\n",
              "      <td>4433</td>\n",
              "      <td>4643</td>\n",
              "      <td>4967</td>\n",
              "      <td>4853</td>\n",
              "      <td>4760</td>\n",
              "      <td>5449</td>\n",
              "      <td>5768</td>\n",
              "      <td>5684</td>\n",
              "      <td>3987</td>\n",
              "      <td>...</td>\n",
              "      <td>1421</td>\n",
              "      <td>1415</td>\n",
              "      <td>1428</td>\n",
              "      <td>1415</td>\n",
              "      <td>1379</td>\n",
              "      <td>1370</td>\n",
              "      <td>1360</td>\n",
              "      <td>1353</td>\n",
              "      <td>1352</td>\n",
              "      <td>1336</td>\n",
              "      <td>1346</td>\n",
              "      <td>1351</td>\n",
              "      <td>1330</td>\n",
              "      <td>1315</td>\n",
              "      <td>1305</td>\n",
              "      <td>1292</td>\n",
              "      <td>1282</td>\n",
              "      <td>1286</td>\n",
              "      <td>1259</td>\n",
              "      <td>1259</td>\n",
              "      <td>1250</td>\n",
              "      <td>1229</td>\n",
              "      <td>1232</td>\n",
              "      <td>1195</td>\n",
              "      <td>1177</td>\n",
              "      <td>1184</td>\n",
              "      <td>1153</td>\n",
              "      <td>1137</td>\n",
              "      <td>1138</td>\n",
              "      <td>1137</td>\n",
              "      <td>1108</td>\n",
              "      <td>1104</td>\n",
              "      <td>1117</td>\n",
              "      <td>1091</td>\n",
              "      <td>1079</td>\n",
              "      <td>1085</td>\n",
              "      <td>1064</td>\n",
              "      <td>1029</td>\n",
              "      <td>1020</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3687</td>\n",
              "      <td>4266</td>\n",
              "      <td>4421</td>\n",
              "      <td>4498</td>\n",
              "      <td>5019</td>\n",
              "      <td>5293</td>\n",
              "      <td>5438</td>\n",
              "      <td>5427</td>\n",
              "      <td>5383</td>\n",
              "      <td>5132</td>\n",
              "      <td>5227</td>\n",
              "      <td>5172</td>\n",
              "      <td>5097</td>\n",
              "      <td>5313</td>\n",
              "      <td>5411</td>\n",
              "      <td>5412</td>\n",
              "      <td>5341</td>\n",
              "      <td>5191</td>\n",
              "      <td>5140</td>\n",
              "      <td>5069</td>\n",
              "      <td>5110</td>\n",
              "      <td>5119</td>\n",
              "      <td>5046</td>\n",
              "      <td>4981</td>\n",
              "      <td>5023</td>\n",
              "      <td>4987</td>\n",
              "      <td>4862</td>\n",
              "      <td>4965</td>\n",
              "      <td>4992</td>\n",
              "      <td>4595</td>\n",
              "      <td>4756</td>\n",
              "      <td>4529</td>\n",
              "      <td>4801</td>\n",
              "      <td>5077</td>\n",
              "      <td>4983</td>\n",
              "      <td>4868</td>\n",
              "      <td>5515</td>\n",
              "      <td>5972</td>\n",
              "      <td>5913</td>\n",
              "      <td>4027</td>\n",
              "      <td>...</td>\n",
              "      <td>1446</td>\n",
              "      <td>1440</td>\n",
              "      <td>1443</td>\n",
              "      <td>1425</td>\n",
              "      <td>1390</td>\n",
              "      <td>1379</td>\n",
              "      <td>1376</td>\n",
              "      <td>1363</td>\n",
              "      <td>1355</td>\n",
              "      <td>1347</td>\n",
              "      <td>1361</td>\n",
              "      <td>1356</td>\n",
              "      <td>1341</td>\n",
              "      <td>1330</td>\n",
              "      <td>1321</td>\n",
              "      <td>1304</td>\n",
              "      <td>1290</td>\n",
              "      <td>1289</td>\n",
              "      <td>1263</td>\n",
              "      <td>1269</td>\n",
              "      <td>1261</td>\n",
              "      <td>1245</td>\n",
              "      <td>1241</td>\n",
              "      <td>1214</td>\n",
              "      <td>1185</td>\n",
              "      <td>1188</td>\n",
              "      <td>1156</td>\n",
              "      <td>1147</td>\n",
              "      <td>1149</td>\n",
              "      <td>1144</td>\n",
              "      <td>1111</td>\n",
              "      <td>1114</td>\n",
              "      <td>1114</td>\n",
              "      <td>1100</td>\n",
              "      <td>1065</td>\n",
              "      <td>1092</td>\n",
              "      <td>1061</td>\n",
              "      <td>1030</td>\n",
              "      <td>1016</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2749</td>\n",
              "      <td>4258</td>\n",
              "      <td>4603</td>\n",
              "      <td>4493</td>\n",
              "      <td>4958</td>\n",
              "      <td>5234</td>\n",
              "      <td>5417</td>\n",
              "      <td>5355</td>\n",
              "      <td>5349</td>\n",
              "      <td>5096</td>\n",
              "      <td>5147</td>\n",
              "      <td>5078</td>\n",
              "      <td>5040</td>\n",
              "      <td>5237</td>\n",
              "      <td>5321</td>\n",
              "      <td>5344</td>\n",
              "      <td>5255</td>\n",
              "      <td>5121</td>\n",
              "      <td>5035</td>\n",
              "      <td>4956</td>\n",
              "      <td>4994</td>\n",
              "      <td>4980</td>\n",
              "      <td>4905</td>\n",
              "      <td>4857</td>\n",
              "      <td>4900</td>\n",
              "      <td>4831</td>\n",
              "      <td>4720</td>\n",
              "      <td>4848</td>\n",
              "      <td>4847</td>\n",
              "      <td>4484</td>\n",
              "      <td>4613</td>\n",
              "      <td>4402</td>\n",
              "      <td>4674</td>\n",
              "      <td>4966</td>\n",
              "      <td>4848</td>\n",
              "      <td>4776</td>\n",
              "      <td>5473</td>\n",
              "      <td>5894</td>\n",
              "      <td>5789</td>\n",
              "      <td>4086</td>\n",
              "      <td>...</td>\n",
              "      <td>1432</td>\n",
              "      <td>1427</td>\n",
              "      <td>1426</td>\n",
              "      <td>1416</td>\n",
              "      <td>1386</td>\n",
              "      <td>1374</td>\n",
              "      <td>1375</td>\n",
              "      <td>1359</td>\n",
              "      <td>1343</td>\n",
              "      <td>1343</td>\n",
              "      <td>1354</td>\n",
              "      <td>1351</td>\n",
              "      <td>1333</td>\n",
              "      <td>1329</td>\n",
              "      <td>1313</td>\n",
              "      <td>1296</td>\n",
              "      <td>1280</td>\n",
              "      <td>1281</td>\n",
              "      <td>1251</td>\n",
              "      <td>1255</td>\n",
              "      <td>1253</td>\n",
              "      <td>1238</td>\n",
              "      <td>1223</td>\n",
              "      <td>1207</td>\n",
              "      <td>1188</td>\n",
              "      <td>1188</td>\n",
              "      <td>1154</td>\n",
              "      <td>1143</td>\n",
              "      <td>1144</td>\n",
              "      <td>1146</td>\n",
              "      <td>1122</td>\n",
              "      <td>1108</td>\n",
              "      <td>1109</td>\n",
              "      <td>1109</td>\n",
              "      <td>1071</td>\n",
              "      <td>1088</td>\n",
              "      <td>1060</td>\n",
              "      <td>1030</td>\n",
              "      <td>1006</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2746</td>\n",
              "      <td>4018</td>\n",
              "      <td>4675</td>\n",
              "      <td>4417</td>\n",
              "      <td>4886</td>\n",
              "      <td>5117</td>\n",
              "      <td>5215</td>\n",
              "      <td>5096</td>\n",
              "      <td>5098</td>\n",
              "      <td>4834</td>\n",
              "      <td>4853</td>\n",
              "      <td>4857</td>\n",
              "      <td>4734</td>\n",
              "      <td>4879</td>\n",
              "      <td>4976</td>\n",
              "      <td>4958</td>\n",
              "      <td>4885</td>\n",
              "      <td>4754</td>\n",
              "      <td>4647</td>\n",
              "      <td>4532</td>\n",
              "      <td>4586</td>\n",
              "      <td>4591</td>\n",
              "      <td>4492</td>\n",
              "      <td>4453</td>\n",
              "      <td>4497</td>\n",
              "      <td>4398</td>\n",
              "      <td>4297</td>\n",
              "      <td>4408</td>\n",
              "      <td>4401</td>\n",
              "      <td>4102</td>\n",
              "      <td>4227</td>\n",
              "      <td>4075</td>\n",
              "      <td>4264</td>\n",
              "      <td>4529</td>\n",
              "      <td>4490</td>\n",
              "      <td>4438</td>\n",
              "      <td>5001</td>\n",
              "      <td>5378</td>\n",
              "      <td>5321</td>\n",
              "      <td>3779</td>\n",
              "      <td>...</td>\n",
              "      <td>1401</td>\n",
              "      <td>1397</td>\n",
              "      <td>1395</td>\n",
              "      <td>1390</td>\n",
              "      <td>1368</td>\n",
              "      <td>1349</td>\n",
              "      <td>1354</td>\n",
              "      <td>1340</td>\n",
              "      <td>1330</td>\n",
              "      <td>1324</td>\n",
              "      <td>1336</td>\n",
              "      <td>1332</td>\n",
              "      <td>1320</td>\n",
              "      <td>1307</td>\n",
              "      <td>1287</td>\n",
              "      <td>1283</td>\n",
              "      <td>1267</td>\n",
              "      <td>1265</td>\n",
              "      <td>1239</td>\n",
              "      <td>1240</td>\n",
              "      <td>1239</td>\n",
              "      <td>1229</td>\n",
              "      <td>1212</td>\n",
              "      <td>1202</td>\n",
              "      <td>1178</td>\n",
              "      <td>1178</td>\n",
              "      <td>1143</td>\n",
              "      <td>1135</td>\n",
              "      <td>1138</td>\n",
              "      <td>1135</td>\n",
              "      <td>1110</td>\n",
              "      <td>1107</td>\n",
              "      <td>1112</td>\n",
              "      <td>1094</td>\n",
              "      <td>1072</td>\n",
              "      <td>1087</td>\n",
              "      <td>1052</td>\n",
              "      <td>1034</td>\n",
              "      <td>1019</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 201 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    0     1     2     3     4     5    ...   195   196   197   198   199  200\n",
              "0  3172  4142  4506  4279  4782  5048  ...  1062  1069  1057  1020  1020    3\n",
              "1  2580  4266  4502  4426  4853  5249  ...  1079  1085  1064  1029  1020    3\n",
              "2  3687  4266  4421  4498  5019  5293  ...  1065  1092  1061  1030  1016    3\n",
              "3  2749  4258  4603  4493  4958  5234  ...  1071  1088  1060  1030  1006    3\n",
              "4  2746  4018  4675  4417  4886  5117  ...  1072  1087  1052  1034  1019    3\n",
              "\n",
              "[5 rows x 201 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx_1RuBeqr5N",
        "colab_type": "text"
      },
      "source": [
        "### Droping the row if ground_truth value is zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5W1G0Gnqr5O",
        "colab_type": "code",
        "outputId": "f2d1e080-4d8f-4fb4-8b86-13efe1aae20a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Percentage of column which will be droped\",(data.size - data[data[200] == 0].size)/data.size,\"%\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of column which will be droped 0.48746730083234247 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktKi_hPWqr5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data[data.iloc[:, -1] != 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGpof4FQcQXQ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cShDTWysqr5W",
        "colab_type": "text"
      },
      "source": [
        "### Spliting the data into feature and target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go8a2eIMqr5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMEDNN3_1ctn",
        "colab_type": "text"
      },
      "source": [
        "### Correlation between the features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGy8ax6u1byo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.figure(figsize=(150, 200))\n",
        "# sns.heatmap(X.corr(), annot=True, vmin=-1, vmax=1, center= 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKLpBTla_ErW",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcA_i82K-rM-",
        "colab_type": "text"
      },
      "source": [
        "### Feature Selection\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jie3RWu-_ee3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
        "\n",
        "X = SelectKBest(f_classif, k=150).fit_transform(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktbZr3Leo99F",
        "colab_type": "text"
      },
      "source": [
        "### OneHotEncoding the target column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VRfB2AicayJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "onehotencoder = OneHotEncoder() \n",
        "y = onehotencoder.fit_transform(np.array(y).reshape(-1,1)).toarray() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oeXMTbgpITF",
        "colab_type": "text"
      },
      "source": [
        "### Standardizing the feature columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSFPgGw0pPam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = preprocessing.scale(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRtV7aDDqr5a",
        "colab_type": "text"
      },
      "source": [
        "### Spliting the data into training and testing set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DattLTVzqr5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1)#0.25 0.15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWY0TIQ1Wx3f",
        "colab_type": "code",
        "outputId": "b3b98be0-1142-406b-f7a4-c6aad8b1ab8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "model = POGA(numberOfParents=8, numParents=4, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, generationNumber=8)\n",
        "end = time.time()\n",
        "print('time taken', end-start)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generation 1 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 1 finished\n",
            "Generation 2 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 2 finished\n",
            "Generation 3 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 3 finished\n",
            "Generation 4 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 4 finished\n",
            "Generation 5 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 5 finished\n",
            "Generation 6 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 6 finished\n",
            "Generation 7 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 7 finished\n",
            "Generation 8 started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Generation 8 finished\n",
            "time taken 10821.245257854462\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZTsCSdGj8tq",
        "colab_type": "code",
        "outputId": "961e8ab4-228b-4d01-a23a-ebe5fadff083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "best_parameters = model.best_parameters()\n",
        "best_parameters"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.1,\n",
              " 'batch_size': 530,\n",
              " 'hidden_layer_sizes': [61, 149, 52, 69, 85],\n",
              " 'learning_rate_init': 0.001,\n",
              " 'n_iter_no_change': 401}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDkl6QWElPrA",
        "colab_type": "code",
        "outputId": "9b0d5a96-eb8d-4688-afe6-b2f607daba84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "import seaborn as sns \n",
        "sns.heatmap(model.score_list, annot=True, vmin=0, vmax=1, center= 0)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0aa1ff9fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc1LQ2MLqr5e",
        "colab_type": "text"
      },
      "source": [
        "## Preparing ANN model \n",
        "### Defining the model\n",
        "[Link to learn about the parameters](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWQgr4vtqr5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MLPClassifier(hidden_layer_sizes=tuple(best_parameters['hidden_layer_sizes']),\n",
        "                      activation='relu',\n",
        "                      solver='adam',\n",
        "                      alpha=best_parameters['alpha'],\n",
        "                      batch_size=best_parameters['batch_size'],\n",
        "                      learning_rate='constant',\n",
        "                      learning_rate_init=best_parameters['learning_rate_init'],\n",
        "                      power_t=0.5,\n",
        "                      max_iter=1000,\n",
        "                      shuffle=True,\n",
        "                      random_state=1,\n",
        "                      tol=0.0001,\n",
        "                      verbose=False,\n",
        "                      warm_start=True,\n",
        "                      momentum=0.9,\n",
        "                      nesterovs_momentum=True,\n",
        "                      early_stopping=False,\n",
        "                      validation_fraction=0.18,#0.33 0.18\n",
        "                      beta_1=0.9,\n",
        "                      beta_2=0.999,\n",
        "                      epsilon=1e-08,\n",
        "                      n_iter_no_change=best_parameters['n_iter_no_change'],\n",
        "                      max_fun=15000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XELwBndEqr5l",
        "colab_type": "text"
      },
      "source": [
        "### Fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVw238aeqr5m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "ede7cf96-4512-4e05-c564-be2b41b8e661"
      },
      "source": [
        "model.fit(X_train,y_train)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.1, batch_size=530, beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(61, 149, 52, 69, 85),\n",
              "              learning_rate='constant', learning_rate_init=0.001, max_fun=15000,\n",
              "              max_iter=1000, momentum=0.9, n_iter_no_change=401,\n",
              "              nesterovs_momentum=True, power_t=0.5, random_state=1,\n",
              "              shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.18,\n",
              "              verbose=False, warm_start=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX3r0ZE0qr5z",
        "colab_type": "text"
      },
      "source": [
        "## Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtnChScYqr6C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "134f95ca-87ab-4016-ee7c-5179ad6d8d71"
      },
      "source": [
        "model.score(X_train,y_train)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9998852026173803"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9qS2xN_qr5s",
        "colab_type": "text"
      },
      "source": [
        "# Prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6FWrIN8CkvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix,cohen_kappa_score\n",
        "prediction = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8yGpSWSiWpO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1ebb15c-a683-40d9-98d1-8351f2e24815"
      },
      "source": [
        "accuracy_score(y_test, prediction)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9161248374512354"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhLCi-ON7r3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c027b0e3-102a-4427-927c-ac4163c8b621"
      },
      "source": [
        "precision_score(y_test, prediction,average=\"weighted\")"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9335779335062789"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v2W84p57wok",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2400e1de-f317-49e8-87d7-a605d9c6f123"
      },
      "source": [
        "recall_score(y_test, prediction, average=\"weighted\")"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.922626788036411"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRLQYy2p7-pM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6182631-497a-4c3e-c9a1-2b0807963fd9"
      },
      "source": [
        "f1_score(y_test, prediction, average=\"weighted\")"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9274671309625515"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb9yuuRuO1Sy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09f2f6d9-dc6d-4d0c-ebf2-5e2039ab657b"
      },
      "source": [
        "cohen_kappa_score(y_test.argmax(axis=1), prediction.argmax(axis=1), labels=list(x for x in range(1,17)), weights=None, sample_weight=None)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9315264082354964"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKt6JroFRSV3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "b0527976-d63a-4431-fa18-fc460834e7db"
      },
      "source": [
        "print(classification_report(y_test, prediction, target_names=label_values))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                              precision    recall  f1-score   support\n",
            "\n",
            "                     Alfalfa       0.75      1.00      0.86         6\n",
            "                 Corn-notill       0.94      0.87      0.91       220\n",
            "                Corn-mintill       0.91      0.93      0.92       125\n",
            "                        Corn       0.91      0.76      0.83        42\n",
            "               Grass-pasture       0.96      0.93      0.94        72\n",
            "                 Grass-trees       0.98      1.00      0.99       105\n",
            "         Grass-pasture-mowed       1.00      0.75      0.86         4\n",
            "               Hay-windrowed       0.99      0.97      0.98        71\n",
            "                        Oats       1.00      1.00      1.00         2\n",
            "              Soybean-notill       0.93      0.94      0.94       143\n",
            "             Soybean-mintill       0.92      0.93      0.92       359\n",
            "               Soybean-clean       0.96      0.94      0.95       105\n",
            "                       Wheat       1.00      1.00      1.00        28\n",
            "                       Woods       0.93      0.95      0.94       192\n",
            "Buildings-Grass-Trees-Drives       0.85      0.78      0.81        59\n",
            "          Stone-Steel-Towers       0.75      0.60      0.67         5\n",
            "\n",
            "                   micro avg       0.93      0.92      0.93      1538\n",
            "                   macro avg       0.92      0.90      0.91      1538\n",
            "                weighted avg       0.93      0.92      0.93      1538\n",
            "                 samples avg       0.92      0.92      0.92      1538\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}