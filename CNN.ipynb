{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN",
      "provenance": [],
      "authorship_tag": "ABX9TyPYffcnBVFQxRFGvdbwAGOv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srajan1122/Hyperspectral_Image_Classification/blob/srajan/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO-nUq2-KL7a",
        "colab_type": "code",
        "outputId": "5d7965c8-668c-441b-d63f-ea78a266dfaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXpp9_cwKqz1",
        "colab_type": "text"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVxnzfWvKN-K",
        "colab_type": "code",
        "outputId": "2830f458-e96f-4eac-9fe5-c975969adc39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder \n",
        "from sklearn import preprocessing\n",
        "import keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqasbIqPK0KM",
        "colab_type": "text"
      },
      "source": [
        "# Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erOp3hTTKuzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_dataset = io.loadmat('/content/drive/My Drive/Srajan/Internship/SEM4-LeadingindiaAI/Tasks/Datasets/PaviaU/PaviaU.mat')\n",
        "for key, value in loaded_dataset.items():\n",
        "  if isinstance(value, type(np.array([1]))):\n",
        "    image = loaded_dataset[key]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjbphR_nK5O8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ground_truth_1 = io.loadmat('/content/drive/My Drive/Srajan/Internship/SEM4-LeadingindiaAI/Tasks/Datasets/PaviaU/PaviaU_gt.mat')\n",
        "for key, value in ground_truth_1.items():\n",
        "  if isinstance(value, type(np.array([1]))):\n",
        "    ground_truth = ground_truth_1[key]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9l4ZElPK8xW",
        "colab_type": "text"
      },
      "source": [
        "## Class Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JumPKdTvK_EY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_values = [\"Alfalfa\", \"Corn-notill\", \"Corn-mintill\",\n",
        "                        \"Corn\", \"Grass-pasture\", \"Grass-trees\",\n",
        "                        \"Grass-pasture-mowed\", \"Hay-windrowed\", \"Oats\",\n",
        "                        \"Soybean-notill\", \"Soybean-mintill\", \"Soybean-clean\",\n",
        "                        \"Wheat\", \"Woods\", \"Buildings-Grass-Trees-Drives\",\n",
        "                        \"Stone-Steel-Towers\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYIFKIPmLCFV",
        "colab_type": "text"
      },
      "source": [
        "## Resizing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnRRsjn8K_zG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_with_gt = np.dstack((image, ground_truth))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2hhElWJLF9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_output = image_with_gt.reshape(ground_truth.size, image.shape[2]+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKGD0bRxLJff",
        "colab_type": "text"
      },
      "source": [
        "## Data Visualization in pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AWkTHdDLOwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.DataFrame(final_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ctUP_zKLUpJ",
        "colab_type": "code",
        "outputId": "12175ff5-f3de-4a90-e2e2-8b2c902030a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "      <th>101</th>\n",
              "      <th>102</th>\n",
              "      <th>103</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>647</td>\n",
              "      <td>499</td>\n",
              "      <td>464</td>\n",
              "      <td>371</td>\n",
              "      <td>291</td>\n",
              "      <td>319</td>\n",
              "      <td>365</td>\n",
              "      <td>322</td>\n",
              "      <td>296</td>\n",
              "      <td>305</td>\n",
              "      <td>277</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "      <td>222</td>\n",
              "      <td>201</td>\n",
              "      <td>162</td>\n",
              "      <td>157</td>\n",
              "      <td>183</td>\n",
              "      <td>204</td>\n",
              "      <td>194</td>\n",
              "      <td>198</td>\n",
              "      <td>216</td>\n",
              "      <td>249</td>\n",
              "      <td>284</td>\n",
              "      <td>294</td>\n",
              "      <td>322</td>\n",
              "      <td>338</td>\n",
              "      <td>342</td>\n",
              "      <td>336</td>\n",
              "      <td>342</td>\n",
              "      <td>362</td>\n",
              "      <td>365</td>\n",
              "      <td>348</td>\n",
              "      <td>341</td>\n",
              "      <td>324</td>\n",
              "      <td>316</td>\n",
              "      <td>293</td>\n",
              "      <td>274</td>\n",
              "      <td>251</td>\n",
              "      <td>244</td>\n",
              "      <td>...</td>\n",
              "      <td>192</td>\n",
              "      <td>227</td>\n",
              "      <td>287</td>\n",
              "      <td>376</td>\n",
              "      <td>493</td>\n",
              "      <td>633</td>\n",
              "      <td>763</td>\n",
              "      <td>913</td>\n",
              "      <td>1149</td>\n",
              "      <td>1442</td>\n",
              "      <td>1759</td>\n",
              "      <td>2102</td>\n",
              "      <td>2425</td>\n",
              "      <td>2689</td>\n",
              "      <td>2895</td>\n",
              "      <td>3058</td>\n",
              "      <td>3196</td>\n",
              "      <td>3252</td>\n",
              "      <td>3195</td>\n",
              "      <td>3297</td>\n",
              "      <td>3542</td>\n",
              "      <td>3550</td>\n",
              "      <td>3537</td>\n",
              "      <td>3545</td>\n",
              "      <td>3514</td>\n",
              "      <td>3477</td>\n",
              "      <td>3468</td>\n",
              "      <td>3433</td>\n",
              "      <td>3408</td>\n",
              "      <td>3420</td>\n",
              "      <td>3416</td>\n",
              "      <td>3335</td>\n",
              "      <td>3256</td>\n",
              "      <td>3226</td>\n",
              "      <td>3205</td>\n",
              "      <td>3210</td>\n",
              "      <td>3221</td>\n",
              "      <td>3238</td>\n",
              "      <td>3250</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>604</td>\n",
              "      <td>546</td>\n",
              "      <td>527</td>\n",
              "      <td>455</td>\n",
              "      <td>378</td>\n",
              "      <td>377</td>\n",
              "      <td>336</td>\n",
              "      <td>314</td>\n",
              "      <td>324</td>\n",
              "      <td>329</td>\n",
              "      <td>328</td>\n",
              "      <td>326</td>\n",
              "      <td>275</td>\n",
              "      <td>215</td>\n",
              "      <td>197</td>\n",
              "      <td>217</td>\n",
              "      <td>239</td>\n",
              "      <td>258</td>\n",
              "      <td>246</td>\n",
              "      <td>233</td>\n",
              "      <td>241</td>\n",
              "      <td>261</td>\n",
              "      <td>279</td>\n",
              "      <td>300</td>\n",
              "      <td>329</td>\n",
              "      <td>344</td>\n",
              "      <td>341</td>\n",
              "      <td>362</td>\n",
              "      <td>362</td>\n",
              "      <td>367</td>\n",
              "      <td>368</td>\n",
              "      <td>359</td>\n",
              "      <td>345</td>\n",
              "      <td>344</td>\n",
              "      <td>327</td>\n",
              "      <td>302</td>\n",
              "      <td>281</td>\n",
              "      <td>271</td>\n",
              "      <td>270</td>\n",
              "      <td>261</td>\n",
              "      <td>...</td>\n",
              "      <td>152</td>\n",
              "      <td>190</td>\n",
              "      <td>242</td>\n",
              "      <td>301</td>\n",
              "      <td>391</td>\n",
              "      <td>505</td>\n",
              "      <td>633</td>\n",
              "      <td>774</td>\n",
              "      <td>960</td>\n",
              "      <td>1191</td>\n",
              "      <td>1454</td>\n",
              "      <td>1737</td>\n",
              "      <td>2001</td>\n",
              "      <td>2209</td>\n",
              "      <td>2363</td>\n",
              "      <td>2484</td>\n",
              "      <td>2594</td>\n",
              "      <td>2613</td>\n",
              "      <td>2541</td>\n",
              "      <td>2588</td>\n",
              "      <td>2821</td>\n",
              "      <td>2839</td>\n",
              "      <td>2738</td>\n",
              "      <td>2690</td>\n",
              "      <td>2678</td>\n",
              "      <td>2673</td>\n",
              "      <td>2712</td>\n",
              "      <td>2725</td>\n",
              "      <td>2657</td>\n",
              "      <td>2605</td>\n",
              "      <td>2583</td>\n",
              "      <td>2538</td>\n",
              "      <td>2509</td>\n",
              "      <td>2511</td>\n",
              "      <td>2501</td>\n",
              "      <td>2468</td>\n",
              "      <td>2442</td>\n",
              "      <td>2464</td>\n",
              "      <td>2528</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>621</td>\n",
              "      <td>746</td>\n",
              "      <td>556</td>\n",
              "      <td>360</td>\n",
              "      <td>285</td>\n",
              "      <td>300</td>\n",
              "      <td>274</td>\n",
              "      <td>276</td>\n",
              "      <td>332</td>\n",
              "      <td>319</td>\n",
              "      <td>278</td>\n",
              "      <td>255</td>\n",
              "      <td>232</td>\n",
              "      <td>207</td>\n",
              "      <td>210</td>\n",
              "      <td>209</td>\n",
              "      <td>168</td>\n",
              "      <td>139</td>\n",
              "      <td>137</td>\n",
              "      <td>154</td>\n",
              "      <td>168</td>\n",
              "      <td>202</td>\n",
              "      <td>225</td>\n",
              "      <td>231</td>\n",
              "      <td>244</td>\n",
              "      <td>257</td>\n",
              "      <td>263</td>\n",
              "      <td>262</td>\n",
              "      <td>266</td>\n",
              "      <td>276</td>\n",
              "      <td>285</td>\n",
              "      <td>291</td>\n",
              "      <td>285</td>\n",
              "      <td>272</td>\n",
              "      <td>271</td>\n",
              "      <td>241</td>\n",
              "      <td>208</td>\n",
              "      <td>194</td>\n",
              "      <td>179</td>\n",
              "      <td>157</td>\n",
              "      <td>...</td>\n",
              "      <td>116</td>\n",
              "      <td>153</td>\n",
              "      <td>188</td>\n",
              "      <td>243</td>\n",
              "      <td>322</td>\n",
              "      <td>413</td>\n",
              "      <td>492</td>\n",
              "      <td>591</td>\n",
              "      <td>737</td>\n",
              "      <td>933</td>\n",
              "      <td>1125</td>\n",
              "      <td>1327</td>\n",
              "      <td>1519</td>\n",
              "      <td>1666</td>\n",
              "      <td>1790</td>\n",
              "      <td>1934</td>\n",
              "      <td>2029</td>\n",
              "      <td>2034</td>\n",
              "      <td>2010</td>\n",
              "      <td>2069</td>\n",
              "      <td>2191</td>\n",
              "      <td>2233</td>\n",
              "      <td>2245</td>\n",
              "      <td>2249</td>\n",
              "      <td>2255</td>\n",
              "      <td>2250</td>\n",
              "      <td>2249</td>\n",
              "      <td>2239</td>\n",
              "      <td>2239</td>\n",
              "      <td>2282</td>\n",
              "      <td>2288</td>\n",
              "      <td>2242</td>\n",
              "      <td>2193</td>\n",
              "      <td>2202</td>\n",
              "      <td>2225</td>\n",
              "      <td>2266</td>\n",
              "      <td>2308</td>\n",
              "      <td>2345</td>\n",
              "      <td>2361</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>637</td>\n",
              "      <td>592</td>\n",
              "      <td>482</td>\n",
              "      <td>556</td>\n",
              "      <td>508</td>\n",
              "      <td>284</td>\n",
              "      <td>178</td>\n",
              "      <td>198</td>\n",
              "      <td>193</td>\n",
              "      <td>224</td>\n",
              "      <td>217</td>\n",
              "      <td>215</td>\n",
              "      <td>187</td>\n",
              "      <td>161</td>\n",
              "      <td>152</td>\n",
              "      <td>136</td>\n",
              "      <td>124</td>\n",
              "      <td>122</td>\n",
              "      <td>127</td>\n",
              "      <td>126</td>\n",
              "      <td>125</td>\n",
              "      <td>123</td>\n",
              "      <td>147</td>\n",
              "      <td>188</td>\n",
              "      <td>208</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "      <td>206</td>\n",
              "      <td>219</td>\n",
              "      <td>235</td>\n",
              "      <td>238</td>\n",
              "      <td>227</td>\n",
              "      <td>217</td>\n",
              "      <td>215</td>\n",
              "      <td>216</td>\n",
              "      <td>201</td>\n",
              "      <td>190</td>\n",
              "      <td>167</td>\n",
              "      <td>149</td>\n",
              "      <td>162</td>\n",
              "      <td>...</td>\n",
              "      <td>129</td>\n",
              "      <td>174</td>\n",
              "      <td>245</td>\n",
              "      <td>338</td>\n",
              "      <td>455</td>\n",
              "      <td>585</td>\n",
              "      <td>720</td>\n",
              "      <td>850</td>\n",
              "      <td>1013</td>\n",
              "      <td>1225</td>\n",
              "      <td>1460</td>\n",
              "      <td>1702</td>\n",
              "      <td>1938</td>\n",
              "      <td>2157</td>\n",
              "      <td>2317</td>\n",
              "      <td>2433</td>\n",
              "      <td>2525</td>\n",
              "      <td>2552</td>\n",
              "      <td>2493</td>\n",
              "      <td>2554</td>\n",
              "      <td>2733</td>\n",
              "      <td>2781</td>\n",
              "      <td>2748</td>\n",
              "      <td>2748</td>\n",
              "      <td>2737</td>\n",
              "      <td>2710</td>\n",
              "      <td>2681</td>\n",
              "      <td>2642</td>\n",
              "      <td>2645</td>\n",
              "      <td>2684</td>\n",
              "      <td>2675</td>\n",
              "      <td>2609</td>\n",
              "      <td>2541</td>\n",
              "      <td>2551</td>\n",
              "      <td>2571</td>\n",
              "      <td>2569</td>\n",
              "      <td>2573</td>\n",
              "      <td>2620</td>\n",
              "      <td>2644</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>625</td>\n",
              "      <td>560</td>\n",
              "      <td>480</td>\n",
              "      <td>360</td>\n",
              "      <td>377</td>\n",
              "      <td>341</td>\n",
              "      <td>264</td>\n",
              "      <td>208</td>\n",
              "      <td>231</td>\n",
              "      <td>266</td>\n",
              "      <td>207</td>\n",
              "      <td>154</td>\n",
              "      <td>123</td>\n",
              "      <td>95</td>\n",
              "      <td>106</td>\n",
              "      <td>102</td>\n",
              "      <td>101</td>\n",
              "      <td>123</td>\n",
              "      <td>154</td>\n",
              "      <td>170</td>\n",
              "      <td>191</td>\n",
              "      <td>210</td>\n",
              "      <td>216</td>\n",
              "      <td>256</td>\n",
              "      <td>289</td>\n",
              "      <td>325</td>\n",
              "      <td>348</td>\n",
              "      <td>357</td>\n",
              "      <td>361</td>\n",
              "      <td>362</td>\n",
              "      <td>363</td>\n",
              "      <td>370</td>\n",
              "      <td>386</td>\n",
              "      <td>369</td>\n",
              "      <td>344</td>\n",
              "      <td>331</td>\n",
              "      <td>312</td>\n",
              "      <td>308</td>\n",
              "      <td>288</td>\n",
              "      <td>263</td>\n",
              "      <td>...</td>\n",
              "      <td>173</td>\n",
              "      <td>220</td>\n",
              "      <td>292</td>\n",
              "      <td>382</td>\n",
              "      <td>488</td>\n",
              "      <td>592</td>\n",
              "      <td>692</td>\n",
              "      <td>834</td>\n",
              "      <td>1032</td>\n",
              "      <td>1236</td>\n",
              "      <td>1461</td>\n",
              "      <td>1698</td>\n",
              "      <td>1876</td>\n",
              "      <td>2007</td>\n",
              "      <td>2118</td>\n",
              "      <td>2213</td>\n",
              "      <td>2288</td>\n",
              "      <td>2267</td>\n",
              "      <td>2192</td>\n",
              "      <td>2274</td>\n",
              "      <td>2448</td>\n",
              "      <td>2454</td>\n",
              "      <td>2387</td>\n",
              "      <td>2388</td>\n",
              "      <td>2441</td>\n",
              "      <td>2435</td>\n",
              "      <td>2454</td>\n",
              "      <td>2457</td>\n",
              "      <td>2430</td>\n",
              "      <td>2423</td>\n",
              "      <td>2392</td>\n",
              "      <td>2344</td>\n",
              "      <td>2289</td>\n",
              "      <td>2328</td>\n",
              "      <td>2415</td>\n",
              "      <td>2424</td>\n",
              "      <td>2386</td>\n",
              "      <td>2431</td>\n",
              "      <td>2456</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 104 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1    2    3    4    5    6    ...   97    98    99    100   101   102  103\n",
              "0  647  499  464  371  291  319  365  ...  3226  3205  3210  3221  3238  3250    0\n",
              "1  604  546  527  455  378  377  336  ...  2511  2501  2468  2442  2464  2528    0\n",
              "2  621  746  556  360  285  300  274  ...  2202  2225  2266  2308  2345  2361    0\n",
              "3  637  592  482  556  508  284  178  ...  2551  2571  2569  2573  2620  2644    0\n",
              "4  625  560  480  360  377  341  264  ...  2328  2415  2424  2386  2431  2456    0\n",
              "\n",
              "[5 rows x 104 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLWjsfqaLZs0",
        "colab_type": "text"
      },
      "source": [
        "## Droping the rows if ground truth value is zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlyctDjwLYkb",
        "colab_type": "code",
        "outputId": "964d42de-ca34-4e23-c44a-b07bfb26f9ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Percentage of column which will be droped\",(data.size - data[data.iloc[:, -1] == 0].size)/data.size,\"%\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of column which will be droped 0.20624879459980713 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tJ0vUTCLhZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zero_data = data.index[data.iloc[:, -1] == 0].tolist()\n",
        "data = data[data.iloc[:, -1] != 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE5Gc8BTLiAN",
        "colab_type": "text"
      },
      "source": [
        "# Spliting the data into feature and target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ4dCIbILrwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBvQ4xnt6tQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number_of_classes = len(np.unique(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHPv8SimL1Iu",
        "colab_type": "text"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aMaE8k8L0VV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
        "\n",
        "X = SelectKBest(f_classif, k=int((image.shape[2]+1)*0.75)).fit_transform(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCO0t_-J0G6J",
        "colab_type": "text"
      },
      "source": [
        "# Feature Extraction \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIjIpV160KKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.decomposition import PCA \n",
        "\n",
        "# pca = PCA(n_components = int((image.shape[2]+1)*0.75))\n",
        "# X = pca.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fijfR_5DL9IK",
        "colab_type": "text"
      },
      "source": [
        "# OneHotEncoding in target column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QoUCdAwMBAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "onehotencoder = OneHotEncoder() \n",
        "y = onehotencoder.fit_transform(np.array(y).reshape(-1,1)).toarray() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlNWTtSVMEjl",
        "colab_type": "text"
      },
      "source": [
        "# Standardizing the feature columna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPshPrqEMJvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = preprocessing.scale(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRtV7aDDqr5a",
        "colab_type": "text"
      },
      "source": [
        "# Spliting the data into training and testing set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DattLTVzqr5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=1)#0.25 0.15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OngDFGdDdPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number = int(X_test.shape[0]/2)\n",
        "\n",
        "xx_test = X_test[:number, :]\n",
        "xx_val = X_test[number:, :]\n",
        "\n",
        "if len(y_test.shape) > 1:\n",
        "  loss = keras.losses.categorical_crossentropy\n",
        "  metrics=['accuracy']\n",
        "  yy_test = y_test[:number, :]\n",
        "  yy_val = y_test[number:, :]\n",
        "else:\n",
        "  loss = keras.losses.sparse_categorical_crossentropy\n",
        "  metrics=['sparse_categorical_accuracy']\n",
        "  y_test = [x - 1 for x in y_test]\n",
        "  y_train = [x - 1 for x in y_train]\n",
        "  yy_test = y_test[:number]\n",
        "  yy_val = y_test[number:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M33_KnJNu7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "feature = X.shape[1]\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    X = X.reshape(X.shape[0], 1, feature)\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, feature)\n",
        "    xx_test = xx_test.reshape(xx_test.shape[0], 1, feature)\n",
        "    xx_val = xx_val.reshape(xx_val.shape[0], 1, feature)\n",
        "    input_shape = (1, feature)\n",
        "else:\n",
        "    X = X.reshape(X.shape[0], feature, 1)\n",
        "    X_train = X_train.reshape(X_train.shape[0], feature, 1)\n",
        "    xx_test = xx_test.reshape(xx_test.shape[0], feature, 1)\n",
        "    xx_val = xx_val.reshape(xx_val.shape[0], feature, 1)\n",
        "    input_shape = (feature, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQLkUnZ_YsYO",
        "colab_type": "text"
      },
      "source": [
        "# Genetic Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-9MDtAugFbk",
        "colab_type": "code",
        "outputId": "d30b7c06-542a-4971-d0dd-56db46ebb6f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install pyeasyga"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyeasyga in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pyeasyga) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlapBK49M2QU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D, BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bAr5dYIYrxF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ac1e240c-679e-44a3-bd49-3df7a8b9e1b7"
      },
      "source": [
        "from pyeasyga import pyeasyga\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import keras\n",
        "import time\n",
        "\n",
        "count = 1\n",
        "\n",
        "def initilialize_population():\n",
        "    filter_1 = list(x for x in range(1, 11))\n",
        "    filter_2 = list(x for x in range(11, 31))\n",
        "    filter_3 = list(x for x in range(31, 61))\n",
        "    filter_4 = list(x for x in range(61, 101))\n",
        "\n",
        "    kernel_size_1 = [2,3]\n",
        "    kernel_size_2 = [2,3]\n",
        "    kernel_size_3 = [2,3]\n",
        "    kernel_size_4 = [2,3]\n",
        "\n",
        "\n",
        "    population = []\n",
        "    population.append(filter_1)\n",
        "    population.append(filter_2)\n",
        "    population.append(filter_3)\n",
        "    population.append(filter_4)\n",
        "    population.append(kernel_size_1)\n",
        "    population.append(kernel_size_2)\n",
        "    population.append(kernel_size_3)\n",
        "    population.append(kernel_size_4)\n",
        "\n",
        "    return list(population)\n",
        "\n",
        "def create_individual(data):\n",
        "  choice = []\n",
        "  for i in range(len(data)):\n",
        "    choice.append(random.choice(list(range(len(data[i])))))\n",
        "  return choice\n",
        "\n",
        "def fitness_function(individual, data):\n",
        "  global count\n",
        "  print('Individual no', count)\n",
        "  count += 1\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(filters=data[0][individual[0]], kernel_size=data[4][individual[4]], activation='relu', input_shape=input_shape))\n",
        "  model.add(Conv1D(filters=data[0][individual[0]], kernel_size=data[4][individual[4]], activation='relu', input_shape=input_shape))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Conv1D(filters=data[1][individual[1]], kernel_size=data[5][individual[5]], activation='relu'))\n",
        "  model.add(Conv1D(filters=data[1][individual[1]], kernel_size=data[5][individual[5]], activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Conv1D(filters=data[2][individual[2]], kernel_size=data[6][individual[6]], activation='relu'))\n",
        "  model.add(Conv1D(filters=data[2][individual[2]], kernel_size=data[6][individual[6]], activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Conv1D(filters=data[3][individual[3]], kernel_size=data[7][individual[7]], activation='relu'))\n",
        "  model.add(Conv1D(filters=data[3][individual[3]], kernel_size=data[7][individual[7]], activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(number_of_classes, activation='softmax'))\n",
        "\n",
        "  model.compile(loss=loss,\n",
        "                optimizer=keras.optimizers.Adadelta(),\n",
        "                metrics=metrics)\n",
        "\n",
        "  model.fit(X_train, np.array(y_train),\n",
        "            batch_size=128,\n",
        "            epochs=25,\n",
        "            verbose=1,\n",
        "            validation_data=(xx_val,np.array(yy_val)))\n",
        "\n",
        "\n",
        "  score = model.evaluate(xx_test, np.array(yy_test), verbose=1)[1]\n",
        "  # prediction = model.predict(X_test)\n",
        "  # score = accuracy_score(y_test, prediction)\n",
        "  print('Score is', score)\n",
        "  return score\n",
        "  \n",
        "data = initilialize_population()\n",
        "ga = pyeasyga.GeneticAlgorithm(seed_data=data,\n",
        "                               population_size=5,\n",
        "                               generations=5,\n",
        "                               crossover_probability=0.8,\n",
        "                               mutation_probability=0.4,\n",
        "                               elitism=True,\n",
        "                               maximise_fitness=True)\n",
        "ga.create_individual = create_individual\n",
        "ga.fitness_function = fitness_function\n",
        "\n",
        "start = time.time()\n",
        "ga.run()\n",
        "end = time.time()\n",
        "print('Time taken ------>', end-start)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Individual no 1\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 8s 452us/step - loss: 1.1888 - accuracy: 0.6167 - val_loss: 2.0438 - val_accuracy: 0.4304\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 6s 354us/step - loss: 0.7519 - accuracy: 0.7429 - val_loss: 1.7998 - val_accuracy: 0.4997\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 6s 357us/step - loss: 0.6536 - accuracy: 0.7669 - val_loss: 0.8465 - val_accuracy: 0.7015\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 6s 359us/step - loss: 0.5950 - accuracy: 0.7774 - val_loss: 0.6005 - val_accuracy: 0.7612\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 6s 358us/step - loss: 0.5380 - accuracy: 0.7980 - val_loss: 0.4385 - val_accuracy: 0.8247\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 6s 361us/step - loss: 0.4986 - accuracy: 0.8113 - val_loss: 0.4410 - val_accuracy: 0.8208\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 6s 369us/step - loss: 0.4590 - accuracy: 0.8283 - val_loss: 0.4081 - val_accuracy: 0.8229\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 6s 362us/step - loss: 0.4354 - accuracy: 0.8398 - val_loss: 0.3257 - val_accuracy: 0.8728\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 6s 350us/step - loss: 0.3989 - accuracy: 0.8542 - val_loss: 0.3269 - val_accuracy: 0.8746\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 6s 350us/step - loss: 0.3691 - accuracy: 0.8700 - val_loss: 0.3230 - val_accuracy: 0.8896\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 6s 352us/step - loss: 0.3541 - accuracy: 0.8770 - val_loss: 0.2930 - val_accuracy: 0.8959\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 6s 356us/step - loss: 0.3367 - accuracy: 0.8841 - val_loss: 0.2842 - val_accuracy: 0.8964\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 6s 359us/step - loss: 0.3322 - accuracy: 0.8842 - val_loss: 0.4324 - val_accuracy: 0.8516\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 6s 373us/step - loss: 0.3025 - accuracy: 0.8963 - val_loss: 0.2719 - val_accuracy: 0.8971\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 6s 376us/step - loss: 0.2939 - accuracy: 0.8987 - val_loss: 0.2739 - val_accuracy: 0.8984\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 6s 371us/step - loss: 0.2772 - accuracy: 0.9040 - val_loss: 0.2908 - val_accuracy: 0.8959\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 6s 364us/step - loss: 0.2793 - accuracy: 0.9047 - val_loss: 0.2904 - val_accuracy: 0.9016\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 6s 360us/step - loss: 0.2717 - accuracy: 0.9085 - val_loss: 0.2712 - val_accuracy: 0.9024\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 6s 362us/step - loss: 0.2678 - accuracy: 0.9054 - val_loss: 0.2375 - val_accuracy: 0.9155\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 6s 368us/step - loss: 0.2513 - accuracy: 0.9146 - val_loss: 0.2412 - val_accuracy: 0.9139\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 6s 364us/step - loss: 0.2500 - accuracy: 0.9151 - val_loss: 0.2234 - val_accuracy: 0.9203\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 6s 355us/step - loss: 0.2420 - accuracy: 0.9150 - val_loss: 0.5390 - val_accuracy: 0.8229\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 6s 359us/step - loss: 0.2390 - accuracy: 0.9185 - val_loss: 0.2492 - val_accuracy: 0.9124\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 6s 361us/step - loss: 0.2300 - accuracy: 0.9222 - val_loss: 0.3456 - val_accuracy: 0.8640\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 6s 355us/step - loss: 0.2289 - accuracy: 0.9231 - val_loss: 0.2470 - val_accuracy: 0.9108\n",
            "12833/12833 [==============================] - 2s 118us/step\n",
            "Score is 0.9197381734848022\n",
            "Individual no 2\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 7s 386us/step - loss: 1.2693 - accuracy: 0.5943 - val_loss: 1.8847 - val_accuracy: 0.4449\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.7680 - accuracy: 0.7380 - val_loss: 1.9849 - val_accuracy: 0.2990\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.6521 - accuracy: 0.7624 - val_loss: 0.7779 - val_accuracy: 0.7352\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 5s 297us/step - loss: 0.5838 - accuracy: 0.7923 - val_loss: 0.4583 - val_accuracy: 0.8045\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.5281 - accuracy: 0.8084 - val_loss: 0.4663 - val_accuracy: 0.8166\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.4791 - accuracy: 0.8255 - val_loss: 0.4018 - val_accuracy: 0.8392\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.4538 - accuracy: 0.8330 - val_loss: 0.3694 - val_accuracy: 0.8565\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.4128 - accuracy: 0.8515 - val_loss: 0.3168 - val_accuracy: 0.8750\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.3780 - accuracy: 0.8686 - val_loss: 0.3142 - val_accuracy: 0.8733\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.3653 - accuracy: 0.8755 - val_loss: 0.3418 - val_accuracy: 0.8756\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.3401 - accuracy: 0.8836 - val_loss: 0.2880 - val_accuracy: 0.8905\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 5s 297us/step - loss: 0.3245 - accuracy: 0.8883 - val_loss: 0.2508 - val_accuracy: 0.9086\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.3184 - accuracy: 0.8885 - val_loss: 0.3426 - val_accuracy: 0.8755\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.2992 - accuracy: 0.8987 - val_loss: 0.2835 - val_accuracy: 0.8992\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2863 - accuracy: 0.9032 - val_loss: 0.3054 - val_accuracy: 0.8952\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 5s 305us/step - loss: 0.2880 - accuracy: 0.9048 - val_loss: 0.2558 - val_accuracy: 0.9090\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.2764 - accuracy: 0.9086 - val_loss: 0.2399 - val_accuracy: 0.9102\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 5s 299us/step - loss: 0.2725 - accuracy: 0.9096 - val_loss: 0.2644 - val_accuracy: 0.9078\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2664 - accuracy: 0.9120 - val_loss: 0.3137 - val_accuracy: 0.9015\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2592 - accuracy: 0.9140 - val_loss: 0.2534 - val_accuracy: 0.9105\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 5s 309us/step - loss: 0.2549 - accuracy: 0.9150 - val_loss: 0.2626 - val_accuracy: 0.9116\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 5s 308us/step - loss: 0.2490 - accuracy: 0.9184 - val_loss: 0.2215 - val_accuracy: 0.9192\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 5s 306us/step - loss: 0.2398 - accuracy: 0.9198 - val_loss: 0.2217 - val_accuracy: 0.9204\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 5s 308us/step - loss: 0.2380 - accuracy: 0.9230 - val_loss: 0.2756 - val_accuracy: 0.9056\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 5s 306us/step - loss: 0.2341 - accuracy: 0.9237 - val_loss: 0.2495 - val_accuracy: 0.9130\n",
            "12833/12833 [==============================] - 1s 103us/step\n",
            "Score is 0.9175562858581543\n",
            "Individual no 3\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 7s 391us/step - loss: 1.1668 - accuracy: 0.6223 - val_loss: 2.3208 - val_accuracy: 0.4322\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.7602 - accuracy: 0.7337 - val_loss: 2.0205 - val_accuracy: 0.4823\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.6679 - accuracy: 0.7579 - val_loss: 0.8508 - val_accuracy: 0.7227\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 5s 299us/step - loss: 0.6057 - accuracy: 0.7738 - val_loss: 0.5295 - val_accuracy: 0.8000\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 5s 297us/step - loss: 0.5592 - accuracy: 0.7914 - val_loss: 0.5806 - val_accuracy: 0.7632\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 5s 299us/step - loss: 0.5109 - accuracy: 0.8057 - val_loss: 0.4302 - val_accuracy: 0.8170\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.4541 - accuracy: 0.8301 - val_loss: 0.4361 - val_accuracy: 0.8324\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.4328 - accuracy: 0.8413 - val_loss: 0.4880 - val_accuracy: 0.8020\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.3965 - accuracy: 0.8561 - val_loss: 0.3078 - val_accuracy: 0.8876\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 5s 306us/step - loss: 0.3734 - accuracy: 0.8662 - val_loss: 0.3839 - val_accuracy: 0.8554\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 5s 306us/step - loss: 0.3583 - accuracy: 0.8746 - val_loss: 0.3091 - val_accuracy: 0.8840\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.3439 - accuracy: 0.8769 - val_loss: 0.3300 - val_accuracy: 0.8740\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.3184 - accuracy: 0.8877 - val_loss: 0.2656 - val_accuracy: 0.9020\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.3096 - accuracy: 0.8914 - val_loss: 0.2390 - val_accuracy: 0.9157\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 5s 299us/step - loss: 0.2937 - accuracy: 0.8999 - val_loss: 0.2789 - val_accuracy: 0.9024\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.2881 - accuracy: 0.9029 - val_loss: 0.2552 - val_accuracy: 0.8992\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.2863 - accuracy: 0.9057 - val_loss: 0.2399 - val_accuracy: 0.9099\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2709 - accuracy: 0.9083 - val_loss: 0.2500 - val_accuracy: 0.9123\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 5s 315us/step - loss: 0.2672 - accuracy: 0.9120 - val_loss: 0.2545 - val_accuracy: 0.9058\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 6s 324us/step - loss: 0.2528 - accuracy: 0.9135 - val_loss: 0.2279 - val_accuracy: 0.9169\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 5s 305us/step - loss: 0.2464 - accuracy: 0.9188 - val_loss: 0.2166 - val_accuracy: 0.9236\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 5s 307us/step - loss: 0.2388 - accuracy: 0.9214 - val_loss: 0.2369 - val_accuracy: 0.9155\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.2368 - accuracy: 0.9212 - val_loss: 0.3493 - val_accuracy: 0.8713\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.2304 - accuracy: 0.9218 - val_loss: 0.2204 - val_accuracy: 0.9184\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.2305 - accuracy: 0.9257 - val_loss: 0.2140 - val_accuracy: 0.9256\n",
            "12833/12833 [==============================] - 1s 106us/step\n",
            "Score is 0.9331411123275757\n",
            "Individual no 4\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 7s 419us/step - loss: 1.1685 - accuracy: 0.6140 - val_loss: 2.4690 - val_accuracy: 0.4304\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 5s 307us/step - loss: 0.7408 - accuracy: 0.7522 - val_loss: 2.8924 - val_accuracy: 0.4656\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 5s 309us/step - loss: 0.6547 - accuracy: 0.7648 - val_loss: 2.6789 - val_accuracy: 0.4827\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 5s 308us/step - loss: 0.5978 - accuracy: 0.7777 - val_loss: 1.0053 - val_accuracy: 0.6635\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 5s 309us/step - loss: 0.5486 - accuracy: 0.7988 - val_loss: 0.5229 - val_accuracy: 0.7844\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.5105 - accuracy: 0.8108 - val_loss: 0.4301 - val_accuracy: 0.8291\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 5s 307us/step - loss: 0.4834 - accuracy: 0.8238 - val_loss: 0.6555 - val_accuracy: 0.7403\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 5s 305us/step - loss: 0.4448 - accuracy: 0.8423 - val_loss: 0.5000 - val_accuracy: 0.8051\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 5s 309us/step - loss: 0.4171 - accuracy: 0.8563 - val_loss: 0.3772 - val_accuracy: 0.8610\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 5s 306us/step - loss: 0.3946 - accuracy: 0.8645 - val_loss: 0.3566 - val_accuracy: 0.8663\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.3770 - accuracy: 0.8708 - val_loss: 0.3773 - val_accuracy: 0.8668\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 5s 307us/step - loss: 0.3650 - accuracy: 0.8712 - val_loss: 0.3203 - val_accuracy: 0.8830\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.3481 - accuracy: 0.8763 - val_loss: 0.3307 - val_accuracy: 0.8837\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.3376 - accuracy: 0.8850 - val_loss: 0.3216 - val_accuracy: 0.8808\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.3246 - accuracy: 0.8904 - val_loss: 0.3847 - val_accuracy: 0.8729\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.3148 - accuracy: 0.8925 - val_loss: 0.3582 - val_accuracy: 0.8727\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.3041 - accuracy: 0.8977 - val_loss: 0.4690 - val_accuracy: 0.8487\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.2893 - accuracy: 0.9032 - val_loss: 0.4227 - val_accuracy: 0.8565\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.2944 - accuracy: 0.8996 - val_loss: 0.2939 - val_accuracy: 0.8918\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 5s 299us/step - loss: 0.2836 - accuracy: 0.9038 - val_loss: 0.3322 - val_accuracy: 0.8910\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.2808 - accuracy: 0.9070 - val_loss: 0.2746 - val_accuracy: 0.9027\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 5s 299us/step - loss: 0.2718 - accuracy: 0.9078 - val_loss: 0.2998 - val_accuracy: 0.8854\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.2568 - accuracy: 0.9137 - val_loss: 0.2635 - val_accuracy: 0.9046\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2610 - accuracy: 0.9116 - val_loss: 0.2498 - val_accuracy: 0.9139\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2489 - accuracy: 0.9184 - val_loss: 0.2469 - val_accuracy: 0.9102\n",
            "12833/12833 [==============================] - 1s 103us/step\n",
            "Score is 0.9160757660865784\n",
            "Individual no 5\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 7s 405us/step - loss: 1.1772 - accuracy: 0.6236 - val_loss: 2.4149 - val_accuracy: 0.4304\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 5s 321us/step - loss: 0.7321 - accuracy: 0.7543 - val_loss: 2.7231 - val_accuracy: 0.4550\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 5s 316us/step - loss: 0.6395 - accuracy: 0.7727 - val_loss: 1.8205 - val_accuracy: 0.5108\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 5s 315us/step - loss: 0.5655 - accuracy: 0.7958 - val_loss: 0.5894 - val_accuracy: 0.7860\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 5s 316us/step - loss: 0.5140 - accuracy: 0.8142 - val_loss: 0.8027 - val_accuracy: 0.6764\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 5s 314us/step - loss: 0.4688 - accuracy: 0.8298 - val_loss: 0.4682 - val_accuracy: 0.8024\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 5s 317us/step - loss: 0.4168 - accuracy: 0.8522 - val_loss: 0.3846 - val_accuracy: 0.8614\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 6s 329us/step - loss: 0.3852 - accuracy: 0.8653 - val_loss: 0.3780 - val_accuracy: 0.8613\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 6s 334us/step - loss: 0.3569 - accuracy: 0.8792 - val_loss: 0.2972 - val_accuracy: 0.8905\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 6s 330us/step - loss: 0.3355 - accuracy: 0.8863 - val_loss: 0.3235 - val_accuracy: 0.8893\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 6s 326us/step - loss: 0.3214 - accuracy: 0.8946 - val_loss: 0.4417 - val_accuracy: 0.8489\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 5s 319us/step - loss: 0.2968 - accuracy: 0.9031 - val_loss: 0.2773 - val_accuracy: 0.9055\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 6s 322us/step - loss: 0.2848 - accuracy: 0.9054 - val_loss: 0.3104 - val_accuracy: 0.8803\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 6s 325us/step - loss: 0.2789 - accuracy: 0.9077 - val_loss: 0.2537 - val_accuracy: 0.9111\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 6s 340us/step - loss: 0.2661 - accuracy: 0.9133 - val_loss: 0.3105 - val_accuracy: 0.8820\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 6s 359us/step - loss: 0.2577 - accuracy: 0.9170 - val_loss: 0.3186 - val_accuracy: 0.8915\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 6s 340us/step - loss: 0.2531 - accuracy: 0.9164 - val_loss: 0.3073 - val_accuracy: 0.9001\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 6s 335us/step - loss: 0.2300 - accuracy: 0.9233 - val_loss: 0.4409 - val_accuracy: 0.8279\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 6s 333us/step - loss: 0.2343 - accuracy: 0.9229 - val_loss: 0.2457 - val_accuracy: 0.9116\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 6s 338us/step - loss: 0.2215 - accuracy: 0.9298 - val_loss: 0.4324 - val_accuracy: 0.8437\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 6s 337us/step - loss: 0.2259 - accuracy: 0.9270 - val_loss: 0.2081 - val_accuracy: 0.9276\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 6s 337us/step - loss: 0.2158 - accuracy: 0.9293 - val_loss: 0.3671 - val_accuracy: 0.8737\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 6s 339us/step - loss: 0.2072 - accuracy: 0.9330 - val_loss: 0.2442 - val_accuracy: 0.9125\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 6s 348us/step - loss: 0.2083 - accuracy: 0.9318 - val_loss: 0.2380 - val_accuracy: 0.9210\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 6s 357us/step - loss: 0.1915 - accuracy: 0.9385 - val_loss: 0.2230 - val_accuracy: 0.9253\n",
            "12833/12833 [==============================] - 1s 104us/step\n",
            "Score is 0.9269071817398071\n",
            "Individual no 6\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 7s 405us/step - loss: 1.2589 - accuracy: 0.6093 - val_loss: 2.0911 - val_accuracy: 0.4304\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.7596 - accuracy: 0.7413 - val_loss: 2.4538 - val_accuracy: 0.4629\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.6543 - accuracy: 0.7658 - val_loss: 2.1707 - val_accuracy: 0.4765\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.5629 - accuracy: 0.7950 - val_loss: 0.6423 - val_accuracy: 0.7688\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.4957 - accuracy: 0.8194 - val_loss: 0.4523 - val_accuracy: 0.8230\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 5s 299us/step - loss: 0.4506 - accuracy: 0.8371 - val_loss: 0.3745 - val_accuracy: 0.8533\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.3994 - accuracy: 0.8615 - val_loss: 0.3271 - val_accuracy: 0.8767\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.3739 - accuracy: 0.8738 - val_loss: 0.3306 - val_accuracy: 0.8795\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.3468 - accuracy: 0.8819 - val_loss: 0.3057 - val_accuracy: 0.8893\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 5s 299us/step - loss: 0.3263 - accuracy: 0.8910 - val_loss: 0.3289 - val_accuracy: 0.8860\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.3002 - accuracy: 0.8981 - val_loss: 0.2989 - val_accuracy: 0.8942\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2859 - accuracy: 0.9044 - val_loss: 0.2949 - val_accuracy: 0.8964\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.2745 - accuracy: 0.9088 - val_loss: 0.2276 - val_accuracy: 0.9196\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.2592 - accuracy: 0.9134 - val_loss: 0.2717 - val_accuracy: 0.9095\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.2508 - accuracy: 0.9188 - val_loss: 0.3562 - val_accuracy: 0.8679\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.2572 - accuracy: 0.9157 - val_loss: 0.2185 - val_accuracy: 0.9194\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.2458 - accuracy: 0.9203 - val_loss: 0.2387 - val_accuracy: 0.9163\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2339 - accuracy: 0.9240 - val_loss: 0.3278 - val_accuracy: 0.8731\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2273 - accuracy: 0.9268 - val_loss: 0.2801 - val_accuracy: 0.8992\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.2222 - accuracy: 0.9271 - val_loss: 0.3970 - val_accuracy: 0.8533\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.2205 - accuracy: 0.9300 - val_loss: 0.2397 - val_accuracy: 0.9217\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.2050 - accuracy: 0.9317 - val_loss: 0.2012 - val_accuracy: 0.9313\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.2137 - accuracy: 0.9295 - val_loss: 0.2537 - val_accuracy: 0.9190\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2048 - accuracy: 0.9331 - val_loss: 0.2393 - val_accuracy: 0.9139\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.1996 - accuracy: 0.9341 - val_loss: 0.2420 - val_accuracy: 0.9195\n",
            "12833/12833 [==============================] - 1s 103us/step\n",
            "Score is 0.922933042049408\n",
            "Individual no 7\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 8s 445us/step - loss: 1.2467 - accuracy: 0.5994 - val_loss: 2.2750 - val_accuracy: 0.4304\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 6s 357us/step - loss: 0.7389 - accuracy: 0.7476 - val_loss: 2.3418 - val_accuracy: 0.4464\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 6s 357us/step - loss: 0.6358 - accuracy: 0.7737 - val_loss: 1.5037 - val_accuracy: 0.5737\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 6s 344us/step - loss: 0.5576 - accuracy: 0.7950 - val_loss: 0.6337 - val_accuracy: 0.7388\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 6s 342us/step - loss: 0.4977 - accuracy: 0.8160 - val_loss: 0.4790 - val_accuracy: 0.7954\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 6s 343us/step - loss: 0.4448 - accuracy: 0.8393 - val_loss: 0.3768 - val_accuracy: 0.8521\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 6s 346us/step - loss: 0.4076 - accuracy: 0.8538 - val_loss: 0.4661 - val_accuracy: 0.8219\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 6s 347us/step - loss: 0.3814 - accuracy: 0.8645 - val_loss: 0.4098 - val_accuracy: 0.8164\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 6s 353us/step - loss: 0.3441 - accuracy: 0.8812 - val_loss: 0.3265 - val_accuracy: 0.8779\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 6s 352us/step - loss: 0.3196 - accuracy: 0.8920 - val_loss: 0.2430 - val_accuracy: 0.9075\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 6s 349us/step - loss: 0.3021 - accuracy: 0.8980 - val_loss: 0.2546 - val_accuracy: 0.9100\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 6s 348us/step - loss: 0.2962 - accuracy: 0.9016 - val_loss: 0.2614 - val_accuracy: 0.9098\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 6s 349us/step - loss: 0.2892 - accuracy: 0.9052 - val_loss: 0.2492 - val_accuracy: 0.9121\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 6s 344us/step - loss: 0.2769 - accuracy: 0.9093 - val_loss: 0.2334 - val_accuracy: 0.9147\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 6s 347us/step - loss: 0.2618 - accuracy: 0.9147 - val_loss: 0.3060 - val_accuracy: 0.8917\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 6s 346us/step - loss: 0.2566 - accuracy: 0.9158 - val_loss: 0.4029 - val_accuracy: 0.8512\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 6s 345us/step - loss: 0.2476 - accuracy: 0.9173 - val_loss: 0.3390 - val_accuracy: 0.8862\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 6s 376us/step - loss: 0.2365 - accuracy: 0.9227 - val_loss: 0.2850 - val_accuracy: 0.9037\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 8s 448us/step - loss: 0.2347 - accuracy: 0.9255 - val_loss: 0.2186 - val_accuracy: 0.9256\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 6s 358us/step - loss: 0.2317 - accuracy: 0.9254 - val_loss: 0.2527 - val_accuracy: 0.9112\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 6s 358us/step - loss: 0.2258 - accuracy: 0.9254 - val_loss: 0.2352 - val_accuracy: 0.9200\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 6s 355us/step - loss: 0.2208 - accuracy: 0.9279 - val_loss: 0.2676 - val_accuracy: 0.9105\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 6s 359us/step - loss: 0.2159 - accuracy: 0.9321 - val_loss: 0.2047 - val_accuracy: 0.9304\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 6s 365us/step - loss: 0.2066 - accuracy: 0.9316 - val_loss: 0.2496 - val_accuracy: 0.9211\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 6s 365us/step - loss: 0.2055 - accuracy: 0.9344 - val_loss: 0.2380 - val_accuracy: 0.9160\n",
            "12833/12833 [==============================] - 2s 121us/step\n",
            "Score is 0.9251149296760559\n",
            "Individual no 8\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 8s 481us/step - loss: 1.1791 - accuracy: 0.6207 - val_loss: 2.3344 - val_accuracy: 0.4304\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 6s 361us/step - loss: 0.7463 - accuracy: 0.7477 - val_loss: 2.7259 - val_accuracy: 0.4661\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 6s 361us/step - loss: 0.6437 - accuracy: 0.7710 - val_loss: 2.0948 - val_accuracy: 0.4574\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 6s 361us/step - loss: 0.5759 - accuracy: 0.7883 - val_loss: 0.7620 - val_accuracy: 0.7190\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 6s 359us/step - loss: 0.5289 - accuracy: 0.7996 - val_loss: 0.4795 - val_accuracy: 0.7996\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 6s 358us/step - loss: 0.4872 - accuracy: 0.8134 - val_loss: 0.4061 - val_accuracy: 0.8233\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 6s 358us/step - loss: 0.4347 - accuracy: 0.8366 - val_loss: 0.3900 - val_accuracy: 0.8530\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 6s 359us/step - loss: 0.4040 - accuracy: 0.8513 - val_loss: 0.3223 - val_accuracy: 0.8804\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 6s 357us/step - loss: 0.3868 - accuracy: 0.8633 - val_loss: 0.4756 - val_accuracy: 0.8113\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 6s 357us/step - loss: 0.3599 - accuracy: 0.8747 - val_loss: 0.3003 - val_accuracy: 0.8911\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 6s 359us/step - loss: 0.3349 - accuracy: 0.8841 - val_loss: 0.3036 - val_accuracy: 0.8867\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 6s 359us/step - loss: 0.3201 - accuracy: 0.8889 - val_loss: 0.3719 - val_accuracy: 0.8435\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 6s 358us/step - loss: 0.3150 - accuracy: 0.8919 - val_loss: 0.3633 - val_accuracy: 0.8432\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 6s 360us/step - loss: 0.2965 - accuracy: 0.8970 - val_loss: 0.3872 - val_accuracy: 0.8636\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 6s 357us/step - loss: 0.2953 - accuracy: 0.8973 - val_loss: 0.3505 - val_accuracy: 0.8799\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 6s 357us/step - loss: 0.2854 - accuracy: 0.9037 - val_loss: 0.2606 - val_accuracy: 0.9070\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 6s 359us/step - loss: 0.2709 - accuracy: 0.9086 - val_loss: 0.2542 - val_accuracy: 0.9083\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 6s 359us/step - loss: 0.2744 - accuracy: 0.9076 - val_loss: 0.2915 - val_accuracy: 0.9017\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 6s 356us/step - loss: 0.2689 - accuracy: 0.9086 - val_loss: 0.3068 - val_accuracy: 0.8914\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 6s 356us/step - loss: 0.2605 - accuracy: 0.9106 - val_loss: 0.2323 - val_accuracy: 0.9140\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 6s 358us/step - loss: 0.2555 - accuracy: 0.9150 - val_loss: 0.2600 - val_accuracy: 0.9067\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 6s 360us/step - loss: 0.2572 - accuracy: 0.9163 - val_loss: 0.2519 - val_accuracy: 0.9066\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 6s 358us/step - loss: 0.2446 - accuracy: 0.9176 - val_loss: 0.2445 - val_accuracy: 0.9081\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 6s 357us/step - loss: 0.2383 - accuracy: 0.9195 - val_loss: 0.2413 - val_accuracy: 0.9113\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 6s 359us/step - loss: 0.2374 - accuracy: 0.9208 - val_loss: 0.3623 - val_accuracy: 0.8749\n",
            "12833/12833 [==============================] - 2s 119us/step\n",
            "Score is 0.8790618181228638\n",
            "Individual no 9\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 7s 415us/step - loss: 1.2449 - accuracy: 0.6029 - val_loss: 2.1201 - val_accuracy: 0.4410\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 5s 306us/step - loss: 0.7591 - accuracy: 0.7359 - val_loss: 2.3648 - val_accuracy: 0.4778\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 5s 311us/step - loss: 0.6653 - accuracy: 0.7588 - val_loss: 1.0678 - val_accuracy: 0.6239\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 5s 307us/step - loss: 0.6120 - accuracy: 0.7686 - val_loss: 0.5670 - val_accuracy: 0.7664\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 5s 306us/step - loss: 0.5644 - accuracy: 0.7864 - val_loss: 0.5670 - val_accuracy: 0.7770\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 5s 311us/step - loss: 0.5304 - accuracy: 0.7989 - val_loss: 0.4732 - val_accuracy: 0.8053\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 5s 315us/step - loss: 0.5138 - accuracy: 0.8048 - val_loss: 0.4176 - val_accuracy: 0.8194\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 5s 316us/step - loss: 0.4791 - accuracy: 0.8217 - val_loss: 0.4492 - val_accuracy: 0.8343\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 5s 315us/step - loss: 0.4443 - accuracy: 0.8376 - val_loss: 0.4991 - val_accuracy: 0.8051\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 5s 321us/step - loss: 0.4214 - accuracy: 0.8474 - val_loss: 0.3478 - val_accuracy: 0.8717\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 5s 316us/step - loss: 0.3928 - accuracy: 0.8603 - val_loss: 0.3466 - val_accuracy: 0.8682\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 5s 313us/step - loss: 0.3807 - accuracy: 0.8665 - val_loss: 0.3150 - val_accuracy: 0.8849\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 5s 309us/step - loss: 0.3642 - accuracy: 0.8731 - val_loss: 0.3164 - val_accuracy: 0.8852\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 5s 316us/step - loss: 0.3510 - accuracy: 0.8770 - val_loss: 0.2918 - val_accuracy: 0.8900\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 5s 310us/step - loss: 0.3378 - accuracy: 0.8809 - val_loss: 0.2887 - val_accuracy: 0.8953\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 5s 309us/step - loss: 0.3214 - accuracy: 0.8902 - val_loss: 0.3313 - val_accuracy: 0.8789\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 5s 317us/step - loss: 0.3260 - accuracy: 0.8854 - val_loss: 0.2627 - val_accuracy: 0.9007\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 5s 317us/step - loss: 0.3193 - accuracy: 0.8908 - val_loss: 0.3634 - val_accuracy: 0.8658\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 5s 311us/step - loss: 0.3046 - accuracy: 0.8944 - val_loss: 0.3018 - val_accuracy: 0.8930\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 5s 307us/step - loss: 0.2915 - accuracy: 0.8980 - val_loss: 0.3362 - val_accuracy: 0.8691\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 5s 309us/step - loss: 0.2876 - accuracy: 0.9008 - val_loss: 0.2646 - val_accuracy: 0.9041\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 5s 311us/step - loss: 0.2806 - accuracy: 0.9037 - val_loss: 0.2947 - val_accuracy: 0.8919\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 5s 313us/step - loss: 0.2780 - accuracy: 0.9039 - val_loss: 0.4358 - val_accuracy: 0.8146\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 5s 312us/step - loss: 0.2785 - accuracy: 0.9047 - val_loss: 0.2829 - val_accuracy: 0.8965\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 5s 318us/step - loss: 0.2684 - accuracy: 0.9095 - val_loss: 0.3538 - val_accuracy: 0.8778\n",
            "12833/12833 [==============================] - 1s 104us/step\n",
            "Score is 0.882568359375\n",
            "Individual no 10\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 8s 440us/step - loss: 1.2063 - accuracy: 0.6136 - val_loss: 2.4972 - val_accuracy: 0.4304\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 6s 375us/step - loss: 0.7357 - accuracy: 0.7523 - val_loss: 2.6199 - val_accuracy: 0.4510\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 6s 371us/step - loss: 0.6331 - accuracy: 0.7709 - val_loss: 1.6868 - val_accuracy: 0.4776\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 6s 355us/step - loss: 0.5668 - accuracy: 0.7921 - val_loss: 0.5746 - val_accuracy: 0.7710\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 6s 357us/step - loss: 0.5185 - accuracy: 0.8083 - val_loss: 0.4494 - val_accuracy: 0.8219\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 6s 344us/step - loss: 0.4683 - accuracy: 0.8250 - val_loss: 0.4235 - val_accuracy: 0.8360\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 6s 346us/step - loss: 0.4357 - accuracy: 0.8420 - val_loss: 0.3706 - val_accuracy: 0.8556\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 6s 358us/step - loss: 0.3999 - accuracy: 0.8565 - val_loss: 0.3575 - val_accuracy: 0.8615\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 6s 355us/step - loss: 0.3791 - accuracy: 0.8662 - val_loss: 0.3087 - val_accuracy: 0.8871\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 6s 359us/step - loss: 0.3546 - accuracy: 0.8789 - val_loss: 0.3112 - val_accuracy: 0.8815\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 6s 357us/step - loss: 0.3392 - accuracy: 0.8840 - val_loss: 0.3115 - val_accuracy: 0.8773\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 6s 356us/step - loss: 0.3217 - accuracy: 0.8910 - val_loss: 0.3316 - val_accuracy: 0.8819\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 6s 358us/step - loss: 0.3102 - accuracy: 0.8955 - val_loss: 0.2795 - val_accuracy: 0.8954\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 6s 353us/step - loss: 0.2921 - accuracy: 0.9003 - val_loss: 0.2442 - val_accuracy: 0.9105\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 6s 352us/step - loss: 0.2751 - accuracy: 0.9077 - val_loss: 0.3019 - val_accuracy: 0.8894\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 6s 347us/step - loss: 0.2712 - accuracy: 0.9099 - val_loss: 0.2617 - val_accuracy: 0.9049\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 6s 348us/step - loss: 0.2684 - accuracy: 0.9116 - val_loss: 0.2736 - val_accuracy: 0.9043\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 6s 356us/step - loss: 0.2544 - accuracy: 0.9167 - val_loss: 0.2668 - val_accuracy: 0.9007\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 6s 354us/step - loss: 0.2474 - accuracy: 0.9187 - val_loss: 0.3468 - val_accuracy: 0.8802\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 6s 357us/step - loss: 0.2357 - accuracy: 0.9230 - val_loss: 0.2519 - val_accuracy: 0.9040\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 6s 348us/step - loss: 0.2333 - accuracy: 0.9227 - val_loss: 0.2478 - val_accuracy: 0.9170\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 6s 358us/step - loss: 0.2258 - accuracy: 0.9253 - val_loss: 0.2444 - val_accuracy: 0.9144\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 6s 356us/step - loss: 0.2175 - accuracy: 0.9305 - val_loss: 0.2298 - val_accuracy: 0.9147\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 6s 352us/step - loss: 0.2134 - accuracy: 0.9303 - val_loss: 0.2501 - val_accuracy: 0.9102\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 6s 360us/step - loss: 0.2179 - accuracy: 0.9280 - val_loss: 0.2422 - val_accuracy: 0.9164\n",
            "12833/12833 [==============================] - 2s 120us/step\n",
            "Score is 0.92363440990448\n",
            "Individual no 11\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 8s 445us/step - loss: 1.2186 - accuracy: 0.6356 - val_loss: 2.0434 - val_accuracy: 0.4304\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 6s 360us/step - loss: 0.7539 - accuracy: 0.7468 - val_loss: 2.4808 - val_accuracy: 0.4510\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 6s 353us/step - loss: 0.6291 - accuracy: 0.7756 - val_loss: 2.1823 - val_accuracy: 0.4399\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 6s 356us/step - loss: 0.5422 - accuracy: 0.8045 - val_loss: 0.7325 - val_accuracy: 0.7239\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 6s 351us/step - loss: 0.4707 - accuracy: 0.8278 - val_loss: 0.5692 - val_accuracy: 0.7582\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 6s 353us/step - loss: 0.4165 - accuracy: 0.8569 - val_loss: 0.3430 - val_accuracy: 0.8778\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 6s 365us/step - loss: 0.3787 - accuracy: 0.8688 - val_loss: 0.4649 - val_accuracy: 0.8569\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 6s 364us/step - loss: 0.3487 - accuracy: 0.8791 - val_loss: 0.3402 - val_accuracy: 0.8696\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 6s 357us/step - loss: 0.3310 - accuracy: 0.8870 - val_loss: 0.3072 - val_accuracy: 0.8906\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 6s 353us/step - loss: 0.3083 - accuracy: 0.8973 - val_loss: 0.5791 - val_accuracy: 0.7762\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 6s 355us/step - loss: 0.2992 - accuracy: 0.9007 - val_loss: 0.3201 - val_accuracy: 0.8734\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 6s 355us/step - loss: 0.2802 - accuracy: 0.9094 - val_loss: 0.4160 - val_accuracy: 0.8577\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 6s 352us/step - loss: 0.2599 - accuracy: 0.9156 - val_loss: 0.2768 - val_accuracy: 0.9077\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 6s 351us/step - loss: 0.2552 - accuracy: 0.9164 - val_loss: 0.2339 - val_accuracy: 0.9177\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 6s 348us/step - loss: 0.2520 - accuracy: 0.9155 - val_loss: 0.2801 - val_accuracy: 0.9000\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 6s 361us/step - loss: 0.2449 - accuracy: 0.9212 - val_loss: 0.2887 - val_accuracy: 0.9008\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 6s 366us/step - loss: 0.2244 - accuracy: 0.9276 - val_loss: 0.2655 - val_accuracy: 0.9064\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 6s 354us/step - loss: 0.2259 - accuracy: 0.9257 - val_loss: 0.4276 - val_accuracy: 0.8689\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 6s 355us/step - loss: 0.2146 - accuracy: 0.9296 - val_loss: 0.2857 - val_accuracy: 0.8968\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 6s 354us/step - loss: 0.2103 - accuracy: 0.9306 - val_loss: 0.2665 - val_accuracy: 0.9086\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 6s 357us/step - loss: 0.2092 - accuracy: 0.9327 - val_loss: 0.2393 - val_accuracy: 0.9177\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 6s 357us/step - loss: 0.2012 - accuracy: 0.9337 - val_loss: 0.2486 - val_accuracy: 0.9133\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 6s 357us/step - loss: 0.1931 - accuracy: 0.9390 - val_loss: 0.2978 - val_accuracy: 0.9075\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 6s 352us/step - loss: 0.1926 - accuracy: 0.9378 - val_loss: 0.3026 - val_accuracy: 0.8955\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 6s 354us/step - loss: 0.1871 - accuracy: 0.9394 - val_loss: 0.3450 - val_accuracy: 0.8730\n",
            "12833/12833 [==============================] - 2s 120us/step\n",
            "Score is 0.8781266808509827\n",
            "Individual no 12\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 8s 464us/step - loss: 1.1777 - accuracy: 0.6266 - val_loss: 2.2737 - val_accuracy: 0.4304\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 6s 354us/step - loss: 0.7546 - accuracy: 0.7373 - val_loss: 2.8049 - val_accuracy: 0.4329\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 6s 348us/step - loss: 0.6350 - accuracy: 0.7676 - val_loss: 1.1235 - val_accuracy: 0.5948\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 6s 349us/step - loss: 0.5747 - accuracy: 0.7826 - val_loss: 0.5397 - val_accuracy: 0.7783\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 6s 355us/step - loss: 0.5258 - accuracy: 0.8045 - val_loss: 0.4690 - val_accuracy: 0.8191\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 6s 349us/step - loss: 0.4858 - accuracy: 0.8214 - val_loss: 0.3974 - val_accuracy: 0.8357\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 6s 345us/step - loss: 0.4458 - accuracy: 0.8386 - val_loss: 0.4507 - val_accuracy: 0.7965\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 6s 350us/step - loss: 0.4146 - accuracy: 0.8535 - val_loss: 0.3364 - val_accuracy: 0.8781\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 6s 347us/step - loss: 0.3793 - accuracy: 0.8642 - val_loss: 0.3576 - val_accuracy: 0.8669\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 6s 354us/step - loss: 0.3655 - accuracy: 0.8727 - val_loss: 0.5051 - val_accuracy: 0.8320\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 6s 350us/step - loss: 0.3401 - accuracy: 0.8818 - val_loss: 0.3066 - val_accuracy: 0.8816\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 6s 351us/step - loss: 0.3208 - accuracy: 0.8913 - val_loss: 0.3335 - val_accuracy: 0.8802\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 6s 352us/step - loss: 0.3050 - accuracy: 0.8958 - val_loss: 0.3599 - val_accuracy: 0.8696\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 6s 356us/step - loss: 0.2983 - accuracy: 0.8973 - val_loss: 0.2968 - val_accuracy: 0.9017\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 6s 351us/step - loss: 0.2829 - accuracy: 0.9031 - val_loss: 0.5887 - val_accuracy: 0.7842\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 6s 348us/step - loss: 0.2687 - accuracy: 0.9095 - val_loss: 0.3116 - val_accuracy: 0.8908\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 6s 347us/step - loss: 0.2753 - accuracy: 0.9087 - val_loss: 0.2904 - val_accuracy: 0.8949\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 6s 350us/step - loss: 0.2529 - accuracy: 0.9184 - val_loss: 0.3053 - val_accuracy: 0.8855\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 6s 349us/step - loss: 0.2537 - accuracy: 0.9171 - val_loss: 0.3004 - val_accuracy: 0.8978\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 6s 352us/step - loss: 0.2419 - accuracy: 0.9210 - val_loss: 0.2662 - val_accuracy: 0.9065\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 6s 349us/step - loss: 0.2335 - accuracy: 0.9238 - val_loss: 0.3745 - val_accuracy: 0.8599\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 6s 351us/step - loss: 0.2350 - accuracy: 0.9219 - val_loss: 0.2843 - val_accuracy: 0.9028\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 6s 349us/step - loss: 0.2320 - accuracy: 0.9247 - val_loss: 0.2846 - val_accuracy: 0.8964\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 6s 350us/step - loss: 0.2140 - accuracy: 0.9268 - val_loss: 0.2745 - val_accuracy: 0.9082\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 6s 350us/step - loss: 0.2191 - accuracy: 0.9271 - val_loss: 0.3669 - val_accuracy: 0.8861\n",
            "12833/12833 [==============================] - 2s 120us/step\n",
            "Score is 0.8972181081771851\n",
            "Individual no 13\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 8s 444us/step - loss: 1.1541 - accuracy: 0.6287 - val_loss: 2.1053 - val_accuracy: 0.4304\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 6s 356us/step - loss: 0.7462 - accuracy: 0.7437 - val_loss: 2.0349 - val_accuracy: 0.4572\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 6s 358us/step - loss: 0.6483 - accuracy: 0.7642 - val_loss: 0.8099 - val_accuracy: 0.7256\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 6s 362us/step - loss: 0.5781 - accuracy: 0.7815 - val_loss: 0.6146 - val_accuracy: 0.7595\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 6s 356us/step - loss: 0.5439 - accuracy: 0.7962 - val_loss: 0.4610 - val_accuracy: 0.8114\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 6s 361us/step - loss: 0.5109 - accuracy: 0.8073 - val_loss: 0.4529 - val_accuracy: 0.8267\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 6s 359us/step - loss: 0.4583 - accuracy: 0.8279 - val_loss: 0.4190 - val_accuracy: 0.8482\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 6s 360us/step - loss: 0.4241 - accuracy: 0.8474 - val_loss: 0.3715 - val_accuracy: 0.8593\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 6s 357us/step - loss: 0.3890 - accuracy: 0.8573 - val_loss: 0.3700 - val_accuracy: 0.8580\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 6s 353us/step - loss: 0.3695 - accuracy: 0.8688 - val_loss: 0.4838 - val_accuracy: 0.7997\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 6s 351us/step - loss: 0.3462 - accuracy: 0.8786 - val_loss: 0.3475 - val_accuracy: 0.8528\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 6s 358us/step - loss: 0.3379 - accuracy: 0.8830 - val_loss: 0.3184 - val_accuracy: 0.8793\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 6s 360us/step - loss: 0.3154 - accuracy: 0.8907 - val_loss: 0.4208 - val_accuracy: 0.8541\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 6s 365us/step - loss: 0.3086 - accuracy: 0.8910 - val_loss: 0.2778 - val_accuracy: 0.8925\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 6s 369us/step - loss: 0.3141 - accuracy: 0.8926 - val_loss: 0.3471 - val_accuracy: 0.8754\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 6s 356us/step - loss: 0.2903 - accuracy: 0.9003 - val_loss: 0.4709 - val_accuracy: 0.8068\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 6s 363us/step - loss: 0.2844 - accuracy: 0.9035 - val_loss: 0.3417 - val_accuracy: 0.8684\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 6s 361us/step - loss: 0.2768 - accuracy: 0.9079 - val_loss: 0.2547 - val_accuracy: 0.9084\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 6s 356us/step - loss: 0.2760 - accuracy: 0.9064 - val_loss: 0.3432 - val_accuracy: 0.8834\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 6s 352us/step - loss: 0.2642 - accuracy: 0.9102 - val_loss: 0.2540 - val_accuracy: 0.9036\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 6s 356us/step - loss: 0.2610 - accuracy: 0.9113 - val_loss: 0.2736 - val_accuracy: 0.8985\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 6s 355us/step - loss: 0.2613 - accuracy: 0.9109 - val_loss: 0.2946 - val_accuracy: 0.8982\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 6s 354us/step - loss: 0.2488 - accuracy: 0.9148 - val_loss: 0.2778 - val_accuracy: 0.8925\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 6s 358us/step - loss: 0.2467 - accuracy: 0.9165 - val_loss: 0.2731 - val_accuracy: 0.8969\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 6s 361us/step - loss: 0.2438 - accuracy: 0.9171 - val_loss: 0.3312 - val_accuracy: 0.8751\n",
            "12833/12833 [==============================] - 2s 124us/step\n",
            "Score is 0.8843606114387512\n",
            "Individual no 14\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 7s 417us/step - loss: 1.2064 - accuracy: 0.6325 - val_loss: 2.2315 - val_accuracy: 0.4441\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 5s 305us/step - loss: 0.7575 - accuracy: 0.7452 - val_loss: 2.6293 - val_accuracy: 0.4579\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 5s 305us/step - loss: 0.6449 - accuracy: 0.7719 - val_loss: 1.3850 - val_accuracy: 0.5462\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.5667 - accuracy: 0.7931 - val_loss: 0.6115 - val_accuracy: 0.7626\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 5s 305us/step - loss: 0.5105 - accuracy: 0.8167 - val_loss: 0.4611 - val_accuracy: 0.8142\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 5s 305us/step - loss: 0.4704 - accuracy: 0.8289 - val_loss: 0.4454 - val_accuracy: 0.8156\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.4298 - accuracy: 0.8432 - val_loss: 0.3545 - val_accuracy: 0.8571\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.3920 - accuracy: 0.8598 - val_loss: 0.3300 - val_accuracy: 0.8662\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.3722 - accuracy: 0.8707 - val_loss: 0.3120 - val_accuracy: 0.8937\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 5s 306us/step - loss: 0.3486 - accuracy: 0.8840 - val_loss: 0.2862 - val_accuracy: 0.8911\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.3296 - accuracy: 0.8871 - val_loss: 0.3096 - val_accuracy: 0.8874\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 5s 306us/step - loss: 0.3158 - accuracy: 0.8955 - val_loss: 0.3026 - val_accuracy: 0.8911\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.2995 - accuracy: 0.9015 - val_loss: 0.4261 - val_accuracy: 0.8347\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.2873 - accuracy: 0.9039 - val_loss: 0.2622 - val_accuracy: 0.9049\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2739 - accuracy: 0.9083 - val_loss: 0.2338 - val_accuracy: 0.9215\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2586 - accuracy: 0.9174 - val_loss: 0.3243 - val_accuracy: 0.8909\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.2544 - accuracy: 0.9157 - val_loss: 0.2369 - val_accuracy: 0.9176\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2463 - accuracy: 0.9204 - val_loss: 0.3454 - val_accuracy: 0.8678\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.2402 - accuracy: 0.9210 - val_loss: 0.4755 - val_accuracy: 0.8313\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.2490 - accuracy: 0.9198 - val_loss: 0.2744 - val_accuracy: 0.9031\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.2265 - accuracy: 0.9265 - val_loss: 0.2525 - val_accuracy: 0.9110\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2221 - accuracy: 0.9272 - val_loss: 0.2213 - val_accuracy: 0.9275\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.2100 - accuracy: 0.9301 - val_loss: 0.3059 - val_accuracy: 0.8964\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.2200 - accuracy: 0.9286 - val_loss: 0.2313 - val_accuracy: 0.9261\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2094 - accuracy: 0.9324 - val_loss: 0.2613 - val_accuracy: 0.9063\n",
            "12833/12833 [==============================] - 1s 104us/step\n",
            "Score is 0.90812748670578\n",
            "Individual no 15\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 7s 390us/step - loss: 1.4234 - accuracy: 0.5154 - val_loss: 1.8481 - val_accuracy: 0.4710\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.7862 - accuracy: 0.7363 - val_loss: 1.9325 - val_accuracy: 0.4852\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 5s 305us/step - loss: 0.6464 - accuracy: 0.7704 - val_loss: 0.6358 - val_accuracy: 0.7591\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.5760 - accuracy: 0.7899 - val_loss: 0.4750 - val_accuracy: 0.8046\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.5197 - accuracy: 0.8112 - val_loss: 0.4559 - val_accuracy: 0.8087\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.4847 - accuracy: 0.8243 - val_loss: 0.3796 - val_accuracy: 0.8523\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.4457 - accuracy: 0.8380 - val_loss: 0.3528 - val_accuracy: 0.8587\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.4143 - accuracy: 0.8527 - val_loss: 0.5320 - val_accuracy: 0.8051\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 5s 299us/step - loss: 0.3804 - accuracy: 0.8669 - val_loss: 0.3044 - val_accuracy: 0.8891\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.3623 - accuracy: 0.8771 - val_loss: 0.3372 - val_accuracy: 0.8885\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.3454 - accuracy: 0.8813 - val_loss: 0.2919 - val_accuracy: 0.8896\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.3262 - accuracy: 0.8906 - val_loss: 0.3435 - val_accuracy: 0.8767\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 5s 299us/step - loss: 0.3156 - accuracy: 0.8943 - val_loss: 0.3010 - val_accuracy: 0.8891\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 5s 299us/step - loss: 0.3030 - accuracy: 0.9003 - val_loss: 0.2908 - val_accuracy: 0.8968\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 5s 297us/step - loss: 0.2836 - accuracy: 0.9057 - val_loss: 0.2488 - val_accuracy: 0.9118\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2786 - accuracy: 0.9070 - val_loss: 0.4040 - val_accuracy: 0.8579\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2728 - accuracy: 0.9082 - val_loss: 0.2999 - val_accuracy: 0.8966\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.2694 - accuracy: 0.9123 - val_loss: 0.2387 - val_accuracy: 0.9146\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 5s 312us/step - loss: 0.2624 - accuracy: 0.9110 - val_loss: 0.2618 - val_accuracy: 0.9021\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 5s 305us/step - loss: 0.2502 - accuracy: 0.9154 - val_loss: 0.2399 - val_accuracy: 0.9185\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 5s 305us/step - loss: 0.2429 - accuracy: 0.9223 - val_loss: 0.3400 - val_accuracy: 0.8860\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.2359 - accuracy: 0.9231 - val_loss: 0.2958 - val_accuracy: 0.9080\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.2443 - accuracy: 0.9200 - val_loss: 0.3238 - val_accuracy: 0.8894\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.2316 - accuracy: 0.9262 - val_loss: 0.2902 - val_accuracy: 0.8960\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 5s 299us/step - loss: 0.2148 - accuracy: 0.9309 - val_loss: 0.2315 - val_accuracy: 0.9196\n",
            "12833/12833 [==============================] - 1s 102us/step\n",
            "Score is 0.9255824685096741\n",
            "Individual no 16\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 7s 404us/step - loss: 1.2327 - accuracy: 0.5927 - val_loss: 2.1696 - val_accuracy: 0.4304\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.7555 - accuracy: 0.7441 - val_loss: 2.8263 - val_accuracy: 0.3135\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.6418 - accuracy: 0.7752 - val_loss: 2.5584 - val_accuracy: 0.1566\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.5752 - accuracy: 0.7903 - val_loss: 0.8039 - val_accuracy: 0.6831\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.5354 - accuracy: 0.8053 - val_loss: 0.5301 - val_accuracy: 0.7933\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.4842 - accuracy: 0.8204 - val_loss: 0.6158 - val_accuracy: 0.7768\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 5s 309us/step - loss: 0.4468 - accuracy: 0.8392 - val_loss: 0.3512 - val_accuracy: 0.8594\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.4164 - accuracy: 0.8516 - val_loss: 0.4087 - val_accuracy: 0.8509\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.3973 - accuracy: 0.8605 - val_loss: 0.4362 - val_accuracy: 0.8464\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.3629 - accuracy: 0.8742 - val_loss: 0.3399 - val_accuracy: 0.8734\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.3447 - accuracy: 0.8818 - val_loss: 0.2859 - val_accuracy: 0.8907\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.3365 - accuracy: 0.8829 - val_loss: 0.2810 - val_accuracy: 0.8936\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 5s 293us/step - loss: 0.3063 - accuracy: 0.8968 - val_loss: 0.2762 - val_accuracy: 0.8993\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.3142 - accuracy: 0.8956 - val_loss: 0.2881 - val_accuracy: 0.9017\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.2918 - accuracy: 0.9012 - val_loss: 0.3104 - val_accuracy: 0.8879\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.2763 - accuracy: 0.9090 - val_loss: 0.2988 - val_accuracy: 0.8906\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.2700 - accuracy: 0.9117 - val_loss: 0.3193 - val_accuracy: 0.8811\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.2561 - accuracy: 0.9139 - val_loss: 0.3898 - val_accuracy: 0.8721\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.2504 - accuracy: 0.9168 - val_loss: 0.3019 - val_accuracy: 0.8964\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.2406 - accuracy: 0.9206 - val_loss: 0.2598 - val_accuracy: 0.9123\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.2400 - accuracy: 0.9208 - val_loss: 0.2306 - val_accuracy: 0.9165\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.2285 - accuracy: 0.9255 - val_loss: 0.2371 - val_accuracy: 0.9155\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.2294 - accuracy: 0.9267 - val_loss: 0.2464 - val_accuracy: 0.9197\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.2189 - accuracy: 0.9300 - val_loss: 0.2546 - val_accuracy: 0.9138\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.2157 - accuracy: 0.9320 - val_loss: 0.2509 - val_accuracy: 0.9107\n",
            "12833/12833 [==============================] - 1s 103us/step\n",
            "Score is 0.9162315726280212\n",
            "Individual no 17\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 7s 394us/step - loss: 1.2701 - accuracy: 0.5983 - val_loss: 2.3198 - val_accuracy: 0.4304\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 5s 306us/step - loss: 0.7589 - accuracy: 0.7459 - val_loss: 2.9858 - val_accuracy: 0.3734\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.6248 - accuracy: 0.7773 - val_loss: 2.1129 - val_accuracy: 0.4408\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.5592 - accuracy: 0.7976 - val_loss: 0.7533 - val_accuracy: 0.7171\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 5s 307us/step - loss: 0.5019 - accuracy: 0.8157 - val_loss: 0.4241 - val_accuracy: 0.8381\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.4660 - accuracy: 0.8302 - val_loss: 0.3780 - val_accuracy: 0.8516\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 5s 305us/step - loss: 0.4332 - accuracy: 0.8437 - val_loss: 0.3565 - val_accuracy: 0.8523\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.4091 - accuracy: 0.8538 - val_loss: 0.3387 - val_accuracy: 0.8723\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 5s 307us/step - loss: 0.3738 - accuracy: 0.8658 - val_loss: 0.4242 - val_accuracy: 0.8367\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.3648 - accuracy: 0.8715 - val_loss: 0.3145 - val_accuracy: 0.8908\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 5s 306us/step - loss: 0.3377 - accuracy: 0.8812 - val_loss: 0.2929 - val_accuracy: 0.8914\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 5s 310us/step - loss: 0.3357 - accuracy: 0.8871 - val_loss: 0.3172 - val_accuracy: 0.8827\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 5s 307us/step - loss: 0.3201 - accuracy: 0.8884 - val_loss: 0.2909 - val_accuracy: 0.8898\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 5s 305us/step - loss: 0.2986 - accuracy: 0.8988 - val_loss: 0.3351 - val_accuracy: 0.8777\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 5s 308us/step - loss: 0.3030 - accuracy: 0.8975 - val_loss: 0.2720 - val_accuracy: 0.8958\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 5s 305us/step - loss: 0.2810 - accuracy: 0.9057 - val_loss: 0.2850 - val_accuracy: 0.8972\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.2786 - accuracy: 0.9051 - val_loss: 0.4013 - val_accuracy: 0.8618\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2705 - accuracy: 0.9105 - val_loss: 0.2686 - val_accuracy: 0.9021\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.2610 - accuracy: 0.9123 - val_loss: 0.2513 - val_accuracy: 0.9112\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.2568 - accuracy: 0.9146 - val_loss: 0.2769 - val_accuracy: 0.9051\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.2525 - accuracy: 0.9161 - val_loss: 0.2746 - val_accuracy: 0.9024\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 5s 299us/step - loss: 0.2469 - accuracy: 0.9163 - val_loss: 0.3332 - val_accuracy: 0.8876\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2362 - accuracy: 0.9217 - val_loss: 0.2698 - val_accuracy: 0.9045\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.2281 - accuracy: 0.9210 - val_loss: 0.2844 - val_accuracy: 0.8986\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 5s 308us/step - loss: 0.2263 - accuracy: 0.9259 - val_loss: 0.2269 - val_accuracy: 0.9244\n",
            "12833/12833 [==============================] - 1s 112us/step\n",
            "Score is 0.9291669726371765\n",
            "Individual no 18\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 7s 396us/step - loss: 1.2340 - accuracy: 0.6143 - val_loss: 2.0814 - val_accuracy: 0.4304\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.7679 - accuracy: 0.7426 - val_loss: 2.5594 - val_accuracy: 0.4536\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 5s 297us/step - loss: 0.6687 - accuracy: 0.7582 - val_loss: 2.4880 - val_accuracy: 0.4657\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.5854 - accuracy: 0.7861 - val_loss: 0.7042 - val_accuracy: 0.7301\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.5360 - accuracy: 0.8060 - val_loss: 0.5041 - val_accuracy: 0.8048\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.5000 - accuracy: 0.8210 - val_loss: 0.4262 - val_accuracy: 0.8358\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.4584 - accuracy: 0.8372 - val_loss: 0.4750 - val_accuracy: 0.8148\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.4281 - accuracy: 0.8460 - val_loss: 0.3837 - val_accuracy: 0.8611\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.3975 - accuracy: 0.8607 - val_loss: 0.4032 - val_accuracy: 0.8466\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.3666 - accuracy: 0.8739 - val_loss: 0.3114 - val_accuracy: 0.8763\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 5s 297us/step - loss: 0.3452 - accuracy: 0.8845 - val_loss: 0.4191 - val_accuracy: 0.8482\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 5s 297us/step - loss: 0.3228 - accuracy: 0.8919 - val_loss: 0.3433 - val_accuracy: 0.8786\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.3239 - accuracy: 0.8911 - val_loss: 0.3758 - val_accuracy: 0.8765\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 5s 306us/step - loss: 0.3178 - accuracy: 0.8957 - val_loss: 0.4830 - val_accuracy: 0.7983\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 5s 315us/step - loss: 0.2853 - accuracy: 0.9084 - val_loss: 0.4548 - val_accuracy: 0.8145\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.2759 - accuracy: 0.9103 - val_loss: 0.2301 - val_accuracy: 0.9231\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.2686 - accuracy: 0.9105 - val_loss: 0.2621 - val_accuracy: 0.9049\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2619 - accuracy: 0.9154 - val_loss: 0.2628 - val_accuracy: 0.9166\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 5s 297us/step - loss: 0.2626 - accuracy: 0.9146 - val_loss: 0.2891 - val_accuracy: 0.9055\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.2588 - accuracy: 0.9157 - val_loss: 0.2630 - val_accuracy: 0.9028\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.2521 - accuracy: 0.9187 - val_loss: 0.4828 - val_accuracy: 0.8177\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.2397 - accuracy: 0.9189 - val_loss: 0.2736 - val_accuracy: 0.9110\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.2415 - accuracy: 0.9237 - val_loss: 0.3432 - val_accuracy: 0.8832\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 5s 299us/step - loss: 0.2283 - accuracy: 0.9250 - val_loss: 0.3479 - val_accuracy: 0.8815\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.2274 - accuracy: 0.9296 - val_loss: 0.2919 - val_accuracy: 0.8996\n",
            "12833/12833 [==============================] - 1s 104us/step\n",
            "Score is 0.9046988487243652\n",
            "Individual no 19\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 7s 403us/step - loss: 1.2273 - accuracy: 0.6099 - val_loss: 2.0660 - val_accuracy: 0.4442\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.7590 - accuracy: 0.7433 - val_loss: 2.3863 - val_accuracy: 0.4802\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.6370 - accuracy: 0.7724 - val_loss: 1.1117 - val_accuracy: 0.5933\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 5s 292us/step - loss: 0.5731 - accuracy: 0.7858 - val_loss: 0.6023 - val_accuracy: 0.7458\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 5s 293us/step - loss: 0.5143 - accuracy: 0.8116 - val_loss: 0.3996 - val_accuracy: 0.8393\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.4787 - accuracy: 0.8262 - val_loss: 0.4006 - val_accuracy: 0.8406\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 5s 292us/step - loss: 0.4422 - accuracy: 0.8366 - val_loss: 0.4737 - val_accuracy: 0.7926\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.4034 - accuracy: 0.8575 - val_loss: 0.3636 - val_accuracy: 0.8623\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.3752 - accuracy: 0.8672 - val_loss: 0.3638 - val_accuracy: 0.8571\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 5s 320us/step - loss: 0.3674 - accuracy: 0.8725 - val_loss: 0.3562 - val_accuracy: 0.8726\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 9s 503us/step - loss: 0.3337 - accuracy: 0.8879 - val_loss: 0.3820 - val_accuracy: 0.8665\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 5s 293us/step - loss: 0.3257 - accuracy: 0.8901 - val_loss: 0.2949 - val_accuracy: 0.8976\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 5s 293us/step - loss: 0.3058 - accuracy: 0.8953 - val_loss: 0.3654 - val_accuracy: 0.8543\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.2928 - accuracy: 0.8991 - val_loss: 0.2939 - val_accuracy: 0.8867\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 5s 292us/step - loss: 0.2858 - accuracy: 0.9038 - val_loss: 0.4408 - val_accuracy: 0.8516\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.2692 - accuracy: 0.9111 - val_loss: 0.3387 - val_accuracy: 0.8873\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.2653 - accuracy: 0.9118 - val_loss: 0.2316 - val_accuracy: 0.9206\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 5s 293us/step - loss: 0.2548 - accuracy: 0.9179 - val_loss: 0.2823 - val_accuracy: 0.9054\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 5s 293us/step - loss: 0.2477 - accuracy: 0.9163 - val_loss: 0.2577 - val_accuracy: 0.9088\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.2473 - accuracy: 0.9188 - val_loss: 0.2390 - val_accuracy: 0.9180\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.2374 - accuracy: 0.9227 - val_loss: 0.2508 - val_accuracy: 0.9179\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.2326 - accuracy: 0.9251 - val_loss: 0.2765 - val_accuracy: 0.9070\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.2394 - accuracy: 0.9212 - val_loss: 0.2371 - val_accuracy: 0.9151\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 5s 293us/step - loss: 0.2163 - accuracy: 0.9304 - val_loss: 0.3548 - val_accuracy: 0.8661\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 5s 293us/step - loss: 0.2215 - accuracy: 0.9281 - val_loss: 0.2340 - val_accuracy: 0.9246\n",
            "12833/12833 [==============================] - 1s 104us/step\n",
            "Score is 0.9273747205734253\n",
            "Individual no 20\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 7s 405us/step - loss: 1.2718 - accuracy: 0.5862 - val_loss: 2.3317 - val_accuracy: 0.4304\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 5s 313us/step - loss: 0.7560 - accuracy: 0.7527 - val_loss: 2.7845 - val_accuracy: 0.4305\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 5s 310us/step - loss: 0.6429 - accuracy: 0.7728 - val_loss: 1.4472 - val_accuracy: 0.5481\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 5s 310us/step - loss: 0.5707 - accuracy: 0.7946 - val_loss: 0.5722 - val_accuracy: 0.7567\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 5s 318us/step - loss: 0.5089 - accuracy: 0.8166 - val_loss: 0.4800 - val_accuracy: 0.8032\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 6s 322us/step - loss: 0.4728 - accuracy: 0.8289 - val_loss: 0.4140 - val_accuracy: 0.8353\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 5s 311us/step - loss: 0.4323 - accuracy: 0.8478 - val_loss: 0.3434 - val_accuracy: 0.8762\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 5s 312us/step - loss: 0.4115 - accuracy: 0.8514 - val_loss: 0.3949 - val_accuracy: 0.8439\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 5s 311us/step - loss: 0.3961 - accuracy: 0.8589 - val_loss: 0.4080 - val_accuracy: 0.8474\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 5s 312us/step - loss: 0.3781 - accuracy: 0.8651 - val_loss: 0.3251 - val_accuracy: 0.8840\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 5s 310us/step - loss: 0.3556 - accuracy: 0.8719 - val_loss: 0.3231 - val_accuracy: 0.8823\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 5s 312us/step - loss: 0.3472 - accuracy: 0.8822 - val_loss: 0.3349 - val_accuracy: 0.8720\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 5s 312us/step - loss: 0.3272 - accuracy: 0.8843 - val_loss: 0.2774 - val_accuracy: 0.9006\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 5s 314us/step - loss: 0.3163 - accuracy: 0.8899 - val_loss: 0.3471 - val_accuracy: 0.8666\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 5s 314us/step - loss: 0.3134 - accuracy: 0.8928 - val_loss: 0.3355 - val_accuracy: 0.8747\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 5s 314us/step - loss: 0.3009 - accuracy: 0.8980 - val_loss: 0.3052 - val_accuracy: 0.8941\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 5s 312us/step - loss: 0.2974 - accuracy: 0.8980 - val_loss: 0.2809 - val_accuracy: 0.8950\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 5s 312us/step - loss: 0.2924 - accuracy: 0.9001 - val_loss: 0.3645 - val_accuracy: 0.8764\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 5s 314us/step - loss: 0.2801 - accuracy: 0.9063 - val_loss: 0.2684 - val_accuracy: 0.9059\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 5s 315us/step - loss: 0.2781 - accuracy: 0.9058 - val_loss: 0.2692 - val_accuracy: 0.9024\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 6s 323us/step - loss: 0.2655 - accuracy: 0.9116 - val_loss: 0.2341 - val_accuracy: 0.9162\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 5s 320us/step - loss: 0.2602 - accuracy: 0.9103 - val_loss: 0.2527 - val_accuracy: 0.9079\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 5s 314us/step - loss: 0.2633 - accuracy: 0.9104 - val_loss: 0.3077 - val_accuracy: 0.8844\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 5s 312us/step - loss: 0.2459 - accuracy: 0.9158 - val_loss: 0.2852 - val_accuracy: 0.8999\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 5s 312us/step - loss: 0.2448 - accuracy: 0.9179 - val_loss: 0.2972 - val_accuracy: 0.9050\n",
            "12833/12833 [==============================] - 1s 105us/step\n",
            "Score is 0.9129588007926941\n",
            "Individual no 21\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 7s 395us/step - loss: 1.2334 - accuracy: 0.6194 - val_loss: 1.9545 - val_accuracy: 0.4304\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 5s 308us/step - loss: 0.7849 - accuracy: 0.7303 - val_loss: 2.1976 - val_accuracy: 0.3990\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 5s 306us/step - loss: 0.6737 - accuracy: 0.7574 - val_loss: 1.1879 - val_accuracy: 0.6090\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 5s 309us/step - loss: 0.6045 - accuracy: 0.7791 - val_loss: 0.5131 - val_accuracy: 0.7972\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 5s 310us/step - loss: 0.5582 - accuracy: 0.7937 - val_loss: 0.4650 - val_accuracy: 0.8066\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.5287 - accuracy: 0.8034 - val_loss: 0.6039 - val_accuracy: 0.7690\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.4979 - accuracy: 0.8146 - val_loss: 0.4331 - val_accuracy: 0.8419\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.4752 - accuracy: 0.8210 - val_loss: 0.5501 - val_accuracy: 0.7686\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 5s 305us/step - loss: 0.4383 - accuracy: 0.8396 - val_loss: 0.3445 - val_accuracy: 0.8754\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 5s 313us/step - loss: 0.4147 - accuracy: 0.8473 - val_loss: 0.5235 - val_accuracy: 0.8191\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 5s 314us/step - loss: 0.3990 - accuracy: 0.8545 - val_loss: 0.3556 - val_accuracy: 0.8436\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 5s 314us/step - loss: 0.3812 - accuracy: 0.8603 - val_loss: 0.4317 - val_accuracy: 0.8495\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.3537 - accuracy: 0.8770 - val_loss: 0.3031 - val_accuracy: 0.8909\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.3423 - accuracy: 0.8822 - val_loss: 0.2728 - val_accuracy: 0.9012\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 5s 308us/step - loss: 0.3407 - accuracy: 0.8829 - val_loss: 0.2901 - val_accuracy: 0.8907\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 5s 309us/step - loss: 0.3184 - accuracy: 0.8895 - val_loss: 0.5251 - val_accuracy: 0.8106\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 5s 312us/step - loss: 0.3012 - accuracy: 0.8973 - val_loss: 0.3133 - val_accuracy: 0.8942\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 5s 314us/step - loss: 0.2966 - accuracy: 0.8993 - val_loss: 0.3174 - val_accuracy: 0.8849\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 5s 309us/step - loss: 0.2922 - accuracy: 0.9013 - val_loss: 0.2932 - val_accuracy: 0.8939\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 5s 309us/step - loss: 0.2749 - accuracy: 0.9073 - val_loss: 0.2689 - val_accuracy: 0.9034\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 5s 309us/step - loss: 0.2817 - accuracy: 0.9040 - val_loss: 0.2514 - val_accuracy: 0.9077\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.2668 - accuracy: 0.9096 - val_loss: 0.2523 - val_accuracy: 0.9094\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.2637 - accuracy: 0.9096 - val_loss: 0.2564 - val_accuracy: 0.9077\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 5s 307us/step - loss: 0.2615 - accuracy: 0.9124 - val_loss: 0.2732 - val_accuracy: 0.9088\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.2577 - accuracy: 0.9142 - val_loss: 0.3065 - val_accuracy: 0.8883\n",
            "12833/12833 [==============================] - 1s 106us/step\n",
            "Score is 0.8920751214027405\n",
            "Individual no 22\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 6s 359us/step - loss: 1.9081 - accuracy: 0.3816 - val_loss: 1.7639 - val_accuracy: 0.4304\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 5s 268us/step - loss: 1.7590 - accuracy: 0.4393 - val_loss: 1.7606 - val_accuracy: 0.4304\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 5s 266us/step - loss: 1.7593 - accuracy: 0.4393 - val_loss: 1.7607 - val_accuracy: 0.4304\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 5s 265us/step - loss: 1.7596 - accuracy: 0.4393 - val_loss: 1.7615 - val_accuracy: 0.4304\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 5s 264us/step - loss: 1.7563 - accuracy: 0.4393 - val_loss: 1.7610 - val_accuracy: 0.4304\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 5s 265us/step - loss: 1.7564 - accuracy: 0.4393 - val_loss: 1.7612 - val_accuracy: 0.4304\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 5s 267us/step - loss: 1.7567 - accuracy: 0.4393 - val_loss: 1.7607 - val_accuracy: 0.4304\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 5s 269us/step - loss: 1.7553 - accuracy: 0.4393 - val_loss: 1.7606 - val_accuracy: 0.4304\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 5s 268us/step - loss: 1.7558 - accuracy: 0.4393 - val_loss: 1.7610 - val_accuracy: 0.4304\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 5s 264us/step - loss: 1.7551 - accuracy: 0.4393 - val_loss: 1.7607 - val_accuracy: 0.4304\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 5s 263us/step - loss: 1.7554 - accuracy: 0.4393 - val_loss: 1.7607 - val_accuracy: 0.4304\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 5s 276us/step - loss: 1.7557 - accuracy: 0.4393 - val_loss: 1.7607 - val_accuracy: 0.4304\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 5s 268us/step - loss: 1.7547 - accuracy: 0.4393 - val_loss: 1.7610 - val_accuracy: 0.4304\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 5s 266us/step - loss: 1.7552 - accuracy: 0.4393 - val_loss: 1.7612 - val_accuracy: 0.4304\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 5s 267us/step - loss: 1.7547 - accuracy: 0.4393 - val_loss: 1.7608 - val_accuracy: 0.4304\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 5s 264us/step - loss: 1.7545 - accuracy: 0.4393 - val_loss: 1.7607 - val_accuracy: 0.4304\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 5s 267us/step - loss: 1.7538 - accuracy: 0.4393 - val_loss: 1.7609 - val_accuracy: 0.4304\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 5s 264us/step - loss: 1.7541 - accuracy: 0.4393 - val_loss: 1.7608 - val_accuracy: 0.4304\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 4s 261us/step - loss: 1.7534 - accuracy: 0.4393 - val_loss: 1.7609 - val_accuracy: 0.4304\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 4s 261us/step - loss: 1.7548 - accuracy: 0.4393 - val_loss: 1.7607 - val_accuracy: 0.4304\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 5s 264us/step - loss: 1.7529 - accuracy: 0.4393 - val_loss: 1.7623 - val_accuracy: 0.4304\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 5s 264us/step - loss: 1.7544 - accuracy: 0.4393 - val_loss: 1.7610 - val_accuracy: 0.4304\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 5s 265us/step - loss: 1.7534 - accuracy: 0.4393 - val_loss: 1.7613 - val_accuracy: 0.4304\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 5s 265us/step - loss: 1.7534 - accuracy: 0.4393 - val_loss: 1.7609 - val_accuracy: 0.4304\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 5s 265us/step - loss: 1.7537 - accuracy: 0.4393 - val_loss: 1.7607 - val_accuracy: 0.4304\n",
            "12833/12833 [==============================] - 1s 95us/step\n",
            "Score is 0.43715420365333557\n",
            "Individual no 23\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 7s 419us/step - loss: 1.2900 - accuracy: 0.5894 - val_loss: 2.4987 - val_accuracy: 0.4304\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.7617 - accuracy: 0.7440 - val_loss: 3.1419 - val_accuracy: 0.4423\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 5s 305us/step - loss: 0.6440 - accuracy: 0.7686 - val_loss: 2.2303 - val_accuracy: 0.4594\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 5s 316us/step - loss: 0.5770 - accuracy: 0.7872 - val_loss: 0.5801 - val_accuracy: 0.7744\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 5s 313us/step - loss: 0.5291 - accuracy: 0.8072 - val_loss: 0.4886 - val_accuracy: 0.8139\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.4655 - accuracy: 0.8334 - val_loss: 0.4711 - val_accuracy: 0.8249\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 5s 314us/step - loss: 0.4312 - accuracy: 0.8486 - val_loss: 0.4475 - val_accuracy: 0.8159\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.3967 - accuracy: 0.8586 - val_loss: 0.3394 - val_accuracy: 0.8805\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 5s 306us/step - loss: 0.3637 - accuracy: 0.8745 - val_loss: 0.2923 - val_accuracy: 0.8975\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.3413 - accuracy: 0.8816 - val_loss: 0.2919 - val_accuracy: 0.8933\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.3319 - accuracy: 0.8871 - val_loss: 0.3289 - val_accuracy: 0.8856\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.3235 - accuracy: 0.8897 - val_loss: 0.4445 - val_accuracy: 0.8315\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.3071 - accuracy: 0.8974 - val_loss: 0.2841 - val_accuracy: 0.9009\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.2945 - accuracy: 0.9004 - val_loss: 0.3123 - val_accuracy: 0.8980\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.2783 - accuracy: 0.9051 - val_loss: 0.3587 - val_accuracy: 0.8656\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.2813 - accuracy: 0.9075 - val_loss: 0.5108 - val_accuracy: 0.8070\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.2673 - accuracy: 0.9108 - val_loss: 0.2383 - val_accuracy: 0.9158\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.2657 - accuracy: 0.9100 - val_loss: 0.3061 - val_accuracy: 0.8985\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.2524 - accuracy: 0.9178 - val_loss: 0.2339 - val_accuracy: 0.9183\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2486 - accuracy: 0.9178 - val_loss: 0.2653 - val_accuracy: 0.9035\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.2350 - accuracy: 0.9202 - val_loss: 0.2721 - val_accuracy: 0.9092\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.2250 - accuracy: 0.9243 - val_loss: 0.3663 - val_accuracy: 0.8597\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.2281 - accuracy: 0.9268 - val_loss: 0.3097 - val_accuracy: 0.8891\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 9s 520us/step - loss: 0.2256 - accuracy: 0.9252 - val_loss: 0.2504 - val_accuracy: 0.9118\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 6s 340us/step - loss: 0.2236 - accuracy: 0.9282 - val_loss: 0.2858 - val_accuracy: 0.8999\n",
            "12833/12833 [==============================] - 1s 106us/step\n",
            "Score is 0.9071144461631775\n",
            "Individual no 24\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 7s 391us/step - loss: 1.2010 - accuracy: 0.6342 - val_loss: 2.0761 - val_accuracy: 0.4304\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 5s 299us/step - loss: 0.7780 - accuracy: 0.7410 - val_loss: 2.2005 - val_accuracy: 0.4676\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.6723 - accuracy: 0.7637 - val_loss: 1.1644 - val_accuracy: 0.6603\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 5s 297us/step - loss: 0.6115 - accuracy: 0.7795 - val_loss: 0.5690 - val_accuracy: 0.7809\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.5833 - accuracy: 0.7833 - val_loss: 0.5009 - val_accuracy: 0.8076\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.5413 - accuracy: 0.7970 - val_loss: 0.4374 - val_accuracy: 0.8283\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 5s 297us/step - loss: 0.5107 - accuracy: 0.8075 - val_loss: 0.4535 - val_accuracy: 0.8118\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.4824 - accuracy: 0.8179 - val_loss: 0.4299 - val_accuracy: 0.8263\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 5s 297us/step - loss: 0.4715 - accuracy: 0.8275 - val_loss: 0.3888 - val_accuracy: 0.8527\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.4441 - accuracy: 0.8365 - val_loss: 0.3689 - val_accuracy: 0.8583\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.4265 - accuracy: 0.8424 - val_loss: 0.4766 - val_accuracy: 0.8363\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 5s 297us/step - loss: 0.4107 - accuracy: 0.8501 - val_loss: 0.3577 - val_accuracy: 0.8722\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.3878 - accuracy: 0.8601 - val_loss: 0.3506 - val_accuracy: 0.8681\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 5s 293us/step - loss: 0.3796 - accuracy: 0.8641 - val_loss: 0.3355 - val_accuracy: 0.8703\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.3651 - accuracy: 0.8717 - val_loss: 0.3201 - val_accuracy: 0.8823\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.3534 - accuracy: 0.8766 - val_loss: 0.3658 - val_accuracy: 0.8609\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 5s 299us/step - loss: 0.3363 - accuracy: 0.8843 - val_loss: 0.3421 - val_accuracy: 0.8696\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 5s 297us/step - loss: 0.3183 - accuracy: 0.8917 - val_loss: 0.4023 - val_accuracy: 0.8395\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 6s 323us/step - loss: 0.3158 - accuracy: 0.8911 - val_loss: 0.3155 - val_accuracy: 0.8858\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.3052 - accuracy: 0.8989 - val_loss: 0.2643 - val_accuracy: 0.9066\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 5s 297us/step - loss: 0.2928 - accuracy: 0.8994 - val_loss: 0.2470 - val_accuracy: 0.9116\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.2877 - accuracy: 0.9012 - val_loss: 0.2981 - val_accuracy: 0.8943\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.2896 - accuracy: 0.9025 - val_loss: 0.2681 - val_accuracy: 0.8986\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 5s 293us/step - loss: 0.2761 - accuracy: 0.9079 - val_loss: 0.2244 - val_accuracy: 0.9192\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 5s 293us/step - loss: 0.2754 - accuracy: 0.9106 - val_loss: 0.2382 - val_accuracy: 0.9158\n",
            "12833/12833 [==============================] - 1s 103us/step\n",
            "Score is 0.9241798520088196\n",
            "Individual no 25\n",
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/25\n",
            "17110/17110 [==============================] - 7s 397us/step - loss: 1.3657 - accuracy: 0.5705 - val_loss: 1.9827 - val_accuracy: 0.4527\n",
            "Epoch 2/25\n",
            "17110/17110 [==============================] - 5s 314us/step - loss: 0.8196 - accuracy: 0.7294 - val_loss: 2.2731 - val_accuracy: 0.4774\n",
            "Epoch 3/25\n",
            "17110/17110 [==============================] - 5s 318us/step - loss: 0.6720 - accuracy: 0.7604 - val_loss: 1.4434 - val_accuracy: 0.5906\n",
            "Epoch 4/25\n",
            "17110/17110 [==============================] - 5s 313us/step - loss: 0.6045 - accuracy: 0.7795 - val_loss: 0.6247 - val_accuracy: 0.7612\n",
            "Epoch 5/25\n",
            "17110/17110 [==============================] - 5s 315us/step - loss: 0.5341 - accuracy: 0.8051 - val_loss: 0.4468 - val_accuracy: 0.8196\n",
            "Epoch 6/25\n",
            "17110/17110 [==============================] - 5s 314us/step - loss: 0.4919 - accuracy: 0.8202 - val_loss: 0.4306 - val_accuracy: 0.8315\n",
            "Epoch 7/25\n",
            "17110/17110 [==============================] - 5s 312us/step - loss: 0.4559 - accuracy: 0.8338 - val_loss: 0.4166 - val_accuracy: 0.8470\n",
            "Epoch 8/25\n",
            "17110/17110 [==============================] - 5s 312us/step - loss: 0.4243 - accuracy: 0.8441 - val_loss: 0.4621 - val_accuracy: 0.8364\n",
            "Epoch 9/25\n",
            "17110/17110 [==============================] - 5s 318us/step - loss: 0.3901 - accuracy: 0.8635 - val_loss: 0.4026 - val_accuracy: 0.8449\n",
            "Epoch 10/25\n",
            "17110/17110 [==============================] - 6s 329us/step - loss: 0.3758 - accuracy: 0.8679 - val_loss: 0.3198 - val_accuracy: 0.8816\n",
            "Epoch 11/25\n",
            "17110/17110 [==============================] - 6s 322us/step - loss: 0.3616 - accuracy: 0.8742 - val_loss: 0.2925 - val_accuracy: 0.8935\n",
            "Epoch 12/25\n",
            "17110/17110 [==============================] - 5s 314us/step - loss: 0.3409 - accuracy: 0.8832 - val_loss: 0.3519 - val_accuracy: 0.8724\n",
            "Epoch 13/25\n",
            "17110/17110 [==============================] - 5s 320us/step - loss: 0.3323 - accuracy: 0.8867 - val_loss: 0.3010 - val_accuracy: 0.8914\n",
            "Epoch 14/25\n",
            "17110/17110 [==============================] - 5s 316us/step - loss: 0.3175 - accuracy: 0.8897 - val_loss: 0.4223 - val_accuracy: 0.8571\n",
            "Epoch 15/25\n",
            "17110/17110 [==============================] - 5s 321us/step - loss: 0.3089 - accuracy: 0.8942 - val_loss: 0.2835 - val_accuracy: 0.9001\n",
            "Epoch 16/25\n",
            "17110/17110 [==============================] - 5s 321us/step - loss: 0.2967 - accuracy: 0.9009 - val_loss: 0.2633 - val_accuracy: 0.9068\n",
            "Epoch 17/25\n",
            "17110/17110 [==============================] - 5s 317us/step - loss: 0.2970 - accuracy: 0.9008 - val_loss: 0.3246 - val_accuracy: 0.8880\n",
            "Epoch 18/25\n",
            "17110/17110 [==============================] - 6s 322us/step - loss: 0.2845 - accuracy: 0.9038 - val_loss: 0.2598 - val_accuracy: 0.9055\n",
            "Epoch 19/25\n",
            "17110/17110 [==============================] - 6s 322us/step - loss: 0.2711 - accuracy: 0.9109 - val_loss: 0.3108 - val_accuracy: 0.8907\n",
            "Epoch 20/25\n",
            "17110/17110 [==============================] - 5s 320us/step - loss: 0.2731 - accuracy: 0.9084 - val_loss: 0.2773 - val_accuracy: 0.9048\n",
            "Epoch 21/25\n",
            "17110/17110 [==============================] - 5s 321us/step - loss: 0.2646 - accuracy: 0.9116 - val_loss: 0.2551 - val_accuracy: 0.9063\n",
            "Epoch 22/25\n",
            "17110/17110 [==============================] - 6s 325us/step - loss: 0.2543 - accuracy: 0.9127 - val_loss: 0.2873 - val_accuracy: 0.8941\n",
            "Epoch 23/25\n",
            "17110/17110 [==============================] - 5s 312us/step - loss: 0.2557 - accuracy: 0.9134 - val_loss: 0.3215 - val_accuracy: 0.8733\n",
            "Epoch 24/25\n",
            "17110/17110 [==============================] - 5s 306us/step - loss: 0.2495 - accuracy: 0.9174 - val_loss: 0.2483 - val_accuracy: 0.9144\n",
            "Epoch 25/25\n",
            "17110/17110 [==============================] - 5s 306us/step - loss: 0.2376 - accuracy: 0.9200 - val_loss: 0.2972 - val_accuracy: 0.8980\n",
            "12833/12833 [==============================] - 1s 104us/step\n",
            "Score is 0.9036858081817627\n",
            "Time taken ------> 3596.7544362545013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU62XsCXnOj4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "5b7e44a7-773c-4d44-bb8c-8fd056ccad2f"
      },
      "source": [
        "best_parameters = ga.best_individual()[1]\n",
        "for index,i in enumerate(data):\n",
        "  print(i[best_parameters[index]])\n",
        "\n",
        "print(ga.best_individual()[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "23\n",
            "38\n",
            "66\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "0.9241798520088196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXoVZ9ibM34E",
        "colab_type": "text"
      },
      "source": [
        "# Building CNN Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT7KyTCKM-27",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f205b81d-d692-4d16-9fbf-f24ff2699e38"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters=data[0][best_parameters[0]], kernel_size=data[4][best_parameters[4]], activation='relu', input_shape=input_shape))\n",
        "model.add(Conv1D(filters=data[0][best_parameters[0]], kernel_size=data[4][best_parameters[4]], activation='relu', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=data[1][best_parameters[1]], kernel_size=data[5][best_parameters[5]], activation='relu'))\n",
        "model.add(Conv1D(filters=data[1][best_parameters[1]], kernel_size=data[5][best_parameters[5]], activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=data[2][best_parameters[2]], kernel_size=data[5][best_parameters[5]], activation='relu'))\n",
        "model.add(Conv1D(filters=data[2][best_parameters[2]], kernel_size=data[5][best_parameters[5]], activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=data[3][best_parameters[3]], kernel_size=data[6][best_parameters[6]], activation='relu'))\n",
        "model.add(Conv1D(filters=data[3][best_parameters[3]], kernel_size=data[6][best_parameters[6]], activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(number_of_classes, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_201 (Conv1D)          (None, 77, 8)             24        \n",
            "_________________________________________________________________\n",
            "conv1d_202 (Conv1D)          (None, 76, 8)             136       \n",
            "_________________________________________________________________\n",
            "batch_normalization_176 (Bat (None, 76, 8)             32        \n",
            "_________________________________________________________________\n",
            "max_pooling1d_101 (MaxPoolin (None, 38, 8)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_203 (Conv1D)          (None, 36, 23)            575       \n",
            "_________________________________________________________________\n",
            "conv1d_204 (Conv1D)          (None, 34, 23)            1610      \n",
            "_________________________________________________________________\n",
            "batch_normalization_177 (Bat (None, 34, 23)            92        \n",
            "_________________________________________________________________\n",
            "max_pooling1d_102 (MaxPoolin (None, 17, 23)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_205 (Conv1D)          (None, 15, 38)            2660      \n",
            "_________________________________________________________________\n",
            "conv1d_206 (Conv1D)          (None, 13, 38)            4370      \n",
            "_________________________________________________________________\n",
            "batch_normalization_178 (Bat (None, 13, 38)            152       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_103 (MaxPoolin (None, 6, 38)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_207 (Conv1D)          (None, 4, 66)             7590      \n",
            "_________________________________________________________________\n",
            "conv1d_208 (Conv1D)          (None, 2, 66)             13134     \n",
            "_________________________________________________________________\n",
            "batch_normalization_179 (Bat (None, 2, 66)             264       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_104 (MaxPoolin (None, 1, 66)             0         \n",
            "_________________________________________________________________\n",
            "dropout_101 (Dropout)        (None, 1, 66)             0         \n",
            "_________________________________________________________________\n",
            "flatten_26 (Flatten)         (None, 66)                0         \n",
            "_________________________________________________________________\n",
            "dense_101 (Dense)            (None, 64)                4288      \n",
            "_________________________________________________________________\n",
            "batch_normalization_180 (Bat (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_102 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_102 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_181 (Bat (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout_103 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_103 (Dense)            (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "batch_normalization_182 (Bat (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "dropout_104 (Dropout)        (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_104 (Dense)            (None, 9)                 153       \n",
            "=================================================================\n",
            "Total params: 38,136\n",
            "Trainable params: 37,642\n",
            "Non-trainable params: 494\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nHrv5P4EPUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = Sequential()\n",
        "# model.add(Conv1D(filters=8, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "# model.add(Conv1D(filters=8, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "# model.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n",
        "# model.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "# model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "# model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "# model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "# model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(Dense(16, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(Dense(number_of_classes, activation='softmax'))\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5kxIOUabfGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in model.layers:\n",
        "#   name = i.output.name.split('/')[0].split('_')\n",
        "#   if len(name) > 2:\n",
        "#     name = name[0] + '_' + name[1]\n",
        "#   else:\n",
        "#     name = name[0]\n",
        "#   print(name, i.output.shape)\n",
        "#   print('_________________________________________________')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-VSlVynNBID",
        "colab_type": "code",
        "outputId": "dd7616c3-3a8f-490d-8c9e-a47955b0fdff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras\n",
        "model.compile(loss=loss,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=metrics)\n",
        "\n",
        "model.fit(X_train, np.array(y_train),\n",
        "          batch_size=128,\n",
        "          epochs=100,\n",
        "          verbose=1,\n",
        "          validation_data=(xx_val, np.array(yy_val)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 17110 samples, validate on 12833 samples\n",
            "Epoch 1/100\n",
            "17110/17110 [==============================] - 7s 388us/step - loss: 1.4225 - accuracy: 0.5252 - val_loss: 2.0856 - val_accuracy: 0.4304\n",
            "Epoch 2/100\n",
            "17110/17110 [==============================] - 5s 292us/step - loss: 0.8088 - accuracy: 0.7319 - val_loss: 2.5197 - val_accuracy: 0.4593\n",
            "Epoch 3/100\n",
            "17110/17110 [==============================] - 5s 293us/step - loss: 0.6662 - accuracy: 0.7642 - val_loss: 1.1185 - val_accuracy: 0.6345\n",
            "Epoch 4/100\n",
            "17110/17110 [==============================] - 5s 291us/step - loss: 0.6026 - accuracy: 0.7807 - val_loss: 0.5149 - val_accuracy: 0.7863\n",
            "Epoch 5/100\n",
            "17110/17110 [==============================] - 5s 292us/step - loss: 0.5491 - accuracy: 0.7995 - val_loss: 0.4653 - val_accuracy: 0.8117\n",
            "Epoch 6/100\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.5071 - accuracy: 0.8113 - val_loss: 0.4120 - val_accuracy: 0.8286\n",
            "Epoch 7/100\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.4866 - accuracy: 0.8215 - val_loss: 0.4210 - val_accuracy: 0.8509\n",
            "Epoch 8/100\n",
            "17110/17110 [==============================] - 5s 290us/step - loss: 0.4623 - accuracy: 0.8301 - val_loss: 0.3776 - val_accuracy: 0.8440\n",
            "Epoch 9/100\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.4422 - accuracy: 0.8387 - val_loss: 0.4135 - val_accuracy: 0.8311\n",
            "Epoch 10/100\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.4062 - accuracy: 0.8508 - val_loss: 0.4234 - val_accuracy: 0.8379\n",
            "Epoch 11/100\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.3837 - accuracy: 0.8648 - val_loss: 0.3095 - val_accuracy: 0.8855\n",
            "Epoch 12/100\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.3653 - accuracy: 0.8722 - val_loss: 0.3283 - val_accuracy: 0.8643\n",
            "Epoch 13/100\n",
            "17110/17110 [==============================] - 5s 293us/step - loss: 0.3434 - accuracy: 0.8800 - val_loss: 0.3790 - val_accuracy: 0.8587\n",
            "Epoch 14/100\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.3301 - accuracy: 0.8890 - val_loss: 0.3324 - val_accuracy: 0.8694\n",
            "Epoch 15/100\n",
            "17110/17110 [==============================] - 5s 290us/step - loss: 0.3212 - accuracy: 0.8925 - val_loss: 0.2763 - val_accuracy: 0.8960\n",
            "Epoch 16/100\n",
            "17110/17110 [==============================] - 5s 292us/step - loss: 0.3024 - accuracy: 0.8949 - val_loss: 0.2946 - val_accuracy: 0.8961\n",
            "Epoch 17/100\n",
            "17110/17110 [==============================] - 5s 292us/step - loss: 0.3103 - accuracy: 0.8932 - val_loss: 0.2793 - val_accuracy: 0.8948\n",
            "Epoch 18/100\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.2898 - accuracy: 0.9008 - val_loss: 0.3678 - val_accuracy: 0.8633\n",
            "Epoch 19/100\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.2960 - accuracy: 0.9018 - val_loss: 0.2758 - val_accuracy: 0.9039\n",
            "Epoch 20/100\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.2656 - accuracy: 0.9112 - val_loss: 0.2680 - val_accuracy: 0.9032\n",
            "Epoch 21/100\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.2673 - accuracy: 0.9112 - val_loss: 0.2816 - val_accuracy: 0.9034\n",
            "Epoch 22/100\n",
            "17110/17110 [==============================] - 5s 293us/step - loss: 0.2628 - accuracy: 0.9118 - val_loss: 0.2401 - val_accuracy: 0.9178\n",
            "Epoch 23/100\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.2528 - accuracy: 0.9141 - val_loss: 0.2847 - val_accuracy: 0.8961\n",
            "Epoch 24/100\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.2496 - accuracy: 0.9193 - val_loss: 0.2583 - val_accuracy: 0.9069\n",
            "Epoch 25/100\n",
            "17110/17110 [==============================] - 5s 305us/step - loss: 0.2467 - accuracy: 0.9177 - val_loss: 0.2545 - val_accuracy: 0.9145\n",
            "Epoch 26/100\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.2464 - accuracy: 0.9183 - val_loss: 0.2692 - val_accuracy: 0.8977\n",
            "Epoch 27/100\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.2421 - accuracy: 0.9195 - val_loss: 0.2813 - val_accuracy: 0.9003\n",
            "Epoch 28/100\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.2449 - accuracy: 0.9193 - val_loss: 0.2286 - val_accuracy: 0.9186\n",
            "Epoch 29/100\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.2364 - accuracy: 0.9203 - val_loss: 0.3339 - val_accuracy: 0.8861\n",
            "Epoch 30/100\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.2282 - accuracy: 0.9224 - val_loss: 0.2596 - val_accuracy: 0.9063\n",
            "Epoch 31/100\n",
            "17110/17110 [==============================] - 5s 297us/step - loss: 0.2264 - accuracy: 0.9240 - val_loss: 0.2081 - val_accuracy: 0.9298\n",
            "Epoch 32/100\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.2206 - accuracy: 0.9269 - val_loss: 0.2895 - val_accuracy: 0.9034\n",
            "Epoch 33/100\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.2237 - accuracy: 0.9261 - val_loss: 0.2570 - val_accuracy: 0.9085\n",
            "Epoch 34/100\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.2143 - accuracy: 0.9290 - val_loss: 0.2290 - val_accuracy: 0.9177\n",
            "Epoch 35/100\n",
            "17110/17110 [==============================] - 5s 293us/step - loss: 0.2120 - accuracy: 0.9312 - val_loss: 0.2230 - val_accuracy: 0.9222\n",
            "Epoch 36/100\n",
            "17110/17110 [==============================] - 5s 299us/step - loss: 0.2098 - accuracy: 0.9284 - val_loss: 0.2169 - val_accuracy: 0.9241\n",
            "Epoch 37/100\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.2049 - accuracy: 0.9313 - val_loss: 0.2417 - val_accuracy: 0.9120\n",
            "Epoch 38/100\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.2053 - accuracy: 0.9336 - val_loss: 0.2323 - val_accuracy: 0.9190\n",
            "Epoch 39/100\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.1903 - accuracy: 0.9373 - val_loss: 0.2311 - val_accuracy: 0.9214\n",
            "Epoch 40/100\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.1901 - accuracy: 0.9362 - val_loss: 0.2225 - val_accuracy: 0.9234\n",
            "Epoch 41/100\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.1936 - accuracy: 0.9346 - val_loss: 0.2184 - val_accuracy: 0.9264\n",
            "Epoch 42/100\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.1973 - accuracy: 0.9338 - val_loss: 0.2348 - val_accuracy: 0.9193\n",
            "Epoch 43/100\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.1876 - accuracy: 0.9375 - val_loss: 0.2753 - val_accuracy: 0.9011\n",
            "Epoch 44/100\n",
            "17110/17110 [==============================] - 5s 317us/step - loss: 0.1874 - accuracy: 0.9380 - val_loss: 0.2139 - val_accuracy: 0.9274\n",
            "Epoch 45/100\n",
            "17110/17110 [==============================] - 5s 307us/step - loss: 0.1891 - accuracy: 0.9361 - val_loss: 0.2130 - val_accuracy: 0.9246\n",
            "Epoch 46/100\n",
            "17110/17110 [==============================] - 5s 297us/step - loss: 0.1819 - accuracy: 0.9398 - val_loss: 0.2161 - val_accuracy: 0.9274\n",
            "Epoch 47/100\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.1797 - accuracy: 0.9405 - val_loss: 0.2731 - val_accuracy: 0.9114\n",
            "Epoch 48/100\n",
            "17110/17110 [==============================] - 5s 304us/step - loss: 0.1758 - accuracy: 0.9412 - val_loss: 0.2236 - val_accuracy: 0.9225\n",
            "Epoch 49/100\n",
            "17110/17110 [==============================] - 5s 306us/step - loss: 0.1781 - accuracy: 0.9408 - val_loss: 0.2262 - val_accuracy: 0.9261\n",
            "Epoch 50/100\n",
            "17110/17110 [==============================] - 5s 309us/step - loss: 0.1715 - accuracy: 0.9439 - val_loss: 0.2013 - val_accuracy: 0.9310\n",
            "Epoch 51/100\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.1634 - accuracy: 0.9447 - val_loss: 0.2269 - val_accuracy: 0.9235\n",
            "Epoch 52/100\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.1704 - accuracy: 0.9417 - val_loss: 0.2647 - val_accuracy: 0.9098\n",
            "Epoch 53/100\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.1687 - accuracy: 0.9456 - val_loss: 0.2253 - val_accuracy: 0.9253\n",
            "Epoch 54/100\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.1669 - accuracy: 0.9428 - val_loss: 0.2633 - val_accuracy: 0.9121\n",
            "Epoch 55/100\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.1654 - accuracy: 0.9444 - val_loss: 0.2065 - val_accuracy: 0.9302\n",
            "Epoch 56/100\n",
            "17110/17110 [==============================] - 5s 297us/step - loss: 0.1600 - accuracy: 0.9470 - val_loss: 0.2169 - val_accuracy: 0.9293\n",
            "Epoch 57/100\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.1634 - accuracy: 0.9460 - val_loss: 0.1980 - val_accuracy: 0.9339\n",
            "Epoch 58/100\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.1569 - accuracy: 0.9487 - val_loss: 0.2471 - val_accuracy: 0.9155\n",
            "Epoch 59/100\n",
            "17110/17110 [==============================] - 5s 294us/step - loss: 0.1525 - accuracy: 0.9478 - val_loss: 0.2951 - val_accuracy: 0.9028\n",
            "Epoch 60/100\n",
            "17110/17110 [==============================] - 5s 293us/step - loss: 0.1568 - accuracy: 0.9489 - val_loss: 0.2484 - val_accuracy: 0.9245\n",
            "Epoch 61/100\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.1509 - accuracy: 0.9486 - val_loss: 0.2108 - val_accuracy: 0.9312\n",
            "Epoch 62/100\n",
            "17110/17110 [==============================] - 9s 509us/step - loss: 0.1610 - accuracy: 0.9448 - val_loss: 0.2389 - val_accuracy: 0.9234\n",
            "Epoch 63/100\n",
            "17110/17110 [==============================] - 6s 332us/step - loss: 0.1478 - accuracy: 0.9518 - val_loss: 0.3045 - val_accuracy: 0.9019\n",
            "Epoch 64/100\n",
            "17110/17110 [==============================] - 5s 295us/step - loss: 0.1553 - accuracy: 0.9496 - val_loss: 0.2536 - val_accuracy: 0.9223\n",
            "Epoch 65/100\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.1445 - accuracy: 0.9503 - val_loss: 0.2297 - val_accuracy: 0.9272\n",
            "Epoch 66/100\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.1411 - accuracy: 0.9517 - val_loss: 0.2202 - val_accuracy: 0.9297\n",
            "Epoch 67/100\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.1426 - accuracy: 0.9525 - val_loss: 0.2170 - val_accuracy: 0.9302\n",
            "Epoch 68/100\n",
            "17110/17110 [==============================] - 5s 296us/step - loss: 0.1409 - accuracy: 0.9537 - val_loss: 0.2261 - val_accuracy: 0.9258\n",
            "Epoch 69/100\n",
            "17110/17110 [==============================] - 5s 297us/step - loss: 0.1417 - accuracy: 0.9544 - val_loss: 0.2122 - val_accuracy: 0.9328\n",
            "Epoch 70/100\n",
            "17110/17110 [==============================] - 5s 297us/step - loss: 0.1368 - accuracy: 0.9556 - val_loss: 0.2378 - val_accuracy: 0.9208\n",
            "Epoch 71/100\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.1395 - accuracy: 0.9533 - val_loss: 0.2080 - val_accuracy: 0.9331\n",
            "Epoch 72/100\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.1339 - accuracy: 0.9547 - val_loss: 0.2477 - val_accuracy: 0.9268\n",
            "Epoch 73/100\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.1323 - accuracy: 0.9542 - val_loss: 0.2090 - val_accuracy: 0.9342\n",
            "Epoch 74/100\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.1407 - accuracy: 0.9542 - val_loss: 0.2671 - val_accuracy: 0.9243\n",
            "Epoch 75/100\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.1338 - accuracy: 0.9539 - val_loss: 0.2124 - val_accuracy: 0.9320\n",
            "Epoch 76/100\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.1318 - accuracy: 0.9575 - val_loss: 0.2566 - val_accuracy: 0.9226\n",
            "Epoch 77/100\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.1282 - accuracy: 0.9584 - val_loss: 0.2688 - val_accuracy: 0.9246\n",
            "Epoch 78/100\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.1331 - accuracy: 0.9552 - val_loss: 0.2857 - val_accuracy: 0.9155\n",
            "Epoch 79/100\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.1309 - accuracy: 0.9552 - val_loss: 0.2404 - val_accuracy: 0.9278\n",
            "Epoch 80/100\n",
            "17110/17110 [==============================] - 5s 308us/step - loss: 0.1331 - accuracy: 0.9553 - val_loss: 0.2493 - val_accuracy: 0.9222\n",
            "Epoch 81/100\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.1345 - accuracy: 0.9568 - val_loss: 0.2227 - val_accuracy: 0.9296\n",
            "Epoch 82/100\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.1251 - accuracy: 0.9573 - val_loss: 0.2795 - val_accuracy: 0.9208\n",
            "Epoch 83/100\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.1219 - accuracy: 0.9602 - val_loss: 0.2213 - val_accuracy: 0.9363\n",
            "Epoch 84/100\n",
            "17110/17110 [==============================] - 5s 311us/step - loss: 0.1250 - accuracy: 0.9593 - val_loss: 0.2332 - val_accuracy: 0.9276\n",
            "Epoch 85/100\n",
            "17110/17110 [==============================] - 5s 305us/step - loss: 0.1328 - accuracy: 0.9571 - val_loss: 0.2622 - val_accuracy: 0.9223\n",
            "Epoch 86/100\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.1141 - accuracy: 0.9614 - val_loss: 0.2843 - val_accuracy: 0.9143\n",
            "Epoch 87/100\n",
            "17110/17110 [==============================] - 5s 299us/step - loss: 0.1297 - accuracy: 0.9587 - val_loss: 0.2311 - val_accuracy: 0.9335\n",
            "Epoch 88/100\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.1217 - accuracy: 0.9608 - val_loss: 0.2569 - val_accuracy: 0.9178\n",
            "Epoch 89/100\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.1155 - accuracy: 0.9617 - val_loss: 0.2573 - val_accuracy: 0.9219\n",
            "Epoch 90/100\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.1165 - accuracy: 0.9629 - val_loss: 0.2631 - val_accuracy: 0.9238\n",
            "Epoch 91/100\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.1171 - accuracy: 0.9608 - val_loss: 0.2724 - val_accuracy: 0.9271\n",
            "Epoch 92/100\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.1158 - accuracy: 0.9608 - val_loss: 0.3017 - val_accuracy: 0.9137\n",
            "Epoch 93/100\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.1150 - accuracy: 0.9621 - val_loss: 0.2534 - val_accuracy: 0.9243\n",
            "Epoch 94/100\n",
            "17110/17110 [==============================] - 5s 302us/step - loss: 0.1155 - accuracy: 0.9607 - val_loss: 0.2784 - val_accuracy: 0.9167\n",
            "Epoch 95/100\n",
            "17110/17110 [==============================] - 5s 303us/step - loss: 0.1114 - accuracy: 0.9638 - val_loss: 0.2466 - val_accuracy: 0.9296\n",
            "Epoch 96/100\n",
            "17110/17110 [==============================] - 5s 298us/step - loss: 0.1094 - accuracy: 0.9636 - val_loss: 0.2522 - val_accuracy: 0.9279\n",
            "Epoch 97/100\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.1134 - accuracy: 0.9622 - val_loss: 0.2313 - val_accuracy: 0.9335\n",
            "Epoch 98/100\n",
            "17110/17110 [==============================] - 5s 300us/step - loss: 0.1062 - accuracy: 0.9640 - val_loss: 0.2558 - val_accuracy: 0.9261\n",
            "Epoch 99/100\n",
            "17110/17110 [==============================] - 5s 301us/step - loss: 0.1114 - accuracy: 0.9631 - val_loss: 0.2967 - val_accuracy: 0.9112\n",
            "Epoch 100/100\n",
            "17110/17110 [==============================] - 5s 299us/step - loss: 0.1064 - accuracy: 0.9646 - val_loss: 0.2859 - val_accuracy: 0.9259\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f2c9ab2d6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSGrC7sxNWhx",
        "colab_type": "code",
        "outputId": "8cecd936-e835-4795-b5dc-36032623419c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "score = model.evaluate(xx_test, yy_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12833/12833 [==============================] - 1s 104us/step\n",
            "Test loss: 0.24889509557705083\n",
            "Test accuracy: 0.932751476764679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbIwG9dgjk-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if len(np.array(y_test).shape) == 1:\n",
        "  y_test = [x+1 for x in y_test]\n",
        "  y_train = [x+1 for x in y_train]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9zjzu4ArF-O",
        "colab_type": "code",
        "outputId": "4503aadf-fcaf-4ec5-f31e-5adea7df71ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install spectral"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spectral in /usr/local/lib/python3.6/dist-packages (0.21)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from spectral) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf5wCQc3q7ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spectral as sp\n",
        "prediction = model.predict(X)\n",
        "\n",
        "if not len(prediction.shape) == 2:\n",
        "    y_test = [x + 1 for x in y_test]\n",
        "    y_train = [x + 1 for x in y_train]\n",
        "\n",
        "if len(prediction.shape) == 2:\n",
        "    predicted_gt_1 = np.argmax(prediction, axis=1)\n",
        "    predicted_gt_1_list = list(predicted_gt_1)\n",
        "    predicted_gt_1_list = [x + 1 for x in predicted_gt_1_list]\n",
        "else:\n",
        "    predicted_gt_1_list = prediction\n",
        "\n",
        "for i in zero_data:\n",
        "    predicted_gt_1_list.insert(i, 0)\n",
        "\n",
        "predicted_gt_1_list = np.array(predicted_gt_1_list).reshape(image.shape[0], image.shape[1])\n",
        "sp.save_rgb('predicted_gt.jpg', predicted_gt_1_list, colors=sp.spy_colors)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}