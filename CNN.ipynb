{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN",
      "provenance": [],
      "authorship_tag": "ABX9TyM2r+aayHJQYbKrK46V7+N5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srajan1122/Hyperspectral_Image_Classification/blob/srajan/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO-nUq2-KL7a",
        "colab_type": "code",
        "outputId": "98bdd2e0-348c-4230-ed08-e6cb71d9f9f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXpp9_cwKqz1",
        "colab_type": "text"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVxnzfWvKN-K",
        "colab_type": "code",
        "outputId": "9a0dc8c1-b386-439f-c218-9afaa98df7c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder \n",
        "from sklearn import preprocessing\n",
        "import keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqasbIqPK0KM",
        "colab_type": "text"
      },
      "source": [
        "# Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erOp3hTTKuzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_dataset = io.loadmat('/content/drive/My Drive/Srajan/Internship/SEM4-LeadingindiaAI/Tasks/Datasets/Botswana/Botswana.mat')\n",
        "for key, value in loaded_dataset.items():\n",
        "  if isinstance(value, type(np.array([1]))):\n",
        "    image = loaded_dataset[key]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjbphR_nK5O8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ground_truth_1 = io.loadmat('/content/drive/My Drive/Srajan/Internship/SEM4-LeadingindiaAI/Tasks/Datasets/Botswana/Botswana_gt.mat')\n",
        "for key, value in ground_truth_1.items():\n",
        "  if isinstance(value, type(np.array([1]))):\n",
        "    ground_truth = ground_truth_1[key]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9l4ZElPK8xW",
        "colab_type": "text"
      },
      "source": [
        "## Class Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JumPKdTvK_EY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_values = [\"Alfalfa\", \"Corn-notill\", \"Corn-mintill\",\n",
        "                        \"Corn\", \"Grass-pasture\", \"Grass-trees\",\n",
        "                        \"Grass-pasture-mowed\", \"Hay-windrowed\", \"Oats\",\n",
        "                        \"Soybean-notill\", \"Soybean-mintill\", \"Soybean-clean\",\n",
        "                        \"Wheat\", \"Woods\", \"Buildings-Grass-Trees-Drives\",\n",
        "                        \"Stone-Steel-Towers\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYIFKIPmLCFV",
        "colab_type": "text"
      },
      "source": [
        "## Resizing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnRRsjn8K_zG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_with_gt = np.dstack((image, ground_truth))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2hhElWJLF9V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_output = image_with_gt.reshape(ground_truth.size, image.shape[2]+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKGD0bRxLJff",
        "colab_type": "text"
      },
      "source": [
        "## Data Visualization in pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AWkTHdDLOwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.DataFrame(final_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ctUP_zKLUpJ",
        "colab_type": "code",
        "outputId": "c3b522c9-10d1-4fdf-9f82-d3af1c8dda41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>106</th>\n",
              "      <th>107</th>\n",
              "      <th>108</th>\n",
              "      <th>109</th>\n",
              "      <th>110</th>\n",
              "      <th>111</th>\n",
              "      <th>112</th>\n",
              "      <th>113</th>\n",
              "      <th>114</th>\n",
              "      <th>115</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "      <th>143</th>\n",
              "      <th>144</th>\n",
              "      <th>145</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3996</td>\n",
              "      <td>3952</td>\n",
              "      <td>3698</td>\n",
              "      <td>3457</td>\n",
              "      <td>3063</td>\n",
              "      <td>2914</td>\n",
              "      <td>2796</td>\n",
              "      <td>2538</td>\n",
              "      <td>2629</td>\n",
              "      <td>2613</td>\n",
              "      <td>2533</td>\n",
              "      <td>2517</td>\n",
              "      <td>2306</td>\n",
              "      <td>2149</td>\n",
              "      <td>2065</td>\n",
              "      <td>1994</td>\n",
              "      <td>1943</td>\n",
              "      <td>1840</td>\n",
              "      <td>1779</td>\n",
              "      <td>1726</td>\n",
              "      <td>1654</td>\n",
              "      <td>1519</td>\n",
              "      <td>1542</td>\n",
              "      <td>1478</td>\n",
              "      <td>1404</td>\n",
              "      <td>1600</td>\n",
              "      <td>2755</td>\n",
              "      <td>2806</td>\n",
              "      <td>3459</td>\n",
              "      <td>4137</td>\n",
              "      <td>4008</td>\n",
              "      <td>2741</td>\n",
              "      <td>4144</td>\n",
              "      <td>4268</td>\n",
              "      <td>4069</td>\n",
              "      <td>4020</td>\n",
              "      <td>3537</td>\n",
              "      <td>3335</td>\n",
              "      <td>3582</td>\n",
              "      <td>3868</td>\n",
              "      <td>...</td>\n",
              "      <td>450</td>\n",
              "      <td>385</td>\n",
              "      <td>316</td>\n",
              "      <td>240</td>\n",
              "      <td>157</td>\n",
              "      <td>98</td>\n",
              "      <td>149</td>\n",
              "      <td>142</td>\n",
              "      <td>106</td>\n",
              "      <td>91</td>\n",
              "      <td>107</td>\n",
              "      <td>158</td>\n",
              "      <td>164</td>\n",
              "      <td>163</td>\n",
              "      <td>166</td>\n",
              "      <td>184</td>\n",
              "      <td>196</td>\n",
              "      <td>181</td>\n",
              "      <td>169</td>\n",
              "      <td>156</td>\n",
              "      <td>159</td>\n",
              "      <td>134</td>\n",
              "      <td>135</td>\n",
              "      <td>144</td>\n",
              "      <td>159</td>\n",
              "      <td>142</td>\n",
              "      <td>138</td>\n",
              "      <td>145</td>\n",
              "      <td>138</td>\n",
              "      <td>110</td>\n",
              "      <td>104</td>\n",
              "      <td>114</td>\n",
              "      <td>89</td>\n",
              "      <td>89</td>\n",
              "      <td>77</td>\n",
              "      <td>73</td>\n",
              "      <td>60</td>\n",
              "      <td>53</td>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3996</td>\n",
              "      <td>3952</td>\n",
              "      <td>3698</td>\n",
              "      <td>3457</td>\n",
              "      <td>3063</td>\n",
              "      <td>2914</td>\n",
              "      <td>2796</td>\n",
              "      <td>2538</td>\n",
              "      <td>2629</td>\n",
              "      <td>2613</td>\n",
              "      <td>2533</td>\n",
              "      <td>2517</td>\n",
              "      <td>2306</td>\n",
              "      <td>2149</td>\n",
              "      <td>2065</td>\n",
              "      <td>1994</td>\n",
              "      <td>1943</td>\n",
              "      <td>1840</td>\n",
              "      <td>1779</td>\n",
              "      <td>1726</td>\n",
              "      <td>1654</td>\n",
              "      <td>1519</td>\n",
              "      <td>1542</td>\n",
              "      <td>1478</td>\n",
              "      <td>1404</td>\n",
              "      <td>1600</td>\n",
              "      <td>2029</td>\n",
              "      <td>2172</td>\n",
              "      <td>2672</td>\n",
              "      <td>3195</td>\n",
              "      <td>3184</td>\n",
              "      <td>2182</td>\n",
              "      <td>3316</td>\n",
              "      <td>3402</td>\n",
              "      <td>3199</td>\n",
              "      <td>3147</td>\n",
              "      <td>2763</td>\n",
              "      <td>2517</td>\n",
              "      <td>2841</td>\n",
              "      <td>3098</td>\n",
              "      <td>...</td>\n",
              "      <td>427</td>\n",
              "      <td>371</td>\n",
              "      <td>301</td>\n",
              "      <td>226</td>\n",
              "      <td>145</td>\n",
              "      <td>92</td>\n",
              "      <td>128</td>\n",
              "      <td>134</td>\n",
              "      <td>92</td>\n",
              "      <td>85</td>\n",
              "      <td>114</td>\n",
              "      <td>140</td>\n",
              "      <td>149</td>\n",
              "      <td>158</td>\n",
              "      <td>159</td>\n",
              "      <td>166</td>\n",
              "      <td>175</td>\n",
              "      <td>160</td>\n",
              "      <td>151</td>\n",
              "      <td>137</td>\n",
              "      <td>141</td>\n",
              "      <td>133</td>\n",
              "      <td>135</td>\n",
              "      <td>132</td>\n",
              "      <td>143</td>\n",
              "      <td>134</td>\n",
              "      <td>123</td>\n",
              "      <td>133</td>\n",
              "      <td>122</td>\n",
              "      <td>117</td>\n",
              "      <td>109</td>\n",
              "      <td>103</td>\n",
              "      <td>83</td>\n",
              "      <td>93</td>\n",
              "      <td>80</td>\n",
              "      <td>69</td>\n",
              "      <td>59</td>\n",
              "      <td>54</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4100</td>\n",
              "      <td>3923</td>\n",
              "      <td>3615</td>\n",
              "      <td>3451</td>\n",
              "      <td>2941</td>\n",
              "      <td>2886</td>\n",
              "      <td>2850</td>\n",
              "      <td>2581</td>\n",
              "      <td>2628</td>\n",
              "      <td>2616</td>\n",
              "      <td>2607</td>\n",
              "      <td>2479</td>\n",
              "      <td>2359</td>\n",
              "      <td>2118</td>\n",
              "      <td>2099</td>\n",
              "      <td>1946</td>\n",
              "      <td>1971</td>\n",
              "      <td>1885</td>\n",
              "      <td>1743</td>\n",
              "      <td>1774</td>\n",
              "      <td>1680</td>\n",
              "      <td>1566</td>\n",
              "      <td>1534</td>\n",
              "      <td>1494</td>\n",
              "      <td>1375</td>\n",
              "      <td>1603</td>\n",
              "      <td>2152</td>\n",
              "      <td>2277</td>\n",
              "      <td>2870</td>\n",
              "      <td>3474</td>\n",
              "      <td>3502</td>\n",
              "      <td>2441</td>\n",
              "      <td>3612</td>\n",
              "      <td>3677</td>\n",
              "      <td>3489</td>\n",
              "      <td>3410</td>\n",
              "      <td>2991</td>\n",
              "      <td>2866</td>\n",
              "      <td>3101</td>\n",
              "      <td>3280</td>\n",
              "      <td>...</td>\n",
              "      <td>365</td>\n",
              "      <td>324</td>\n",
              "      <td>270</td>\n",
              "      <td>199</td>\n",
              "      <td>131</td>\n",
              "      <td>70</td>\n",
              "      <td>95</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>75</td>\n",
              "      <td>98</td>\n",
              "      <td>105</td>\n",
              "      <td>124</td>\n",
              "      <td>134</td>\n",
              "      <td>138</td>\n",
              "      <td>135</td>\n",
              "      <td>140</td>\n",
              "      <td>123</td>\n",
              "      <td>118</td>\n",
              "      <td>111</td>\n",
              "      <td>112</td>\n",
              "      <td>123</td>\n",
              "      <td>119</td>\n",
              "      <td>110</td>\n",
              "      <td>114</td>\n",
              "      <td>103</td>\n",
              "      <td>95</td>\n",
              "      <td>107</td>\n",
              "      <td>98</td>\n",
              "      <td>113</td>\n",
              "      <td>102</td>\n",
              "      <td>85</td>\n",
              "      <td>67</td>\n",
              "      <td>89</td>\n",
              "      <td>79</td>\n",
              "      <td>55</td>\n",
              "      <td>52</td>\n",
              "      <td>51</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3908</td>\n",
              "      <td>3889</td>\n",
              "      <td>3594</td>\n",
              "      <td>3343</td>\n",
              "      <td>2975</td>\n",
              "      <td>2813</td>\n",
              "      <td>2665</td>\n",
              "      <td>2445</td>\n",
              "      <td>2532</td>\n",
              "      <td>2489</td>\n",
              "      <td>2423</td>\n",
              "      <td>2328</td>\n",
              "      <td>2209</td>\n",
              "      <td>2039</td>\n",
              "      <td>1944</td>\n",
              "      <td>1871</td>\n",
              "      <td>1850</td>\n",
              "      <td>1700</td>\n",
              "      <td>1616</td>\n",
              "      <td>1564</td>\n",
              "      <td>1493</td>\n",
              "      <td>1398</td>\n",
              "      <td>1356</td>\n",
              "      <td>1345</td>\n",
              "      <td>1271</td>\n",
              "      <td>1463</td>\n",
              "      <td>2046</td>\n",
              "      <td>2243</td>\n",
              "      <td>2939</td>\n",
              "      <td>3522</td>\n",
              "      <td>3582</td>\n",
              "      <td>2506</td>\n",
              "      <td>3674</td>\n",
              "      <td>3793</td>\n",
              "      <td>3590</td>\n",
              "      <td>3536</td>\n",
              "      <td>3125</td>\n",
              "      <td>2942</td>\n",
              "      <td>3194</td>\n",
              "      <td>3397</td>\n",
              "      <td>...</td>\n",
              "      <td>370</td>\n",
              "      <td>324</td>\n",
              "      <td>263</td>\n",
              "      <td>200</td>\n",
              "      <td>143</td>\n",
              "      <td>68</td>\n",
              "      <td>100</td>\n",
              "      <td>103</td>\n",
              "      <td>85</td>\n",
              "      <td>74</td>\n",
              "      <td>86</td>\n",
              "      <td>111</td>\n",
              "      <td>126</td>\n",
              "      <td>139</td>\n",
              "      <td>147</td>\n",
              "      <td>125</td>\n",
              "      <td>121</td>\n",
              "      <td>125</td>\n",
              "      <td>120</td>\n",
              "      <td>106</td>\n",
              "      <td>116</td>\n",
              "      <td>117</td>\n",
              "      <td>106</td>\n",
              "      <td>110</td>\n",
              "      <td>118</td>\n",
              "      <td>109</td>\n",
              "      <td>107</td>\n",
              "      <td>106</td>\n",
              "      <td>108</td>\n",
              "      <td>103</td>\n",
              "      <td>94</td>\n",
              "      <td>75</td>\n",
              "      <td>61</td>\n",
              "      <td>73</td>\n",
              "      <td>64</td>\n",
              "      <td>50</td>\n",
              "      <td>57</td>\n",
              "      <td>48</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4007</td>\n",
              "      <td>3926</td>\n",
              "      <td>3767</td>\n",
              "      <td>3445</td>\n",
              "      <td>3038</td>\n",
              "      <td>2945</td>\n",
              "      <td>2914</td>\n",
              "      <td>2588</td>\n",
              "      <td>2616</td>\n",
              "      <td>2624</td>\n",
              "      <td>2608</td>\n",
              "      <td>2509</td>\n",
              "      <td>2347</td>\n",
              "      <td>2176</td>\n",
              "      <td>2099</td>\n",
              "      <td>2002</td>\n",
              "      <td>1982</td>\n",
              "      <td>1889</td>\n",
              "      <td>1775</td>\n",
              "      <td>1687</td>\n",
              "      <td>1705</td>\n",
              "      <td>1531</td>\n",
              "      <td>1530</td>\n",
              "      <td>1454</td>\n",
              "      <td>1450</td>\n",
              "      <td>1631</td>\n",
              "      <td>2222</td>\n",
              "      <td>2426</td>\n",
              "      <td>3174</td>\n",
              "      <td>3859</td>\n",
              "      <td>3855</td>\n",
              "      <td>2711</td>\n",
              "      <td>4073</td>\n",
              "      <td>4139</td>\n",
              "      <td>3992</td>\n",
              "      <td>3948</td>\n",
              "      <td>3447</td>\n",
              "      <td>3264</td>\n",
              "      <td>3517</td>\n",
              "      <td>3747</td>\n",
              "      <td>...</td>\n",
              "      <td>380</td>\n",
              "      <td>327</td>\n",
              "      <td>259</td>\n",
              "      <td>198</td>\n",
              "      <td>142</td>\n",
              "      <td>67</td>\n",
              "      <td>102</td>\n",
              "      <td>116</td>\n",
              "      <td>94</td>\n",
              "      <td>68</td>\n",
              "      <td>82</td>\n",
              "      <td>116</td>\n",
              "      <td>127</td>\n",
              "      <td>147</td>\n",
              "      <td>154</td>\n",
              "      <td>118</td>\n",
              "      <td>106</td>\n",
              "      <td>122</td>\n",
              "      <td>120</td>\n",
              "      <td>106</td>\n",
              "      <td>119</td>\n",
              "      <td>106</td>\n",
              "      <td>97</td>\n",
              "      <td>112</td>\n",
              "      <td>119</td>\n",
              "      <td>122</td>\n",
              "      <td>119</td>\n",
              "      <td>113</td>\n",
              "      <td>111</td>\n",
              "      <td>94</td>\n",
              "      <td>88</td>\n",
              "      <td>63</td>\n",
              "      <td>57</td>\n",
              "      <td>62</td>\n",
              "      <td>51</td>\n",
              "      <td>49</td>\n",
              "      <td>56</td>\n",
              "      <td>42</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 146 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    0     1     2     3     4     5     6    ...  139  140  141  142  143  144  145\n",
              "0  3996  3952  3698  3457  3063  2914  2796  ...   89   77   73   60   53   54    0\n",
              "1  3996  3952  3698  3457  3063  2914  2796  ...   93   80   69   59   54   57    0\n",
              "2  4100  3923  3615  3451  2941  2886  2850  ...   89   79   55   52   51   56    0\n",
              "3  3908  3889  3594  3343  2975  2813  2665  ...   73   64   50   57   48   45    0\n",
              "4  4007  3926  3767  3445  3038  2945  2914  ...   62   51   49   56   42   41    0\n",
              "\n",
              "[5 rows x 146 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLWjsfqaLZs0",
        "colab_type": "text"
      },
      "source": [
        "## Droping the rows if ground truth value is zero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlyctDjwLYkb",
        "colab_type": "code",
        "outputId": "e56f4da8-95bc-4001-f9a7-6035ea88a320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Percentage of column which will be droped\",(data.size - data[data.iloc[:, -1] == 0].size)/data.size,\"%\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of column which will be droped 0.008595867208672087 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tJ0vUTCLhZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zero_data = data.index[data.iloc[:, -1] == 0].tolist()\n",
        "data = data[data.iloc[:, -1] != 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE5Gc8BTLiAN",
        "colab_type": "text"
      },
      "source": [
        "# Spliting the data into feature and target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ4dCIbILrwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBvQ4xnt6tQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number_of_classes = len(np.unique(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHPv8SimL1Iu",
        "colab_type": "text"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aMaE8k8L0VV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2, f_classif, mutual_info_classif\n",
        "\n",
        "X = SelectKBest(f_classif, k=int((image.shape[2]+1)*0.75)).fit_transform(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCO0t_-J0G6J",
        "colab_type": "text"
      },
      "source": [
        "# Feature Extraction \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIjIpV160KKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.decomposition import PCA \n",
        "\n",
        "# pca = PCA(n_components = int((image.shape[2]+1)*0.75))\n",
        "# X = pca.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fijfR_5DL9IK",
        "colab_type": "text"
      },
      "source": [
        "# OneHotEncoding in target column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QoUCdAwMBAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "onehotencoder = OneHotEncoder() \n",
        "y = onehotencoder.fit_transform(np.array(y).reshape(-1,1)).toarray() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlNWTtSVMEjl",
        "colab_type": "text"
      },
      "source": [
        "# Standardizing the feature columna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPshPrqEMJvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = preprocessing.scale(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRtV7aDDqr5a",
        "colab_type": "text"
      },
      "source": [
        "# Spliting the data into training and testing set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DattLTVzqr5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.60, random_state=1)#0.25 0.15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OngDFGdDdPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number = int(X_test.shape[0]/2)\n",
        "\n",
        "xx_test = X_test[:number, :]\n",
        "xx_val = X_test[number:, :]\n",
        "\n",
        "if len(y_test.shape) > 1:\n",
        "  loss = keras.losses.categorical_crossentropy\n",
        "  metrics=['accuracy']\n",
        "  yy_test = y_test[:number, :]\n",
        "  yy_val = y_test[number:, :]\n",
        "else:\n",
        "  loss = keras.losses.sparse_categorical_crossentropy\n",
        "  metrics=['sparse_categorical_accuracy']\n",
        "  y_test = [x - 1 for x in y_test]\n",
        "  y_train = [x - 1 for x in y_train]\n",
        "  yy_test = y_test[:number]\n",
        "  yy_val = y_test[number:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M33_KnJNu7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "feature = X.shape[1]\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    X = X.reshape(X.shape[0], 1, feature)\n",
        "    X_train = X_train.reshape(X_train.shape[0], 1, feature)\n",
        "    xx_test = xx_test.reshape(xx_test.shape[0], 1, feature)\n",
        "    xx_val = xx_val.reshape(xx_val.shape[0], 1, feature)\n",
        "    input_shape = (1, feature)\n",
        "else:\n",
        "    X = X.reshape(X.shape[0], feature, 1)\n",
        "    X_train = X_train.reshape(X_train.shape[0], feature, 1)\n",
        "    xx_test = xx_test.reshape(xx_test.shape[0], feature, 1)\n",
        "    xx_val = xx_val.reshape(xx_val.shape[0], feature, 1)\n",
        "    input_shape = (feature, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQLkUnZ_YsYO",
        "colab_type": "text"
      },
      "source": [
        "# Genetic Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-9MDtAugFbk",
        "colab_type": "code",
        "outputId": "c7966da0-fb80-43e1-b8a3-2c8acb316994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install pyeasyga"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyeasyga in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pyeasyga) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlapBK49M2QU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D, BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bAr5dYIYrxF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b977cd45-6b54-4d5c-83ae-0b4c331a10f3"
      },
      "source": [
        "from pyeasyga import pyeasyga\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import keras\n",
        "import time\n",
        "\n",
        "count = 1\n",
        "\n",
        "def initilialize_population():\n",
        "    filter_1 = list(x for x in range(1, 11))\n",
        "    filter_2 = list(x for x in range(11, 31))\n",
        "    filter_3 = list(x for x in range(31, 61))\n",
        "    filter_4 = list(x for x in range(61, 101))\n",
        "\n",
        "    kernel_size_1 = [2,3]\n",
        "    kernel_size_2 = [2,3]\n",
        "    kernel_size_3 = [2,3]\n",
        "    kernel_size_4 = [2,3]\n",
        "\n",
        "\n",
        "    population = []\n",
        "    population.append(filter_1)\n",
        "    population.append(filter_2)\n",
        "    population.append(filter_3)\n",
        "    population.append(filter_4)\n",
        "    population.append(kernel_size_1)\n",
        "    population.append(kernel_size_2)\n",
        "    population.append(kernel_size_3)\n",
        "    population.append(kernel_size_4)\n",
        "\n",
        "    return list(population)\n",
        "\n",
        "def create_individual(data):\n",
        "  choice = []\n",
        "  for i in range(len(data)):\n",
        "    choice.append(random.choice(list(range(len(data[i])))))\n",
        "  return choice\n",
        "\n",
        "def fitness_function(individual, data):\n",
        "  global count\n",
        "  print('Individual no', count)\n",
        "  count += 1\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(filters=data[0][individual[0]], kernel_size=data[4][individual[4]], activation='relu', input_shape=input_shape))\n",
        "  model.add(Conv1D(filters=data[0][individual[0]], kernel_size=data[4][individual[4]], activation='relu', input_shape=input_shape))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Conv1D(filters=data[1][individual[1]], kernel_size=data[5][individual[5]], activation='relu'))\n",
        "  model.add(Conv1D(filters=data[1][individual[1]], kernel_size=data[5][individual[5]], activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Conv1D(filters=data[2][individual[2]], kernel_size=data[6][individual[6]], activation='relu'))\n",
        "  model.add(Conv1D(filters=data[2][individual[2]], kernel_size=data[6][individual[6]], activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Conv1D(filters=data[3][individual[3]], kernel_size=data[7][individual[7]], activation='relu'))\n",
        "  model.add(Conv1D(filters=data[3][individual[3]], kernel_size=data[7][individual[7]], activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(number_of_classes, activation='softmax'))\n",
        "\n",
        "  model.compile(loss=loss,\n",
        "                optimizer=keras.optimizers.Adadelta(),\n",
        "                metrics=metrics)\n",
        "\n",
        "  model.fit(X_train, np.array(y_train),\n",
        "            batch_size=128,\n",
        "            epochs=25,\n",
        "            verbose=1,\n",
        "            validation_data=(xx_val,np.array(yy_val)))\n",
        "\n",
        "\n",
        "  score = model.evaluate(xx_test, np.array(yy_test), verbose=1)[1]\n",
        "  # prediction = model.predict(X_test)\n",
        "  # score = accuracy_score(y_test, prediction)\n",
        "  print('Score is', score)\n",
        "  return score\n",
        "  \n",
        "data = initilialize_population()\n",
        "ga = pyeasyga.GeneticAlgorithm(seed_data=data,\n",
        "                               population_size=5,\n",
        "                               generations=5,\n",
        "                               crossover_probability=0.8,\n",
        "                               mutation_probability=0.4,\n",
        "                               elitism=True,\n",
        "                               maximise_fitness=True)\n",
        "ga.create_individual = create_individual\n",
        "ga.fitness_function = fitness_function\n",
        "\n",
        "start = time.time()\n",
        "ga.run()\n",
        "end = time.time()\n",
        "print('Time taken ------>', end-start)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Individual no 1\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.9248 - accuracy: 0.1139 - val_loss: 2.6320 - val_accuracy: 0.0626\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 0s 374us/step - loss: 2.4030 - accuracy: 0.2309 - val_loss: 2.6242 - val_accuracy: 0.1559\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 0s 382us/step - loss: 2.1721 - accuracy: 0.2933 - val_loss: 2.6170 - val_accuracy: 0.1600\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 0s 380us/step - loss: 2.0381 - accuracy: 0.3433 - val_loss: 2.6057 - val_accuracy: 0.0882\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 0s 378us/step - loss: 1.9173 - accuracy: 0.3687 - val_loss: 2.6122 - val_accuracy: 0.1374\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 0s 376us/step - loss: 1.8089 - accuracy: 0.4088 - val_loss: 2.5970 - val_accuracy: 0.0913\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 387us/step - loss: 1.7488 - accuracy: 0.4457 - val_loss: 2.5869 - val_accuracy: 0.0697\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 0s 377us/step - loss: 1.6715 - accuracy: 0.4773 - val_loss: 2.5838 - val_accuracy: 0.0697\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 0s 375us/step - loss: 1.5854 - accuracy: 0.5135 - val_loss: 2.5776 - val_accuracy: 0.0697\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 0s 383us/step - loss: 1.5418 - accuracy: 0.5212 - val_loss: 2.5983 - val_accuracy: 0.0697\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 0s 382us/step - loss: 1.4786 - accuracy: 0.5651 - val_loss: 2.5971 - val_accuracy: 0.0697\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 0s 376us/step - loss: 1.4401 - accuracy: 0.5743 - val_loss: 2.5951 - val_accuracy: 0.0697\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 0s 370us/step - loss: 1.3730 - accuracy: 0.5804 - val_loss: 2.5821 - val_accuracy: 0.0697\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 0s 376us/step - loss: 1.3529 - accuracy: 0.5905 - val_loss: 2.5776 - val_accuracy: 0.0697\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 0s 368us/step - loss: 1.3169 - accuracy: 0.6012 - val_loss: 2.5929 - val_accuracy: 0.0697\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 0s 380us/step - loss: 1.2982 - accuracy: 0.6020 - val_loss: 2.5407 - val_accuracy: 0.0749\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 0s 366us/step - loss: 1.2446 - accuracy: 0.6228 - val_loss: 2.5601 - val_accuracy: 0.0718\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 0s 382us/step - loss: 1.2186 - accuracy: 0.6289 - val_loss: 2.5500 - val_accuracy: 0.1292\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 0s 371us/step - loss: 1.1746 - accuracy: 0.6313 - val_loss: 2.5014 - val_accuracy: 0.1292\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 0s 383us/step - loss: 1.1528 - accuracy: 0.6559 - val_loss: 2.4948 - val_accuracy: 0.0892\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 0s 372us/step - loss: 1.1195 - accuracy: 0.6713 - val_loss: 2.4507 - val_accuracy: 0.1415\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 0s 380us/step - loss: 1.0930 - accuracy: 0.6721 - val_loss: 2.4657 - val_accuracy: 0.2174\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 0s 373us/step - loss: 1.0813 - accuracy: 0.6898 - val_loss: 2.3862 - val_accuracy: 0.2174\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 0s 379us/step - loss: 1.0166 - accuracy: 0.6836 - val_loss: 2.3032 - val_accuracy: 0.2513\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 0s 373us/step - loss: 0.9967 - accuracy: 0.6998 - val_loss: 2.1972 - val_accuracy: 0.2923\n",
            "974/974 [==============================] - 0s 131us/step\n",
            "Score is 0.290554404258728\n",
            "Individual no 2\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.7109 - accuracy: 0.1555 - val_loss: 2.6353 - val_accuracy: 0.0759\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 402us/step - loss: 2.1156 - accuracy: 0.3149 - val_loss: 2.6402 - val_accuracy: 0.0872\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 1s 413us/step - loss: 1.8589 - accuracy: 0.4211 - val_loss: 2.6483 - val_accuracy: 0.0738\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 423us/step - loss: 1.6911 - accuracy: 0.4681 - val_loss: 2.6662 - val_accuracy: 0.0738\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 1s 430us/step - loss: 1.6016 - accuracy: 0.5119 - val_loss: 2.6800 - val_accuracy: 0.0738\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 430us/step - loss: 1.5123 - accuracy: 0.5381 - val_loss: 2.7096 - val_accuracy: 0.0738\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 439us/step - loss: 1.4375 - accuracy: 0.5681 - val_loss: 2.7246 - val_accuracy: 0.0738\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 1s 436us/step - loss: 1.3560 - accuracy: 0.5905 - val_loss: 2.7543 - val_accuracy: 0.0738\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 421us/step - loss: 1.3412 - accuracy: 0.6082 - val_loss: 2.7892 - val_accuracy: 0.1056\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 1s 432us/step - loss: 1.2689 - accuracy: 0.6236 - val_loss: 2.8064 - val_accuracy: 0.0738\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 425us/step - loss: 1.2205 - accuracy: 0.6251 - val_loss: 2.8494 - val_accuracy: 0.0738\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 449us/step - loss: 1.1578 - accuracy: 0.6582 - val_loss: 2.8644 - val_accuracy: 0.1005\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 425us/step - loss: 1.1255 - accuracy: 0.6636 - val_loss: 2.8736 - val_accuracy: 0.0738\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 1s 430us/step - loss: 1.0973 - accuracy: 0.6697 - val_loss: 2.8910 - val_accuracy: 0.1036\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 427us/step - loss: 1.0291 - accuracy: 0.7052 - val_loss: 2.9470 - val_accuracy: 0.0708\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 434us/step - loss: 1.0554 - accuracy: 0.6774 - val_loss: 2.8741 - val_accuracy: 0.1046\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 429us/step - loss: 0.9940 - accuracy: 0.7028 - val_loss: 2.8812 - val_accuracy: 0.1067\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 1s 431us/step - loss: 0.9640 - accuracy: 0.7182 - val_loss: 2.9899 - val_accuracy: 0.0574\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 1s 434us/step - loss: 0.9503 - accuracy: 0.7044 - val_loss: 2.8544 - val_accuracy: 0.0974\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 426us/step - loss: 0.9150 - accuracy: 0.7298 - val_loss: 2.9155 - val_accuracy: 0.0687\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 447us/step - loss: 0.9134 - accuracy: 0.7498 - val_loss: 2.8218 - val_accuracy: 0.0831\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 423us/step - loss: 0.8740 - accuracy: 0.7360 - val_loss: 2.7734 - val_accuracy: 0.0903\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 421us/step - loss: 0.8515 - accuracy: 0.7552 - val_loss: 2.7270 - val_accuracy: 0.1005\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 409us/step - loss: 0.8795 - accuracy: 0.7406 - val_loss: 2.5941 - val_accuracy: 0.1149\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 416us/step - loss: 0.8130 - accuracy: 0.7529 - val_loss: 2.6112 - val_accuracy: 0.0933\n",
            "974/974 [==============================] - 0s 131us/step\n",
            "Score is 0.09958932548761368\n",
            "Individual no 3\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.6136 - accuracy: 0.1609 - val_loss: 2.6361 - val_accuracy: 0.0985\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 453us/step - loss: 2.0234 - accuracy: 0.3187 - val_loss: 2.6339 - val_accuracy: 0.0985\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 1.8347 - accuracy: 0.4095 - val_loss: 2.6353 - val_accuracy: 0.0985\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 1.7521 - accuracy: 0.4311 - val_loss: 2.6396 - val_accuracy: 0.0985\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 1s 469us/step - loss: 1.6361 - accuracy: 0.4834 - val_loss: 2.6473 - val_accuracy: 0.0985\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 453us/step - loss: 1.5727 - accuracy: 0.5135 - val_loss: 2.6542 - val_accuracy: 0.1067\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 1.5012 - accuracy: 0.5273 - val_loss: 2.6587 - val_accuracy: 0.1682\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 1.4231 - accuracy: 0.5851 - val_loss: 2.6714 - val_accuracy: 0.1374\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 1.3984 - accuracy: 0.5758 - val_loss: 2.6864 - val_accuracy: 0.1559\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 1.3526 - accuracy: 0.5958 - val_loss: 2.6994 - val_accuracy: 0.0779\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 1.2756 - accuracy: 0.6274 - val_loss: 2.6930 - val_accuracy: 0.1333\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 467us/step - loss: 1.2107 - accuracy: 0.6505 - val_loss: 2.6969 - val_accuracy: 0.1651\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 451us/step - loss: 1.1969 - accuracy: 0.6497 - val_loss: 2.6951 - val_accuracy: 0.1456\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 1s 471us/step - loss: 1.1524 - accuracy: 0.6721 - val_loss: 2.7144 - val_accuracy: 0.1436\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 1.1725 - accuracy: 0.6682 - val_loss: 2.6785 - val_accuracy: 0.1774\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 1.1220 - accuracy: 0.6690 - val_loss: 2.7248 - val_accuracy: 0.1087\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 453us/step - loss: 1.0893 - accuracy: 0.6859 - val_loss: 2.7036 - val_accuracy: 0.1005\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 1.0345 - accuracy: 0.6998 - val_loss: 2.6639 - val_accuracy: 0.1764\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 0.9631 - accuracy: 0.7236 - val_loss: 2.6100 - val_accuracy: 0.1733\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 0.9693 - accuracy: 0.7129 - val_loss: 2.6092 - val_accuracy: 0.1867\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 449us/step - loss: 0.9534 - accuracy: 0.7236 - val_loss: 2.6268 - val_accuracy: 0.1538\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 0.9532 - accuracy: 0.7229 - val_loss: 2.6127 - val_accuracy: 0.1333\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 451us/step - loss: 0.8918 - accuracy: 0.7467 - val_loss: 2.5061 - val_accuracy: 0.1621\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 0.8952 - accuracy: 0.7167 - val_loss: 2.3624 - val_accuracy: 0.2277\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 447us/step - loss: 0.8817 - accuracy: 0.7467 - val_loss: 2.3357 - val_accuracy: 0.2133\n",
            "974/974 [==============================] - 0s 165us/step\n",
            "Score is 0.23408624529838562\n",
            "Individual no 4\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.8665 - accuracy: 0.1470 - val_loss: 2.6408 - val_accuracy: 0.0759\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 424us/step - loss: 2.4053 - accuracy: 0.2510 - val_loss: 2.6419 - val_accuracy: 0.0759\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 1s 417us/step - loss: 2.1720 - accuracy: 0.3133 - val_loss: 2.6475 - val_accuracy: 0.0759\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 435us/step - loss: 2.0337 - accuracy: 0.3472 - val_loss: 2.6552 - val_accuracy: 0.0759\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 1s 417us/step - loss: 1.8943 - accuracy: 0.3995 - val_loss: 2.6686 - val_accuracy: 0.0759\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 429us/step - loss: 1.8178 - accuracy: 0.3957 - val_loss: 2.6802 - val_accuracy: 0.0759\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 416us/step - loss: 1.7416 - accuracy: 0.4349 - val_loss: 2.6844 - val_accuracy: 0.0759\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 1s 444us/step - loss: 1.6895 - accuracy: 0.4396 - val_loss: 2.7033 - val_accuracy: 0.0759\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 435us/step - loss: 1.6074 - accuracy: 0.4550 - val_loss: 2.7157 - val_accuracy: 0.0759\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 1s 422us/step - loss: 1.6008 - accuracy: 0.4673 - val_loss: 2.7408 - val_accuracy: 0.0759\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 417us/step - loss: 1.5761 - accuracy: 0.4796 - val_loss: 2.7538 - val_accuracy: 0.0759\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 415us/step - loss: 1.5056 - accuracy: 0.4942 - val_loss: 2.7607 - val_accuracy: 0.0759\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 424us/step - loss: 1.4866 - accuracy: 0.4865 - val_loss: 2.7761 - val_accuracy: 0.0759\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 1s 418us/step - loss: 1.4410 - accuracy: 0.5081 - val_loss: 2.7885 - val_accuracy: 0.0759\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 431us/step - loss: 1.4296 - accuracy: 0.5096 - val_loss: 2.7780 - val_accuracy: 0.0759\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 406us/step - loss: 1.4037 - accuracy: 0.5327 - val_loss: 2.7889 - val_accuracy: 0.0759\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 429us/step - loss: 1.3759 - accuracy: 0.5404 - val_loss: 2.7994 - val_accuracy: 0.0759\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 1s 413us/step - loss: 1.3082 - accuracy: 0.5473 - val_loss: 2.8298 - val_accuracy: 0.0759\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 1s 428us/step - loss: 1.2861 - accuracy: 0.5689 - val_loss: 2.8174 - val_accuracy: 0.0759\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 423us/step - loss: 1.2887 - accuracy: 0.5543 - val_loss: 2.8337 - val_accuracy: 0.0759\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 426us/step - loss: 1.2438 - accuracy: 0.5689 - val_loss: 2.8259 - val_accuracy: 0.0759\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 426us/step - loss: 1.2570 - accuracy: 0.5704 - val_loss: 2.7730 - val_accuracy: 0.1272\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 416us/step - loss: 1.2369 - accuracy: 0.5812 - val_loss: 2.7696 - val_accuracy: 0.1097\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 431us/step - loss: 1.2106 - accuracy: 0.5897 - val_loss: 2.7680 - val_accuracy: 0.0851\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 422us/step - loss: 1.1999 - accuracy: 0.5858 - val_loss: 2.8230 - val_accuracy: 0.1364\n",
            "974/974 [==============================] - 0s 145us/step\n",
            "Score is 0.12731006741523743\n",
            "Individual no 5\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.5220 - accuracy: 0.1948 - val_loss: 2.6308 - val_accuracy: 0.1682\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 2.0477 - accuracy: 0.3272 - val_loss: 2.6331 - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 1s 472us/step - loss: 1.7849 - accuracy: 0.4249 - val_loss: 2.6371 - val_accuracy: 0.0985\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 473us/step - loss: 1.6136 - accuracy: 0.4881 - val_loss: 2.6394 - val_accuracy: 0.0985\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 1s 478us/step - loss: 1.5100 - accuracy: 0.5242 - val_loss: 2.6382 - val_accuracy: 0.0985\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 475us/step - loss: 1.4842 - accuracy: 0.5366 - val_loss: 2.6342 - val_accuracy: 0.0985\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 475us/step - loss: 1.3473 - accuracy: 0.5982 - val_loss: 2.6380 - val_accuracy: 0.0985\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 1s 480us/step - loss: 1.3289 - accuracy: 0.5935 - val_loss: 2.6452 - val_accuracy: 0.1190\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 477us/step - loss: 1.3014 - accuracy: 0.6082 - val_loss: 2.6323 - val_accuracy: 0.1549\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 1s 480us/step - loss: 1.2487 - accuracy: 0.6174 - val_loss: 2.6672 - val_accuracy: 0.1559\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 486us/step - loss: 1.1889 - accuracy: 0.6551 - val_loss: 2.6597 - val_accuracy: 0.1559\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 468us/step - loss: 1.1666 - accuracy: 0.6451 - val_loss: 2.6704 - val_accuracy: 0.1262\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 483us/step - loss: 1.1295 - accuracy: 0.6613 - val_loss: 2.6396 - val_accuracy: 0.1559\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 1s 473us/step - loss: 1.1056 - accuracy: 0.6705 - val_loss: 2.6279 - val_accuracy: 0.1559\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 479us/step - loss: 1.0797 - accuracy: 0.6705 - val_loss: 2.6277 - val_accuracy: 0.1559\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 493us/step - loss: 1.0214 - accuracy: 0.7052 - val_loss: 2.6354 - val_accuracy: 0.0882\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 478us/step - loss: 1.0403 - accuracy: 0.6674 - val_loss: 2.6631 - val_accuracy: 0.0574\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 1s 481us/step - loss: 0.9753 - accuracy: 0.7167 - val_loss: 2.6036 - val_accuracy: 0.1067\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 1s 490us/step - loss: 0.9732 - accuracy: 0.7021 - val_loss: 2.5246 - val_accuracy: 0.1210\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 471us/step - loss: 0.9620 - accuracy: 0.7021 - val_loss: 2.4456 - val_accuracy: 0.1128\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 487us/step - loss: 0.9326 - accuracy: 0.7375 - val_loss: 2.4866 - val_accuracy: 0.1364\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 480us/step - loss: 0.9069 - accuracy: 0.7167 - val_loss: 2.5615 - val_accuracy: 0.1549\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 483us/step - loss: 0.9034 - accuracy: 0.7113 - val_loss: 2.4098 - val_accuracy: 0.1528\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 480us/step - loss: 0.8683 - accuracy: 0.7467 - val_loss: 2.3653 - val_accuracy: 0.1959\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 473us/step - loss: 0.8449 - accuracy: 0.7460 - val_loss: 2.2977 - val_accuracy: 0.1713\n",
            "974/974 [==============================] - 0s 162us/step\n",
            "Score is 0.18891170620918274\n",
            "Individual no 6\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.8758 - accuracy: 0.1032 - val_loss: 2.6311 - val_accuracy: 0.0738\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 389us/step - loss: 2.4384 - accuracy: 0.1832 - val_loss: 2.6349 - val_accuracy: 0.0738\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 0s 374us/step - loss: 2.2812 - accuracy: 0.2348 - val_loss: 2.6432 - val_accuracy: 0.0738\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 0s 374us/step - loss: 2.0971 - accuracy: 0.3079 - val_loss: 2.6546 - val_accuracy: 0.0738\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 0s 384us/step - loss: 1.9958 - accuracy: 0.3449 - val_loss: 2.6641 - val_accuracy: 0.0944\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 0s 373us/step - loss: 1.9225 - accuracy: 0.3549 - val_loss: 2.6826 - val_accuracy: 0.0882\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 0s 382us/step - loss: 1.8328 - accuracy: 0.3895 - val_loss: 2.6958 - val_accuracy: 0.0882\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 0s 375us/step - loss: 1.7865 - accuracy: 0.3980 - val_loss: 2.7124 - val_accuracy: 0.0882\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 394us/step - loss: 1.7339 - accuracy: 0.4049 - val_loss: 2.7310 - val_accuracy: 0.0882\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 0s 377us/step - loss: 1.7021 - accuracy: 0.4396 - val_loss: 2.7263 - val_accuracy: 0.0882\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 0s 378us/step - loss: 1.6576 - accuracy: 0.4457 - val_loss: 2.7262 - val_accuracy: 0.0882\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 0s 385us/step - loss: 1.6298 - accuracy: 0.4580 - val_loss: 2.7574 - val_accuracy: 0.0882\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 389us/step - loss: 1.5962 - accuracy: 0.4565 - val_loss: 2.7673 - val_accuracy: 0.0882\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 0s 380us/step - loss: 1.5330 - accuracy: 0.4696 - val_loss: 2.7527 - val_accuracy: 0.0882\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 0s 380us/step - loss: 1.4983 - accuracy: 0.5050 - val_loss: 2.7512 - val_accuracy: 0.1179\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 0s 380us/step - loss: 1.5175 - accuracy: 0.4958 - val_loss: 2.7100 - val_accuracy: 0.1692\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 0s 378us/step - loss: 1.4446 - accuracy: 0.5289 - val_loss: 2.6335 - val_accuracy: 0.1744\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 0s 378us/step - loss: 1.4232 - accuracy: 0.5266 - val_loss: 2.6421 - val_accuracy: 0.1836\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 0s 378us/step - loss: 1.3705 - accuracy: 0.5458 - val_loss: 2.6037 - val_accuracy: 0.1744\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 0s 373us/step - loss: 1.3397 - accuracy: 0.5604 - val_loss: 2.5145 - val_accuracy: 0.1928\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 388us/step - loss: 1.3322 - accuracy: 0.5604 - val_loss: 2.4960 - val_accuracy: 0.1877\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 0s 376us/step - loss: 1.3148 - accuracy: 0.5597 - val_loss: 2.4261 - val_accuracy: 0.2318\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 0s 383us/step - loss: 1.2968 - accuracy: 0.5627 - val_loss: 2.3918 - val_accuracy: 0.2400\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 0s 377us/step - loss: 1.2541 - accuracy: 0.5874 - val_loss: 2.2709 - val_accuracy: 0.2615\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 0s 382us/step - loss: 1.2542 - accuracy: 0.5881 - val_loss: 2.1446 - val_accuracy: 0.3210\n",
            "974/974 [==============================] - 0s 137us/step\n",
            "Score is 0.30082136392593384\n",
            "Individual no 7\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.7857 - accuracy: 0.1455 - val_loss: 2.6369 - val_accuracy: 0.0800\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 0s 379us/step - loss: 2.2502 - accuracy: 0.2794 - val_loss: 2.6377 - val_accuracy: 0.0800\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 0s 385us/step - loss: 2.0269 - accuracy: 0.3364 - val_loss: 2.6377 - val_accuracy: 0.0800\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 0s 374us/step - loss: 1.8897 - accuracy: 0.4157 - val_loss: 2.6408 - val_accuracy: 0.0800\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 0s 384us/step - loss: 1.7612 - accuracy: 0.4565 - val_loss: 2.6459 - val_accuracy: 0.0800\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 0s 378us/step - loss: 1.6767 - accuracy: 0.4927 - val_loss: 2.6520 - val_accuracy: 0.0800\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 0s 384us/step - loss: 1.6124 - accuracy: 0.5027 - val_loss: 2.6580 - val_accuracy: 0.0800\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 0s 381us/step - loss: 1.5516 - accuracy: 0.5181 - val_loss: 2.6637 - val_accuracy: 0.0800\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 0s 377us/step - loss: 1.4625 - accuracy: 0.5396 - val_loss: 2.6773 - val_accuracy: 0.0800\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 0s 378us/step - loss: 1.4308 - accuracy: 0.5612 - val_loss: 2.6952 - val_accuracy: 0.0800\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 390us/step - loss: 1.3486 - accuracy: 0.6043 - val_loss: 2.7127 - val_accuracy: 0.0800\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 0s 375us/step - loss: 1.3094 - accuracy: 0.6043 - val_loss: 2.7348 - val_accuracy: 0.0800\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 0s 383us/step - loss: 1.2980 - accuracy: 0.6089 - val_loss: 2.7859 - val_accuracy: 0.0800\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 0s 376us/step - loss: 1.2571 - accuracy: 0.6289 - val_loss: 2.7787 - val_accuracy: 0.0800\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 386us/step - loss: 1.2296 - accuracy: 0.6313 - val_loss: 2.8378 - val_accuracy: 0.0800\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 0s 378us/step - loss: 1.1870 - accuracy: 0.6405 - val_loss: 2.9134 - val_accuracy: 0.0800\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 390us/step - loss: 1.1319 - accuracy: 0.6674 - val_loss: 2.9376 - val_accuracy: 0.0800\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 0s 383us/step - loss: 1.1327 - accuracy: 0.6605 - val_loss: 3.0288 - val_accuracy: 0.0800\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 0s 383us/step - loss: 1.1135 - accuracy: 0.6659 - val_loss: 3.1170 - val_accuracy: 0.0800\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 0s 383us/step - loss: 1.0538 - accuracy: 0.6882 - val_loss: 3.2177 - val_accuracy: 0.0800\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 0s 377us/step - loss: 1.0318 - accuracy: 0.6844 - val_loss: 3.3303 - val_accuracy: 0.0800\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 397us/step - loss: 1.0106 - accuracy: 0.6959 - val_loss: 3.2574 - val_accuracy: 0.0800\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 388us/step - loss: 0.9662 - accuracy: 0.7159 - val_loss: 3.4519 - val_accuracy: 0.0800\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 386us/step - loss: 0.9463 - accuracy: 0.7082 - val_loss: 3.4905 - val_accuracy: 0.0800\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 393us/step - loss: 0.9322 - accuracy: 0.7090 - val_loss: 3.5570 - val_accuracy: 0.0800\n",
            "974/974 [==============================] - 0s 136us/step\n",
            "Score is 0.09137576818466187\n",
            "Individual no 8\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.6509 - accuracy: 0.1717 - val_loss: 2.6356 - val_accuracy: 0.0749\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 2.1967 - accuracy: 0.2948 - val_loss: 2.6387 - val_accuracy: 0.0749\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 1s 476us/step - loss: 1.9789 - accuracy: 0.3641 - val_loss: 2.6429 - val_accuracy: 0.0749\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.8298 - accuracy: 0.4273 - val_loss: 2.6494 - val_accuracy: 0.0749\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 1s 474us/step - loss: 1.8016 - accuracy: 0.4442 - val_loss: 2.6568 - val_accuracy: 0.0759\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 1.7246 - accuracy: 0.4573 - val_loss: 2.6661 - val_accuracy: 0.0759\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 1.6052 - accuracy: 0.5189 - val_loss: 2.6724 - val_accuracy: 0.0759\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 1s 470us/step - loss: 1.5606 - accuracy: 0.5435 - val_loss: 2.6794 - val_accuracy: 0.0759\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.5454 - accuracy: 0.5189 - val_loss: 2.6940 - val_accuracy: 0.0759\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 1s 484us/step - loss: 1.4525 - accuracy: 0.5735 - val_loss: 2.6892 - val_accuracy: 0.0759\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 472us/step - loss: 1.3952 - accuracy: 0.5989 - val_loss: 2.7147 - val_accuracy: 0.0749\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 459us/step - loss: 1.3837 - accuracy: 0.6059 - val_loss: 2.6992 - val_accuracy: 0.0995\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 482us/step - loss: 1.3090 - accuracy: 0.6143 - val_loss: 2.7021 - val_accuracy: 0.1118\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 1.2746 - accuracy: 0.6320 - val_loss: 2.6954 - val_accuracy: 0.0738\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 470us/step - loss: 1.2150 - accuracy: 0.6451 - val_loss: 2.6622 - val_accuracy: 0.1313\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 476us/step - loss: 1.1797 - accuracy: 0.6497 - val_loss: 2.6854 - val_accuracy: 0.0862\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 467us/step - loss: 1.1420 - accuracy: 0.6828 - val_loss: 2.6761 - val_accuracy: 0.1036\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 1s 466us/step - loss: 1.1307 - accuracy: 0.6628 - val_loss: 2.6121 - val_accuracy: 0.1077\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 1s 459us/step - loss: 1.0870 - accuracy: 0.7067 - val_loss: 2.5586 - val_accuracy: 0.1323\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 470us/step - loss: 1.0366 - accuracy: 0.7105 - val_loss: 2.4652 - val_accuracy: 0.2513\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 471us/step - loss: 0.9951 - accuracy: 0.7129 - val_loss: 2.4674 - val_accuracy: 0.2185\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 1.0137 - accuracy: 0.7082 - val_loss: 2.3058 - val_accuracy: 0.2523\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 480us/step - loss: 0.9914 - accuracy: 0.7082 - val_loss: 2.2948 - val_accuracy: 0.2615\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 0.9436 - accuracy: 0.7375 - val_loss: 2.2959 - val_accuracy: 0.2738\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 468us/step - loss: 0.9406 - accuracy: 0.7244 - val_loss: 2.2649 - val_accuracy: 0.3221\n",
            "974/974 [==============================] - 0s 161us/step\n",
            "Score is 0.36036962270736694\n",
            "Individual no 9\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.6294 - accuracy: 0.1640 - val_loss: 2.6328 - val_accuracy: 0.0882\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 470us/step - loss: 2.1483 - accuracy: 0.2995 - val_loss: 2.6316 - val_accuracy: 0.0882\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 1s 452us/step - loss: 1.9357 - accuracy: 0.3726 - val_loss: 2.6310 - val_accuracy: 0.0882\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 1.8352 - accuracy: 0.4211 - val_loss: 2.6259 - val_accuracy: 0.1272\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 1.6707 - accuracy: 0.4965 - val_loss: 2.6280 - val_accuracy: 0.1077\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 470us/step - loss: 1.6185 - accuracy: 0.5343 - val_loss: 2.6131 - val_accuracy: 0.0944\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 1.5652 - accuracy: 0.5242 - val_loss: 2.6294 - val_accuracy: 0.0574\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 1.4730 - accuracy: 0.5620 - val_loss: 2.6218 - val_accuracy: 0.0574\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 1.4232 - accuracy: 0.5889 - val_loss: 2.6213 - val_accuracy: 0.0574\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 1.3514 - accuracy: 0.6035 - val_loss: 2.6098 - val_accuracy: 0.0574\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 494us/step - loss: 1.2962 - accuracy: 0.6259 - val_loss: 2.6137 - val_accuracy: 0.0574\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 518us/step - loss: 1.2511 - accuracy: 0.6605 - val_loss: 2.6021 - val_accuracy: 0.0605\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 484us/step - loss: 1.2296 - accuracy: 0.6320 - val_loss: 2.5181 - val_accuracy: 0.1467\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 1s 474us/step - loss: 1.1977 - accuracy: 0.6636 - val_loss: 2.5022 - val_accuracy: 0.1508\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 1.1727 - accuracy: 0.6482 - val_loss: 2.5159 - val_accuracy: 0.1528\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 468us/step - loss: 1.1191 - accuracy: 0.6759 - val_loss: 2.4709 - val_accuracy: 0.1867\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 468us/step - loss: 1.0872 - accuracy: 0.6798 - val_loss: 2.4245 - val_accuracy: 0.1887\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.0922 - accuracy: 0.6705 - val_loss: 2.3893 - val_accuracy: 0.1744\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 1s 473us/step - loss: 1.0843 - accuracy: 0.6890 - val_loss: 2.3553 - val_accuracy: 0.1949\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 479us/step - loss: 1.0061 - accuracy: 0.6959 - val_loss: 2.2959 - val_accuracy: 0.2267\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 476us/step - loss: 1.0006 - accuracy: 0.7121 - val_loss: 2.3515 - val_accuracy: 0.1692\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 491us/step - loss: 1.0159 - accuracy: 0.7005 - val_loss: 2.2276 - val_accuracy: 0.2246\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 494us/step - loss: 0.9697 - accuracy: 0.7275 - val_loss: 2.2630 - val_accuracy: 0.2226\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 493us/step - loss: 0.9285 - accuracy: 0.7275 - val_loss: 2.1629 - val_accuracy: 0.2062\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 490us/step - loss: 0.9247 - accuracy: 0.7360 - val_loss: 2.0534 - val_accuracy: 0.3097\n",
            "974/974 [==============================] - 0s 180us/step\n",
            "Score is 0.29671457409858704\n",
            "Individual no 10\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.8000 - accuracy: 0.1109 - val_loss: 2.6417 - val_accuracy: 0.0697\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 439us/step - loss: 2.1788 - accuracy: 0.2587 - val_loss: 2.6415 - val_accuracy: 0.0328\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 1s 427us/step - loss: 1.9697 - accuracy: 0.3626 - val_loss: 2.6433 - val_accuracy: 0.1056\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 444us/step - loss: 1.7726 - accuracy: 0.4095 - val_loss: 2.6487 - val_accuracy: 0.1118\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 1s 423us/step - loss: 1.6891 - accuracy: 0.4634 - val_loss: 2.6554 - val_accuracy: 0.1046\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 445us/step - loss: 1.5842 - accuracy: 0.4865 - val_loss: 2.6660 - val_accuracy: 0.0862\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 436us/step - loss: 1.4734 - accuracy: 0.5497 - val_loss: 2.6624 - val_accuracy: 0.0738\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 1s 432us/step - loss: 1.4324 - accuracy: 0.5504 - val_loss: 2.6623 - val_accuracy: 0.0749\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 445us/step - loss: 1.3779 - accuracy: 0.5812 - val_loss: 2.6672 - val_accuracy: 0.0749\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 1s 430us/step - loss: 1.3782 - accuracy: 0.5689 - val_loss: 2.6647 - val_accuracy: 0.0749\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 432us/step - loss: 1.2959 - accuracy: 0.5928 - val_loss: 2.6788 - val_accuracy: 0.1231\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.2837 - accuracy: 0.5966 - val_loss: 2.6513 - val_accuracy: 0.0759\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 441us/step - loss: 1.2229 - accuracy: 0.6189 - val_loss: 2.6592 - val_accuracy: 0.1138\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 1s 436us/step - loss: 1.1971 - accuracy: 0.6259 - val_loss: 2.6680 - val_accuracy: 0.0749\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 428us/step - loss: 1.1790 - accuracy: 0.6313 - val_loss: 2.6272 - val_accuracy: 0.0779\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 434us/step - loss: 1.1252 - accuracy: 0.6528 - val_loss: 2.6447 - val_accuracy: 0.0769\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 431us/step - loss: 1.0777 - accuracy: 0.6697 - val_loss: 2.6512 - val_accuracy: 0.0779\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 1s 439us/step - loss: 1.0366 - accuracy: 0.6982 - val_loss: 2.6092 - val_accuracy: 0.1436\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 1s 423us/step - loss: 1.0393 - accuracy: 0.6967 - val_loss: 2.6848 - val_accuracy: 0.1200\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 434us/step - loss: 1.0199 - accuracy: 0.6851 - val_loss: 2.6704 - val_accuracy: 0.1282\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 426us/step - loss: 0.9477 - accuracy: 0.7136 - val_loss: 2.5995 - val_accuracy: 0.2246\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 429us/step - loss: 0.9615 - accuracy: 0.7013 - val_loss: 2.5056 - val_accuracy: 0.2421\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 423us/step - loss: 0.9647 - accuracy: 0.7175 - val_loss: 2.5731 - val_accuracy: 0.1754\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 435us/step - loss: 0.9191 - accuracy: 0.7236 - val_loss: 2.5799 - val_accuracy: 0.1579\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 429us/step - loss: 0.9169 - accuracy: 0.7336 - val_loss: 2.5411 - val_accuracy: 0.2174\n",
            "974/974 [==============================] - 0s 152us/step\n",
            "Score is 0.20328542590141296\n",
            "Individual no 11\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.6214 - accuracy: 0.1755 - val_loss: 2.6362 - val_accuracy: 0.1436\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 2.0715 - accuracy: 0.3464 - val_loss: 2.6397 - val_accuracy: 0.0749\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 1.8941 - accuracy: 0.4219 - val_loss: 2.6458 - val_accuracy: 0.0749\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 1.7656 - accuracy: 0.4380 - val_loss: 2.6531 - val_accuracy: 0.0749\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 1s 474us/step - loss: 1.6583 - accuracy: 0.5065 - val_loss: 2.6671 - val_accuracy: 0.0513\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 469us/step - loss: 1.5451 - accuracy: 0.5366 - val_loss: 2.6899 - val_accuracy: 0.0974\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 1.5045 - accuracy: 0.5658 - val_loss: 2.7130 - val_accuracy: 0.0636\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 1.4641 - accuracy: 0.5520 - val_loss: 2.7369 - val_accuracy: 0.0574\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.3632 - accuracy: 0.5820 - val_loss: 2.7729 - val_accuracy: 0.0574\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 1.3006 - accuracy: 0.6259 - val_loss: 2.8051 - val_accuracy: 0.0574\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 468us/step - loss: 1.3046 - accuracy: 0.6035 - val_loss: 2.8528 - val_accuracy: 0.0574\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 474us/step - loss: 1.2246 - accuracy: 0.6359 - val_loss: 2.8785 - val_accuracy: 0.0574\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 469us/step - loss: 1.2025 - accuracy: 0.6343 - val_loss: 2.8896 - val_accuracy: 0.0574\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 1s 469us/step - loss: 1.1919 - accuracy: 0.6490 - val_loss: 2.9228 - val_accuracy: 0.0574\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 460us/step - loss: 1.1501 - accuracy: 0.6605 - val_loss: 2.9679 - val_accuracy: 0.0574\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 469us/step - loss: 1.1056 - accuracy: 0.6528 - val_loss: 2.9993 - val_accuracy: 0.0574\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 466us/step - loss: 1.0417 - accuracy: 0.6875 - val_loss: 3.0667 - val_accuracy: 0.0574\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 1s 459us/step - loss: 1.0430 - accuracy: 0.6959 - val_loss: 3.1775 - val_accuracy: 0.0574\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 1s 471us/step - loss: 1.0387 - accuracy: 0.6882 - val_loss: 3.0715 - val_accuracy: 0.0574\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 0.9639 - accuracy: 0.7013 - val_loss: 3.0683 - val_accuracy: 0.0574\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 0.9888 - accuracy: 0.7136 - val_loss: 3.0725 - val_accuracy: 0.0574\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 459us/step - loss: 0.9528 - accuracy: 0.7075 - val_loss: 3.0885 - val_accuracy: 0.0974\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 0.9170 - accuracy: 0.7244 - val_loss: 3.2143 - val_accuracy: 0.0574\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 0.9043 - accuracy: 0.7406 - val_loss: 2.9959 - val_accuracy: 0.1282\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 0.8890 - accuracy: 0.7313 - val_loss: 2.9120 - val_accuracy: 0.1292\n",
            "974/974 [==============================] - 0s 158us/step\n",
            "Score is 0.13039013743400574\n",
            "Individual no 12\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.5896 - accuracy: 0.2071 - val_loss: 2.6283 - val_accuracy: 0.0697\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 2.0682 - accuracy: 0.3256 - val_loss: 2.6309 - val_accuracy: 0.0841\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.8336 - accuracy: 0.4265 - val_loss: 2.6369 - val_accuracy: 0.0841\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 1.6866 - accuracy: 0.4834 - val_loss: 2.6511 - val_accuracy: 0.0841\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 1s 468us/step - loss: 1.6348 - accuracy: 0.4919 - val_loss: 2.6629 - val_accuracy: 0.0841\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 459us/step - loss: 1.5219 - accuracy: 0.5358 - val_loss: 2.6713 - val_accuracy: 0.0841\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 474us/step - loss: 1.4707 - accuracy: 0.5612 - val_loss: 2.6735 - val_accuracy: 0.0841\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 1s 484us/step - loss: 1.3669 - accuracy: 0.6020 - val_loss: 2.6794 - val_accuracy: 0.0841\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 1.3387 - accuracy: 0.5966 - val_loss: 2.6784 - val_accuracy: 0.0841\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 1s 471us/step - loss: 1.3022 - accuracy: 0.6074 - val_loss: 2.6844 - val_accuracy: 0.0841\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 481us/step - loss: 1.2278 - accuracy: 0.6305 - val_loss: 2.6926 - val_accuracy: 0.0841\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 467us/step - loss: 1.2459 - accuracy: 0.6282 - val_loss: 2.6744 - val_accuracy: 0.0841\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 469us/step - loss: 1.2085 - accuracy: 0.6359 - val_loss: 2.6669 - val_accuracy: 0.0841\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 1.1325 - accuracy: 0.6574 - val_loss: 2.6153 - val_accuracy: 0.0841\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 1.0769 - accuracy: 0.6882 - val_loss: 2.6012 - val_accuracy: 0.0841\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 1.0651 - accuracy: 0.6805 - val_loss: 2.6177 - val_accuracy: 0.1210\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 467us/step - loss: 1.0505 - accuracy: 0.6751 - val_loss: 2.5916 - val_accuracy: 0.1395\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 1s 469us/step - loss: 0.9869 - accuracy: 0.7236 - val_loss: 2.5888 - val_accuracy: 0.1467\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 0.9839 - accuracy: 0.7082 - val_loss: 2.5175 - val_accuracy: 0.2759\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 0.9343 - accuracy: 0.7221 - val_loss: 2.5256 - val_accuracy: 0.2082\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 468us/step - loss: 0.9527 - accuracy: 0.7144 - val_loss: 2.5098 - val_accuracy: 0.2215\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 0.8851 - accuracy: 0.7313 - val_loss: 2.3539 - val_accuracy: 0.2482\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 0.8488 - accuracy: 0.7560 - val_loss: 2.3727 - val_accuracy: 0.2544\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 457us/step - loss: 0.8561 - accuracy: 0.7390 - val_loss: 2.3605 - val_accuracy: 0.2677\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 0.8430 - accuracy: 0.7436 - val_loss: 2.5026 - val_accuracy: 0.2195\n",
            "974/974 [==============================] - 0s 160us/step\n",
            "Score is 0.19096508622169495\n",
            "Individual no 13\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.9098 - accuracy: 0.1316 - val_loss: 2.6384 - val_accuracy: 0.0574\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 0s 378us/step - loss: 2.3729 - accuracy: 0.2317 - val_loss: 2.6448 - val_accuracy: 0.0574\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 0s 373us/step - loss: 2.1822 - accuracy: 0.2964 - val_loss: 2.6566 - val_accuracy: 0.0574\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 385us/step - loss: 2.0080 - accuracy: 0.3495 - val_loss: 2.6789 - val_accuracy: 0.0574\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 0s 381us/step - loss: 1.9048 - accuracy: 0.3841 - val_loss: 2.6987 - val_accuracy: 0.0574\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 390us/step - loss: 1.8396 - accuracy: 0.4018 - val_loss: 2.7309 - val_accuracy: 0.0574\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 0s 378us/step - loss: 1.7579 - accuracy: 0.4180 - val_loss: 2.7913 - val_accuracy: 0.0574\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 0s 380us/step - loss: 1.6880 - accuracy: 0.4550 - val_loss: 2.8410 - val_accuracy: 0.0574\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 0s 374us/step - loss: 1.6247 - accuracy: 0.4904 - val_loss: 2.8778 - val_accuracy: 0.0574\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 0s 379us/step - loss: 1.5890 - accuracy: 0.4888 - val_loss: 2.9468 - val_accuracy: 0.0574\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 386us/step - loss: 1.5320 - accuracy: 0.4958 - val_loss: 2.9687 - val_accuracy: 0.0574\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 385us/step - loss: 1.4991 - accuracy: 0.5089 - val_loss: 3.0386 - val_accuracy: 0.0574\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 391us/step - loss: 1.4414 - accuracy: 0.5466 - val_loss: 3.0820 - val_accuracy: 0.0574\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 0s 381us/step - loss: 1.4243 - accuracy: 0.5443 - val_loss: 3.0538 - val_accuracy: 0.0574\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 0s 379us/step - loss: 1.3844 - accuracy: 0.5427 - val_loss: 3.1416 - val_accuracy: 0.0574\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 391us/step - loss: 1.3509 - accuracy: 0.5627 - val_loss: 3.2407 - val_accuracy: 0.0574\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 0s 369us/step - loss: 1.3183 - accuracy: 0.5689 - val_loss: 3.1942 - val_accuracy: 0.0574\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 0s 383us/step - loss: 1.3044 - accuracy: 0.5712 - val_loss: 3.3221 - val_accuracy: 0.0574\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 0s 374us/step - loss: 1.2687 - accuracy: 0.5835 - val_loss: 3.0338 - val_accuracy: 0.0872\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 389us/step - loss: 1.2387 - accuracy: 0.5935 - val_loss: 3.2632 - val_accuracy: 0.0574\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 0s 381us/step - loss: 1.2060 - accuracy: 0.6089 - val_loss: 3.0916 - val_accuracy: 0.0574\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 399us/step - loss: 1.2013 - accuracy: 0.6143 - val_loss: 2.9641 - val_accuracy: 0.0574\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 0s 380us/step - loss: 1.2046 - accuracy: 0.5974 - val_loss: 3.1960 - val_accuracy: 0.0882\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 385us/step - loss: 1.1280 - accuracy: 0.6205 - val_loss: 3.0756 - val_accuracy: 0.0574\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 0s 379us/step - loss: 1.1172 - accuracy: 0.6251 - val_loss: 2.8814 - val_accuracy: 0.0923\n",
            "974/974 [==============================] - 0s 134us/step\n",
            "Score is 0.09650924056768417\n",
            "Individual no 14\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.9185 - accuracy: 0.1047 - val_loss: 2.6345 - val_accuracy: 0.0882\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 388us/step - loss: 2.4943 - accuracy: 0.1809 - val_loss: 2.6298 - val_accuracy: 0.0985\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 0s 376us/step - loss: 2.2219 - accuracy: 0.2533 - val_loss: 2.6316 - val_accuracy: 0.0985\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 0s 383us/step - loss: 2.0557 - accuracy: 0.3356 - val_loss: 2.6350 - val_accuracy: 0.0985\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 0s 376us/step - loss: 1.9536 - accuracy: 0.3472 - val_loss: 2.6434 - val_accuracy: 0.0985\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 0s 384us/step - loss: 1.8182 - accuracy: 0.4280 - val_loss: 2.6598 - val_accuracy: 0.0985\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 0s 382us/step - loss: 1.7315 - accuracy: 0.4503 - val_loss: 2.6856 - val_accuracy: 0.0985\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 0s 384us/step - loss: 1.6586 - accuracy: 0.4650 - val_loss: 2.7248 - val_accuracy: 0.0985\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 0s 377us/step - loss: 1.5825 - accuracy: 0.5004 - val_loss: 2.7610 - val_accuracy: 0.0985\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 0s 379us/step - loss: 1.5535 - accuracy: 0.5112 - val_loss: 2.8171 - val_accuracy: 0.0985\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 0s 377us/step - loss: 1.4528 - accuracy: 0.5481 - val_loss: 2.8630 - val_accuracy: 0.0985\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 0s 385us/step - loss: 1.4297 - accuracy: 0.5558 - val_loss: 2.9245 - val_accuracy: 0.0985\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 0s 378us/step - loss: 1.4283 - accuracy: 0.5473 - val_loss: 2.9776 - val_accuracy: 0.0985\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 0s 383us/step - loss: 1.3319 - accuracy: 0.5820 - val_loss: 3.0275 - val_accuracy: 0.0985\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 0s 376us/step - loss: 1.3465 - accuracy: 0.5758 - val_loss: 3.0508 - val_accuracy: 0.0985\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 0s 383us/step - loss: 1.2847 - accuracy: 0.5997 - val_loss: 3.1278 - val_accuracy: 0.0985\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 400us/step - loss: 1.2102 - accuracy: 0.6151 - val_loss: 3.1699 - val_accuracy: 0.0985\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 0s 382us/step - loss: 1.2411 - accuracy: 0.6112 - val_loss: 3.2745 - val_accuracy: 0.0985\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 0s 373us/step - loss: 1.1690 - accuracy: 0.6359 - val_loss: 3.2905 - val_accuracy: 0.0985\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 0s 382us/step - loss: 1.1452 - accuracy: 0.6428 - val_loss: 3.3470 - val_accuracy: 0.0985\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 0s 366us/step - loss: 1.1322 - accuracy: 0.6397 - val_loss: 3.2577 - val_accuracy: 0.0985\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 0s 377us/step - loss: 1.0693 - accuracy: 0.6751 - val_loss: 3.3924 - val_accuracy: 0.0985\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 0s 385us/step - loss: 1.0733 - accuracy: 0.6736 - val_loss: 3.2558 - val_accuracy: 0.0985\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 0s 377us/step - loss: 1.0429 - accuracy: 0.6713 - val_loss: 3.3993 - val_accuracy: 0.0985\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 0s 381us/step - loss: 1.0266 - accuracy: 0.6844 - val_loss: 3.3886 - val_accuracy: 0.0985\n",
            "974/974 [==============================] - 0s 135us/step\n",
            "Score is 0.09753593057394028\n",
            "Individual no 15\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.9426 - accuracy: 0.1078 - val_loss: 2.6396 - val_accuracy: 0.0882\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 0s 376us/step - loss: 2.4421 - accuracy: 0.2032 - val_loss: 2.6446 - val_accuracy: 0.0882\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 0s 375us/step - loss: 2.2629 - accuracy: 0.2394 - val_loss: 2.6546 - val_accuracy: 0.0882\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 0s 378us/step - loss: 2.1095 - accuracy: 0.2741 - val_loss: 2.6720 - val_accuracy: 0.0882\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 0s 375us/step - loss: 1.9828 - accuracy: 0.3272 - val_loss: 2.6894 - val_accuracy: 0.0738\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 0s 375us/step - loss: 1.8984 - accuracy: 0.3603 - val_loss: 2.7138 - val_accuracy: 0.0738\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 0s 380us/step - loss: 1.8637 - accuracy: 0.3618 - val_loss: 2.7313 - val_accuracy: 0.0749\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 0s 380us/step - loss: 1.7560 - accuracy: 0.3918 - val_loss: 2.7511 - val_accuracy: 0.0749\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 0s 373us/step - loss: 1.7516 - accuracy: 0.3918 - val_loss: 2.7679 - val_accuracy: 0.0749\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 0s 371us/step - loss: 1.6906 - accuracy: 0.4280 - val_loss: 2.7992 - val_accuracy: 0.0749\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 0s 370us/step - loss: 1.6405 - accuracy: 0.4226 - val_loss: 2.8278 - val_accuracy: 0.0749\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 0s 372us/step - loss: 1.6161 - accuracy: 0.4403 - val_loss: 2.8534 - val_accuracy: 0.0749\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 392us/step - loss: 1.5823 - accuracy: 0.4303 - val_loss: 2.8732 - val_accuracy: 0.0749\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 0s 376us/step - loss: 1.5546 - accuracy: 0.4380 - val_loss: 2.8918 - val_accuracy: 0.1077\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 0s 374us/step - loss: 1.5310 - accuracy: 0.4488 - val_loss: 2.9339 - val_accuracy: 0.0749\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 0s 372us/step - loss: 1.5175 - accuracy: 0.4611 - val_loss: 2.9436 - val_accuracy: 0.0933\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 0s 370us/step - loss: 1.4901 - accuracy: 0.4673 - val_loss: 2.9479 - val_accuracy: 0.0749\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 0s 372us/step - loss: 1.4832 - accuracy: 0.4588 - val_loss: 2.9534 - val_accuracy: 0.0749\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 0s 375us/step - loss: 1.4244 - accuracy: 0.4781 - val_loss: 2.9945 - val_accuracy: 0.0882\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 0s 373us/step - loss: 1.4302 - accuracy: 0.4911 - val_loss: 2.9678 - val_accuracy: 0.0882\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 0s 370us/step - loss: 1.3852 - accuracy: 0.5119 - val_loss: 2.9579 - val_accuracy: 0.0882\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 392us/step - loss: 1.3890 - accuracy: 0.5012 - val_loss: 2.9370 - val_accuracy: 0.0882\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 0s 373us/step - loss: 1.3514 - accuracy: 0.5150 - val_loss: 2.9718 - val_accuracy: 0.0882\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 0s 376us/step - loss: 1.3280 - accuracy: 0.5196 - val_loss: 2.8820 - val_accuracy: 0.0882\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 0s 372us/step - loss: 1.3593 - accuracy: 0.5219 - val_loss: 2.8589 - val_accuracy: 0.1056\n",
            "974/974 [==============================] - 0s 146us/step\n",
            "Score is 0.11601642519235611\n",
            "Individual no 16\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 3s 2ms/step - loss: 2.6426 - accuracy: 0.1747 - val_loss: 2.6351 - val_accuracy: 0.0749\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 2.1112 - accuracy: 0.3010 - val_loss: 2.6325 - val_accuracy: 0.0985\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.8563 - accuracy: 0.4103 - val_loss: 2.6330 - val_accuracy: 0.0985\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 480us/step - loss: 1.7516 - accuracy: 0.4534 - val_loss: 2.6421 - val_accuracy: 0.0985\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 1s 468us/step - loss: 1.6311 - accuracy: 0.5189 - val_loss: 2.6517 - val_accuracy: 0.0985\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 451us/step - loss: 1.5614 - accuracy: 0.5242 - val_loss: 2.6675 - val_accuracy: 0.0985\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 1.5104 - accuracy: 0.5697 - val_loss: 2.6920 - val_accuracy: 0.0985\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 1s 460us/step - loss: 1.4139 - accuracy: 0.6051 - val_loss: 2.7271 - val_accuracy: 0.0985\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 1.3568 - accuracy: 0.6089 - val_loss: 2.7553 - val_accuracy: 0.0985\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 1.3419 - accuracy: 0.6220 - val_loss: 2.7906 - val_accuracy: 0.0985\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 451us/step - loss: 1.2558 - accuracy: 0.6397 - val_loss: 2.8515 - val_accuracy: 0.0985\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 472us/step - loss: 1.2311 - accuracy: 0.6459 - val_loss: 2.8872 - val_accuracy: 0.0985\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.1831 - accuracy: 0.6751 - val_loss: 2.9219 - val_accuracy: 0.0985\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 1s 459us/step - loss: 1.1521 - accuracy: 0.6851 - val_loss: 2.9698 - val_accuracy: 0.0985\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.0873 - accuracy: 0.6836 - val_loss: 3.0448 - val_accuracy: 0.0985\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 453us/step - loss: 1.0736 - accuracy: 0.6805 - val_loss: 3.0128 - val_accuracy: 0.0985\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.0483 - accuracy: 0.6975 - val_loss: 3.1015 - val_accuracy: 0.0985\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 1s 470us/step - loss: 1.0072 - accuracy: 0.7152 - val_loss: 3.1122 - val_accuracy: 0.0985\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 0.9791 - accuracy: 0.7136 - val_loss: 2.9318 - val_accuracy: 0.1067\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 0.9529 - accuracy: 0.7244 - val_loss: 2.8904 - val_accuracy: 0.1138\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 447us/step - loss: 0.9272 - accuracy: 0.7283 - val_loss: 2.8631 - val_accuracy: 0.1241\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 479us/step - loss: 0.9448 - accuracy: 0.7298 - val_loss: 2.6461 - val_accuracy: 0.1200\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 467us/step - loss: 0.9221 - accuracy: 0.7306 - val_loss: 2.7566 - val_accuracy: 0.1159\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 460us/step - loss: 0.8800 - accuracy: 0.7475 - val_loss: 2.7151 - val_accuracy: 0.1374\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 452us/step - loss: 0.8499 - accuracy: 0.7506 - val_loss: 2.5900 - val_accuracy: 0.1487\n",
            "974/974 [==============================] - 0s 161us/step\n",
            "Score is 0.15297740697860718\n",
            "Individual no 17\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.8577 - accuracy: 0.1232 - val_loss: 2.6387 - val_accuracy: 0.0841\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 466us/step - loss: 2.3293 - accuracy: 0.2548 - val_loss: 2.6422 - val_accuracy: 0.0841\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 1s 452us/step - loss: 1.9729 - accuracy: 0.3780 - val_loss: 2.6533 - val_accuracy: 0.1292\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 470us/step - loss: 1.8226 - accuracy: 0.4342 - val_loss: 2.6693 - val_accuracy: 0.0841\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 1s 469us/step - loss: 1.7479 - accuracy: 0.4688 - val_loss: 2.6842 - val_accuracy: 0.1005\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 454us/step - loss: 1.6367 - accuracy: 0.5235 - val_loss: 2.6947 - val_accuracy: 0.0872\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.5494 - accuracy: 0.5412 - val_loss: 2.7143 - val_accuracy: 0.0841\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.5129 - accuracy: 0.5574 - val_loss: 2.7516 - val_accuracy: 0.0697\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 449us/step - loss: 1.4005 - accuracy: 0.6035 - val_loss: 2.7672 - val_accuracy: 0.0492\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 1.3782 - accuracy: 0.6105 - val_loss: 2.8041 - val_accuracy: 0.0472\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 446us/step - loss: 1.3248 - accuracy: 0.6212 - val_loss: 2.7917 - val_accuracy: 0.0841\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 1.3071 - accuracy: 0.6166 - val_loss: 2.8172 - val_accuracy: 0.0841\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 454us/step - loss: 1.2199 - accuracy: 0.6443 - val_loss: 2.8265 - val_accuracy: 0.0841\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 1.2037 - accuracy: 0.6682 - val_loss: 2.8026 - val_accuracy: 0.0841\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 480us/step - loss: 1.1758 - accuracy: 0.6659 - val_loss: 2.8352 - val_accuracy: 0.0841\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 470us/step - loss: 1.1587 - accuracy: 0.6574 - val_loss: 2.8426 - val_accuracy: 0.0882\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 476us/step - loss: 1.1503 - accuracy: 0.6620 - val_loss: 2.8441 - val_accuracy: 0.0913\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 1.1116 - accuracy: 0.6844 - val_loss: 2.7964 - val_accuracy: 0.0841\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 1s 467us/step - loss: 1.0466 - accuracy: 0.6790 - val_loss: 2.7638 - val_accuracy: 0.1426\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 478us/step - loss: 1.0435 - accuracy: 0.6882 - val_loss: 2.6842 - val_accuracy: 0.1549\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 471us/step - loss: 1.0220 - accuracy: 0.7036 - val_loss: 2.7615 - val_accuracy: 0.1303\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 483us/step - loss: 1.0058 - accuracy: 0.7090 - val_loss: 2.7079 - val_accuracy: 0.1621\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 0.9760 - accuracy: 0.7090 - val_loss: 2.7751 - val_accuracy: 0.1415\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 481us/step - loss: 0.9479 - accuracy: 0.7229 - val_loss: 2.6894 - val_accuracy: 0.1333\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 476us/step - loss: 0.9225 - accuracy: 0.7367 - val_loss: 2.6578 - val_accuracy: 0.1436\n",
            "974/974 [==============================] - 0s 170us/step\n",
            "Score is 0.15297740697860718\n",
            "Individual no 18\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 3s 2ms/step - loss: 2.7235 - accuracy: 0.1655 - val_loss: 2.6287 - val_accuracy: 0.0667\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 2.2369 - accuracy: 0.2802 - val_loss: 2.6273 - val_accuracy: 0.0574\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 1.9027 - accuracy: 0.4142 - val_loss: 2.6299 - val_accuracy: 0.0574\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 483us/step - loss: 1.8086 - accuracy: 0.4604 - val_loss: 2.6386 - val_accuracy: 0.0574\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 1.6794 - accuracy: 0.5035 - val_loss: 2.6527 - val_accuracy: 0.0574\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 467us/step - loss: 1.5746 - accuracy: 0.5319 - val_loss: 2.6622 - val_accuracy: 0.0574\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 468us/step - loss: 1.5244 - accuracy: 0.5527 - val_loss: 2.6932 - val_accuracy: 0.0574\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 1s 459us/step - loss: 1.4401 - accuracy: 0.5620 - val_loss: 2.7339 - val_accuracy: 0.0831\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 488us/step - loss: 1.3638 - accuracy: 0.6051 - val_loss: 2.7757 - val_accuracy: 0.0821\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 1s 460us/step - loss: 1.3095 - accuracy: 0.6220 - val_loss: 2.8063 - val_accuracy: 0.0810\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 1.3053 - accuracy: 0.6297 - val_loss: 2.8599 - val_accuracy: 0.0779\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 1.2352 - accuracy: 0.6459 - val_loss: 2.8963 - val_accuracy: 0.0738\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 459us/step - loss: 1.2260 - accuracy: 0.6397 - val_loss: 2.9637 - val_accuracy: 0.0872\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 1.1380 - accuracy: 0.6667 - val_loss: 2.9974 - val_accuracy: 0.0738\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 459us/step - loss: 1.1518 - accuracy: 0.6682 - val_loss: 3.0478 - val_accuracy: 0.0749\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 496us/step - loss: 1.0934 - accuracy: 0.6713 - val_loss: 3.1208 - val_accuracy: 0.1118\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 469us/step - loss: 1.1469 - accuracy: 0.6744 - val_loss: 3.2048 - val_accuracy: 0.1005\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 1s 473us/step - loss: 1.0666 - accuracy: 0.6936 - val_loss: 3.2619 - val_accuracy: 0.1046\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 1s 477us/step - loss: 1.0414 - accuracy: 0.6882 - val_loss: 3.3373 - val_accuracy: 0.0923\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 1.0158 - accuracy: 0.7098 - val_loss: 3.2704 - val_accuracy: 0.0821\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 467us/step - loss: 0.9910 - accuracy: 0.7129 - val_loss: 3.3124 - val_accuracy: 0.0851\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 466us/step - loss: 0.9381 - accuracy: 0.7383 - val_loss: 3.3169 - val_accuracy: 0.1077\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 0.9427 - accuracy: 0.7275 - val_loss: 3.3698 - val_accuracy: 0.1077\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 476us/step - loss: 0.9245 - accuracy: 0.7344 - val_loss: 3.4085 - val_accuracy: 0.1087\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 453us/step - loss: 0.9663 - accuracy: 0.7236 - val_loss: 3.3806 - val_accuracy: 0.0995\n",
            "974/974 [==============================] - 0s 166us/step\n",
            "Score is 0.11806981265544891\n",
            "Individual no 19\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.7723 - accuracy: 0.1624 - val_loss: 2.6336 - val_accuracy: 0.0882\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 459us/step - loss: 2.2375 - accuracy: 0.2933 - val_loss: 2.6316 - val_accuracy: 0.0882\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 1s 451us/step - loss: 1.9153 - accuracy: 0.3872 - val_loss: 2.6375 - val_accuracy: 0.0359\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 1.7401 - accuracy: 0.4542 - val_loss: 2.6481 - val_accuracy: 0.0759\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 1s 453us/step - loss: 1.6503 - accuracy: 0.5096 - val_loss: 2.6591 - val_accuracy: 0.0749\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 460us/step - loss: 1.5569 - accuracy: 0.5550 - val_loss: 2.6685 - val_accuracy: 0.0800\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 460us/step - loss: 1.4901 - accuracy: 0.5420 - val_loss: 2.6904 - val_accuracy: 0.0800\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 1s 444us/step - loss: 1.4184 - accuracy: 0.5758 - val_loss: 2.7120 - val_accuracy: 0.0800\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 1.3604 - accuracy: 0.6112 - val_loss: 2.7241 - val_accuracy: 0.0800\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 1s 451us/step - loss: 1.3595 - accuracy: 0.5966 - val_loss: 2.7496 - val_accuracy: 0.0800\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 473us/step - loss: 1.2459 - accuracy: 0.6582 - val_loss: 2.8024 - val_accuracy: 0.0800\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 454us/step - loss: 1.2049 - accuracy: 0.6505 - val_loss: 2.8197 - val_accuracy: 0.0800\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 453us/step - loss: 1.1458 - accuracy: 0.6682 - val_loss: 2.8190 - val_accuracy: 0.0800\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 1s 475us/step - loss: 1.2118 - accuracy: 0.6420 - val_loss: 2.8512 - val_accuracy: 0.0800\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 457us/step - loss: 1.1197 - accuracy: 0.6705 - val_loss: 2.8606 - val_accuracy: 0.0800\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 459us/step - loss: 1.0658 - accuracy: 0.6882 - val_loss: 2.8409 - val_accuracy: 0.0800\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 451us/step - loss: 1.0353 - accuracy: 0.6944 - val_loss: 2.8799 - val_accuracy: 0.0800\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 1s 457us/step - loss: 1.0218 - accuracy: 0.7105 - val_loss: 2.8046 - val_accuracy: 0.0800\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 0.9776 - accuracy: 0.7098 - val_loss: 2.6610 - val_accuracy: 0.1467\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 450us/step - loss: 0.9984 - accuracy: 0.7044 - val_loss: 2.8417 - val_accuracy: 0.0800\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 472us/step - loss: 0.9749 - accuracy: 0.7298 - val_loss: 2.6497 - val_accuracy: 0.1272\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 0.9220 - accuracy: 0.7336 - val_loss: 2.3708 - val_accuracy: 0.2072\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 0.8687 - accuracy: 0.7475 - val_loss: 2.3612 - val_accuracy: 0.1713\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 0.8777 - accuracy: 0.7398 - val_loss: 2.1939 - val_accuracy: 0.2554\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 454us/step - loss: 0.8938 - accuracy: 0.7367 - val_loss: 1.9720 - val_accuracy: 0.2810\n",
            "974/974 [==============================] - 0s 160us/step\n",
            "Score is 0.290554404258728\n",
            "Individual no 20\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.6830 - accuracy: 0.1201 - val_loss: 2.6365 - val_accuracy: 0.0451\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 2.1675 - accuracy: 0.2617 - val_loss: 2.6425 - val_accuracy: 0.0995\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 1s 450us/step - loss: 1.9275 - accuracy: 0.3580 - val_loss: 2.6517 - val_accuracy: 0.1097\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 472us/step - loss: 1.7753 - accuracy: 0.4242 - val_loss: 2.6594 - val_accuracy: 0.1087\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 1s 453us/step - loss: 1.6906 - accuracy: 0.4588 - val_loss: 2.6657 - val_accuracy: 0.0985\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 457us/step - loss: 1.6033 - accuracy: 0.4935 - val_loss: 2.6690 - val_accuracy: 0.1118\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 469us/step - loss: 1.5207 - accuracy: 0.5212 - val_loss: 2.6730 - val_accuracy: 0.0738\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 1s 452us/step - loss: 1.4407 - accuracy: 0.5620 - val_loss: 2.6747 - val_accuracy: 0.0749\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 1.4213 - accuracy: 0.5751 - val_loss: 2.6834 - val_accuracy: 0.0749\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 1s 447us/step - loss: 1.3944 - accuracy: 0.5797 - val_loss: 2.6910 - val_accuracy: 0.0749\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 459us/step - loss: 1.2825 - accuracy: 0.6251 - val_loss: 2.7230 - val_accuracy: 0.0749\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 1.2496 - accuracy: 0.6174 - val_loss: 2.7347 - val_accuracy: 0.0749\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.2429 - accuracy: 0.6105 - val_loss: 2.7491 - val_accuracy: 0.0759\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 1s 480us/step - loss: 1.1887 - accuracy: 0.6451 - val_loss: 2.7593 - val_accuracy: 0.1036\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 1.1250 - accuracy: 0.6574 - val_loss: 2.7911 - val_accuracy: 0.1210\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 466us/step - loss: 1.1364 - accuracy: 0.6413 - val_loss: 2.7765 - val_accuracy: 0.0790\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 453us/step - loss: 1.0506 - accuracy: 0.6774 - val_loss: 2.8348 - val_accuracy: 0.0790\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 1s 467us/step - loss: 1.0295 - accuracy: 0.6798 - val_loss: 2.9014 - val_accuracy: 0.0892\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 1s 460us/step - loss: 1.0454 - accuracy: 0.6782 - val_loss: 2.8957 - val_accuracy: 0.1231\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 452us/step - loss: 0.9842 - accuracy: 0.7090 - val_loss: 2.9200 - val_accuracy: 0.1159\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 0.9706 - accuracy: 0.7082 - val_loss: 2.9163 - val_accuracy: 0.1374\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 452us/step - loss: 0.9682 - accuracy: 0.7059 - val_loss: 2.8105 - val_accuracy: 0.1272\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 0.9441 - accuracy: 0.7113 - val_loss: 2.8789 - val_accuracy: 0.1528\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 0.8812 - accuracy: 0.7460 - val_loss: 2.8507 - val_accuracy: 0.1826\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 454us/step - loss: 0.8284 - accuracy: 0.7567 - val_loss: 2.7550 - val_accuracy: 0.2564\n",
            "974/974 [==============================] - 0s 157us/step\n",
            "Score is 0.25154003500938416\n",
            "Individual no 21\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.5783 - accuracy: 0.1971 - val_loss: 2.6342 - val_accuracy: 0.0841\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 459us/step - loss: 2.0955 - accuracy: 0.3226 - val_loss: 2.6305 - val_accuracy: 0.0841\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 1s 460us/step - loss: 1.8706 - accuracy: 0.3988 - val_loss: 2.6412 - val_accuracy: 0.0841\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.7232 - accuracy: 0.4765 - val_loss: 2.6287 - val_accuracy: 0.0913\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 1s 453us/step - loss: 1.6614 - accuracy: 0.5050 - val_loss: 2.6617 - val_accuracy: 0.0985\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 459us/step - loss: 1.5924 - accuracy: 0.5112 - val_loss: 2.6725 - val_accuracy: 0.0841\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 452us/step - loss: 1.4935 - accuracy: 0.5566 - val_loss: 2.6761 - val_accuracy: 0.1046\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 1.4336 - accuracy: 0.5689 - val_loss: 2.6949 - val_accuracy: 0.1723\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 457us/step - loss: 1.3983 - accuracy: 0.5766 - val_loss: 2.6889 - val_accuracy: 0.1579\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 1s 460us/step - loss: 1.3170 - accuracy: 0.6274 - val_loss: 2.7112 - val_accuracy: 0.1815\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 1.2628 - accuracy: 0.6282 - val_loss: 2.6976 - val_accuracy: 0.1169\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 454us/step - loss: 1.2233 - accuracy: 0.6351 - val_loss: 2.6616 - val_accuracy: 0.1549\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 473us/step - loss: 1.1933 - accuracy: 0.6513 - val_loss: 2.6749 - val_accuracy: 0.1456\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 1s 482us/step - loss: 1.1527 - accuracy: 0.6620 - val_loss: 2.6972 - val_accuracy: 0.0790\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 450us/step - loss: 1.0918 - accuracy: 0.6782 - val_loss: 2.6732 - val_accuracy: 0.1600\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 469us/step - loss: 1.1030 - accuracy: 0.6705 - val_loss: 2.5969 - val_accuracy: 0.1938\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 1.0972 - accuracy: 0.6744 - val_loss: 2.5919 - val_accuracy: 0.1344\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 1s 466us/step - loss: 1.0308 - accuracy: 0.7028 - val_loss: 2.5650 - val_accuracy: 0.2462\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 0.9874 - accuracy: 0.7067 - val_loss: 2.5355 - val_accuracy: 0.1826\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 0.9858 - accuracy: 0.7144 - val_loss: 2.5006 - val_accuracy: 0.1405\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 475us/step - loss: 0.9277 - accuracy: 0.7290 - val_loss: 2.4443 - val_accuracy: 0.1508\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 468us/step - loss: 0.9234 - accuracy: 0.7344 - val_loss: 2.4346 - val_accuracy: 0.2328\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 469us/step - loss: 0.8959 - accuracy: 0.7413 - val_loss: 2.2498 - val_accuracy: 0.3149\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 482us/step - loss: 0.8444 - accuracy: 0.7544 - val_loss: 2.1727 - val_accuracy: 0.3662\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 0.8458 - accuracy: 0.7483 - val_loss: 2.1165 - val_accuracy: 0.3579\n",
            "974/974 [==============================] - 0s 175us/step\n",
            "Score is 0.36344969272613525\n",
            "Individual no 22\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.6144 - accuracy: 0.1786 - val_loss: 2.6395 - val_accuracy: 0.1015\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 453us/step - loss: 2.0819 - accuracy: 0.3387 - val_loss: 2.6478 - val_accuracy: 0.0985\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 1s 450us/step - loss: 1.8513 - accuracy: 0.4103 - val_loss: 2.6537 - val_accuracy: 0.0985\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 1.7501 - accuracy: 0.4573 - val_loss: 2.6635 - val_accuracy: 0.0985\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 1.6121 - accuracy: 0.5035 - val_loss: 2.6707 - val_accuracy: 0.0985\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.5427 - accuracy: 0.5258 - val_loss: 2.6710 - val_accuracy: 0.0985\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 1.4712 - accuracy: 0.5458 - val_loss: 2.6785 - val_accuracy: 0.0985\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 1s 453us/step - loss: 1.4259 - accuracy: 0.5751 - val_loss: 2.6935 - val_accuracy: 0.0985\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 1.3729 - accuracy: 0.5781 - val_loss: 2.7065 - val_accuracy: 0.0985\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 1s 450us/step - loss: 1.3464 - accuracy: 0.5935 - val_loss: 2.7139 - val_accuracy: 0.0985\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 460us/step - loss: 1.2852 - accuracy: 0.6120 - val_loss: 2.7133 - val_accuracy: 0.0985\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 1.2218 - accuracy: 0.6374 - val_loss: 2.7333 - val_accuracy: 0.0985\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 487us/step - loss: 1.2513 - accuracy: 0.6274 - val_loss: 2.7371 - val_accuracy: 0.0985\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 1.1867 - accuracy: 0.6551 - val_loss: 2.7377 - val_accuracy: 0.0985\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 1.1183 - accuracy: 0.6659 - val_loss: 2.7309 - val_accuracy: 0.0985\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 454us/step - loss: 1.1007 - accuracy: 0.6751 - val_loss: 2.6674 - val_accuracy: 0.1015\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 447us/step - loss: 1.0985 - accuracy: 0.6574 - val_loss: 2.6392 - val_accuracy: 0.1015\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.0456 - accuracy: 0.6844 - val_loss: 2.5943 - val_accuracy: 0.0985\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 1s 450us/step - loss: 1.0268 - accuracy: 0.7059 - val_loss: 2.6584 - val_accuracy: 0.0985\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 445us/step - loss: 0.9897 - accuracy: 0.7105 - val_loss: 2.5220 - val_accuracy: 0.1149\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 460us/step - loss: 0.9628 - accuracy: 0.7206 - val_loss: 2.4941 - val_accuracy: 0.1200\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 453us/step - loss: 0.9726 - accuracy: 0.6982 - val_loss: 2.4816 - val_accuracy: 0.1785\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 453us/step - loss: 0.9442 - accuracy: 0.7367 - val_loss: 2.4290 - val_accuracy: 0.1610\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 449us/step - loss: 0.8946 - accuracy: 0.7506 - val_loss: 2.5295 - val_accuracy: 0.1046\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 0.8764 - accuracy: 0.7575 - val_loss: 2.4444 - val_accuracy: 0.1508\n",
            "974/974 [==============================] - 0s 160us/step\n",
            "Score is 0.13655030727386475\n",
            "Individual no 23\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 3s 2ms/step - loss: 2.7622 - accuracy: 0.1424 - val_loss: 2.6381 - val_accuracy: 0.0759\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 2.3062 - accuracy: 0.2402 - val_loss: 2.6384 - val_accuracy: 0.0759\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 2.0876 - accuracy: 0.3503 - val_loss: 2.6379 - val_accuracy: 0.0759\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 1.9678 - accuracy: 0.3949 - val_loss: 2.6466 - val_accuracy: 0.0759\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 1.8393 - accuracy: 0.4573 - val_loss: 2.6469 - val_accuracy: 0.0841\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 457us/step - loss: 1.7423 - accuracy: 0.4573 - val_loss: 2.6730 - val_accuracy: 0.0759\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 1.6572 - accuracy: 0.5035 - val_loss: 2.6870 - val_accuracy: 0.0759\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.6036 - accuracy: 0.5081 - val_loss: 2.7003 - val_accuracy: 0.0769\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 460us/step - loss: 1.5038 - accuracy: 0.5550 - val_loss: 2.6978 - val_accuracy: 0.1200\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 1s 451us/step - loss: 1.4557 - accuracy: 0.5912 - val_loss: 2.7096 - val_accuracy: 0.0738\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 483us/step - loss: 1.4603 - accuracy: 0.5658 - val_loss: 2.7454 - val_accuracy: 0.0738\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 468us/step - loss: 1.3428 - accuracy: 0.6043 - val_loss: 2.7349 - val_accuracy: 0.0738\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 468us/step - loss: 1.3071 - accuracy: 0.6128 - val_loss: 2.7800 - val_accuracy: 0.0749\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 1s 460us/step - loss: 1.3198 - accuracy: 0.6205 - val_loss: 2.7980 - val_accuracy: 0.0738\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 454us/step - loss: 1.2676 - accuracy: 0.6112 - val_loss: 2.8289 - val_accuracy: 0.0738\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 460us/step - loss: 1.2315 - accuracy: 0.6305 - val_loss: 2.8413 - val_accuracy: 0.0738\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 1.1983 - accuracy: 0.6382 - val_loss: 2.8594 - val_accuracy: 0.0738\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 1s 467us/step - loss: 1.1430 - accuracy: 0.6505 - val_loss: 2.8968 - val_accuracy: 0.0738\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 1s 469us/step - loss: 1.1078 - accuracy: 0.6736 - val_loss: 2.8959 - val_accuracy: 0.0738\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 452us/step - loss: 1.1152 - accuracy: 0.6813 - val_loss: 2.9299 - val_accuracy: 0.0738\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 470us/step - loss: 1.0223 - accuracy: 0.7044 - val_loss: 2.9626 - val_accuracy: 0.0738\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 452us/step - loss: 1.0115 - accuracy: 0.6975 - val_loss: 2.9706 - val_accuracy: 0.0738\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.0179 - accuracy: 0.6967 - val_loss: 3.0287 - val_accuracy: 0.0738\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 469us/step - loss: 0.9846 - accuracy: 0.6913 - val_loss: 3.1177 - val_accuracy: 0.1179\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 0.9425 - accuracy: 0.7321 - val_loss: 3.0282 - val_accuracy: 0.0738\n",
            "974/974 [==============================] - 0s 159us/step\n",
            "Score is 0.08008213341236115\n",
            "Individual no 24\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.8423 - accuracy: 0.1139 - val_loss: 2.6295 - val_accuracy: 0.0821\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 388us/step - loss: 2.4164 - accuracy: 0.2379 - val_loss: 2.6182 - val_accuracy: 0.1067\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 1s 417us/step - loss: 2.1982 - accuracy: 0.2771 - val_loss: 2.6090 - val_accuracy: 0.1067\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 424us/step - loss: 2.0742 - accuracy: 0.3464 - val_loss: 2.6078 - val_accuracy: 0.1067\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 1s 408us/step - loss: 1.9480 - accuracy: 0.3972 - val_loss: 2.6065 - val_accuracy: 0.0985\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 418us/step - loss: 1.8692 - accuracy: 0.3918 - val_loss: 2.6044 - val_accuracy: 0.0985\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 416us/step - loss: 1.8162 - accuracy: 0.4188 - val_loss: 2.6137 - val_accuracy: 0.0985\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 1s 419us/step - loss: 1.7801 - accuracy: 0.4357 - val_loss: 2.6054 - val_accuracy: 0.0985\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 408us/step - loss: 1.7007 - accuracy: 0.4419 - val_loss: 2.5972 - val_accuracy: 0.0985\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 1s 417us/step - loss: 1.6378 - accuracy: 0.5004 - val_loss: 2.5938 - val_accuracy: 0.0985\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 411us/step - loss: 1.6017 - accuracy: 0.4888 - val_loss: 2.5908 - val_accuracy: 0.1005\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 428us/step - loss: 1.5350 - accuracy: 0.5296 - val_loss: 2.6031 - val_accuracy: 0.1036\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 405us/step - loss: 1.5215 - accuracy: 0.5250 - val_loss: 2.6167 - val_accuracy: 0.1015\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 1s 410us/step - loss: 1.4228 - accuracy: 0.5612 - val_loss: 2.6278 - val_accuracy: 0.1046\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 399us/step - loss: 1.4497 - accuracy: 0.5312 - val_loss: 2.6282 - val_accuracy: 0.1087\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 406us/step - loss: 1.4035 - accuracy: 0.5558 - val_loss: 2.6223 - val_accuracy: 0.1159\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 398us/step - loss: 1.3397 - accuracy: 0.5789 - val_loss: 2.6194 - val_accuracy: 0.1056\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 1s 404us/step - loss: 1.3436 - accuracy: 0.5835 - val_loss: 2.5738 - val_accuracy: 0.1969\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 1s 395us/step - loss: 1.3224 - accuracy: 0.5581 - val_loss: 2.5289 - val_accuracy: 0.2133\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 402us/step - loss: 1.2571 - accuracy: 0.5974 - val_loss: 2.5297 - val_accuracy: 0.1538\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 395us/step - loss: 1.2900 - accuracy: 0.5727 - val_loss: 2.5209 - val_accuracy: 0.2021\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 405us/step - loss: 1.2367 - accuracy: 0.6097 - val_loss: 2.6049 - val_accuracy: 0.0779\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 395us/step - loss: 1.2358 - accuracy: 0.5943 - val_loss: 2.5279 - val_accuracy: 0.1159\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 407us/step - loss: 1.2078 - accuracy: 0.5966 - val_loss: 2.4352 - val_accuracy: 0.1887\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 393us/step - loss: 1.1827 - accuracy: 0.6120 - val_loss: 2.4314 - val_accuracy: 0.2554\n",
            "974/974 [==============================] - 0s 149us/step\n",
            "Score is 0.2751539945602417\n",
            "Individual no 25\n",
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/25\n",
            "1299/1299 [==============================] - 2s 2ms/step - loss: 2.6927 - accuracy: 0.1655 - val_loss: 2.6287 - val_accuracy: 0.0738\n",
            "Epoch 2/25\n",
            "1299/1299 [==============================] - 1s 452us/step - loss: 2.1705 - accuracy: 0.3010 - val_loss: 2.6184 - val_accuracy: 0.0738\n",
            "Epoch 3/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 1.9428 - accuracy: 0.3780 - val_loss: 2.6230 - val_accuracy: 0.0738\n",
            "Epoch 4/25\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 1.7766 - accuracy: 0.4473 - val_loss: 2.6242 - val_accuracy: 0.0738\n",
            "Epoch 5/25\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 1.6342 - accuracy: 0.4804 - val_loss: 2.6336 - val_accuracy: 0.1559\n",
            "Epoch 6/25\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 1.5742 - accuracy: 0.5104 - val_loss: 2.6471 - val_accuracy: 0.1179\n",
            "Epoch 7/25\n",
            "1299/1299 [==============================] - 1s 459us/step - loss: 1.5137 - accuracy: 0.5181 - val_loss: 2.6635 - val_accuracy: 0.0985\n",
            "Epoch 8/25\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 1.4555 - accuracy: 0.5497 - val_loss: 2.6861 - val_accuracy: 0.0985\n",
            "Epoch 9/25\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 1.3626 - accuracy: 0.5966 - val_loss: 2.6773 - val_accuracy: 0.0985\n",
            "Epoch 10/25\n",
            "1299/1299 [==============================] - 1s 447us/step - loss: 1.3507 - accuracy: 0.5951 - val_loss: 2.6857 - val_accuracy: 0.1118\n",
            "Epoch 11/25\n",
            "1299/1299 [==============================] - 1s 457us/step - loss: 1.2610 - accuracy: 0.6212 - val_loss: 2.6777 - val_accuracy: 0.1241\n",
            "Epoch 12/25\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 1.2019 - accuracy: 0.6390 - val_loss: 2.6752 - val_accuracy: 0.1795\n",
            "Epoch 13/25\n",
            "1299/1299 [==============================] - 1s 454us/step - loss: 1.1604 - accuracy: 0.6443 - val_loss: 2.6507 - val_accuracy: 0.1703\n",
            "Epoch 14/25\n",
            "1299/1299 [==============================] - 1s 476us/step - loss: 1.1325 - accuracy: 0.6520 - val_loss: 2.6681 - val_accuracy: 0.1856\n",
            "Epoch 15/25\n",
            "1299/1299 [==============================] - 1s 446us/step - loss: 1.1218 - accuracy: 0.6713 - val_loss: 2.6348 - val_accuracy: 0.1682\n",
            "Epoch 16/25\n",
            "1299/1299 [==============================] - 1s 452us/step - loss: 1.0508 - accuracy: 0.6644 - val_loss: 2.6760 - val_accuracy: 0.1897\n",
            "Epoch 17/25\n",
            "1299/1299 [==============================] - 1s 466us/step - loss: 1.1041 - accuracy: 0.6651 - val_loss: 2.6235 - val_accuracy: 0.1703\n",
            "Epoch 18/25\n",
            "1299/1299 [==============================] - 1s 449us/step - loss: 1.0657 - accuracy: 0.6721 - val_loss: 2.7235 - val_accuracy: 0.1703\n",
            "Epoch 19/25\n",
            "1299/1299 [==============================] - 1s 451us/step - loss: 1.0108 - accuracy: 0.7005 - val_loss: 2.7163 - val_accuracy: 0.1897\n",
            "Epoch 20/25\n",
            "1299/1299 [==============================] - 1s 453us/step - loss: 0.9870 - accuracy: 0.7036 - val_loss: 2.6183 - val_accuracy: 0.1990\n",
            "Epoch 21/25\n",
            "1299/1299 [==============================] - 1s 451us/step - loss: 0.9773 - accuracy: 0.6998 - val_loss: 2.4695 - val_accuracy: 0.2533\n",
            "Epoch 22/25\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 0.9397 - accuracy: 0.7159 - val_loss: 2.4124 - val_accuracy: 0.1969\n",
            "Epoch 23/25\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 0.9047 - accuracy: 0.7121 - val_loss: 2.3991 - val_accuracy: 0.2021\n",
            "Epoch 24/25\n",
            "1299/1299 [==============================] - 1s 457us/step - loss: 0.9035 - accuracy: 0.7236 - val_loss: 2.2511 - val_accuracy: 0.2667\n",
            "Epoch 25/25\n",
            "1299/1299 [==============================] - 1s 454us/step - loss: 0.8718 - accuracy: 0.7344 - val_loss: 2.3385 - val_accuracy: 0.2656\n",
            "974/974 [==============================] - 0s 165us/step\n",
            "Score is 0.2689938545227051\n",
            "Time taken ------> 517.5808880329132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU62XsCXnOj4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "bb05f088-f38b-4222-8615-4a51db9335d8"
      },
      "source": [
        "best_parameters = ga.best_individual()[1]\n",
        "for index,i in enumerate(data):\n",
        "  print(i[best_parameters[index]])\n",
        "\n",
        "print(ga.best_individual()[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "22\n",
            "59\n",
            "62\n",
            "2\n",
            "3\n",
            "3\n",
            "3\n",
            "0.36344969272613525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXoVZ9ibM34E",
        "colab_type": "text"
      },
      "source": [
        "# Building CNN Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT7KyTCKM-27",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb948173-e6a1-49b2-f4ef-7107cc5c9830"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters=data[0][best_parameters[0]], kernel_size=data[4][best_parameters[4]], activation='relu', input_shape=input_shape))\n",
        "model.add(Conv1D(filters=data[0][best_parameters[0]], kernel_size=data[4][best_parameters[4]], activation='relu', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=data[1][best_parameters[1]], kernel_size=data[5][best_parameters[5]], activation='relu'))\n",
        "model.add(Conv1D(filters=data[1][best_parameters[1]], kernel_size=data[5][best_parameters[5]], activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=data[2][best_parameters[2]], kernel_size=data[5][best_parameters[5]], activation='relu'))\n",
        "model.add(Conv1D(filters=data[2][best_parameters[2]], kernel_size=data[5][best_parameters[5]], activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=data[3][best_parameters[3]], kernel_size=data[6][best_parameters[6]], activation='relu'))\n",
        "model.add(Conv1D(filters=data[3][best_parameters[3]], kernel_size=data[6][best_parameters[6]], activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(number_of_classes, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_201 (Conv1D)          (None, 108, 10)           30        \n",
            "_________________________________________________________________\n",
            "conv1d_202 (Conv1D)          (None, 107, 10)           210       \n",
            "_________________________________________________________________\n",
            "batch_normalization_176 (Bat (None, 107, 10)           40        \n",
            "_________________________________________________________________\n",
            "max_pooling1d_101 (MaxPoolin (None, 53, 10)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_203 (Conv1D)          (None, 51, 22)            682       \n",
            "_________________________________________________________________\n",
            "conv1d_204 (Conv1D)          (None, 49, 22)            1474      \n",
            "_________________________________________________________________\n",
            "batch_normalization_177 (Bat (None, 49, 22)            88        \n",
            "_________________________________________________________________\n",
            "max_pooling1d_102 (MaxPoolin (None, 24, 22)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_205 (Conv1D)          (None, 22, 59)            3953      \n",
            "_________________________________________________________________\n",
            "conv1d_206 (Conv1D)          (None, 20, 59)            10502     \n",
            "_________________________________________________________________\n",
            "batch_normalization_178 (Bat (None, 20, 59)            236       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_103 (MaxPoolin (None, 10, 59)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_207 (Conv1D)          (None, 8, 62)             11036     \n",
            "_________________________________________________________________\n",
            "conv1d_208 (Conv1D)          (None, 6, 62)             11594     \n",
            "_________________________________________________________________\n",
            "batch_normalization_179 (Bat (None, 6, 62)             248       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_104 (MaxPoolin (None, 3, 62)             0         \n",
            "_________________________________________________________________\n",
            "dropout_101 (Dropout)        (None, 3, 62)             0         \n",
            "_________________________________________________________________\n",
            "flatten_26 (Flatten)         (None, 186)               0         \n",
            "_________________________________________________________________\n",
            "dense_101 (Dense)            (None, 64)                11968     \n",
            "_________________________________________________________________\n",
            "batch_normalization_180 (Bat (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_102 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_102 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_181 (Bat (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dropout_103 (Dropout)        (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_103 (Dense)            (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "batch_normalization_182 (Bat (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "dropout_104 (Dropout)        (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_104 (Dense)            (None, 14)                238       \n",
            "=================================================================\n",
            "Total params: 55,355\n",
            "Trainable params: 54,825\n",
            "Non-trainable params: 530\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nHrv5P4EPUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = Sequential()\n",
        "# model.add(Conv1D(filters=8, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "# model.add(Conv1D(filters=8, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "# model.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n",
        "# model.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "# model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "# model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "# model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "# model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling1D(pool_size=2))\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(64, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(Dense(32, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(Dense(16, activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.25))\n",
        "# model.add(Dense(number_of_classes, activation='softmax'))\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5kxIOUabfGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in model.layers:\n",
        "#   name = i.output.name.split('/')[0].split('_')\n",
        "#   if len(name) > 2:\n",
        "#     name = name[0] + '_' + name[1]\n",
        "#   else:\n",
        "#     name = name[0]\n",
        "#   print(name, i.output.shape)\n",
        "#   print('_________________________________________________')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-VSlVynNBID",
        "colab_type": "code",
        "outputId": "0fd14c9d-ecca-4c91-a4ea-f56531fee870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import keras\n",
        "model.compile(loss=loss,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=metrics)\n",
        "\n",
        "model.fit(X_train, np.array(y_train),\n",
        "          batch_size=128,\n",
        "          epochs=100,\n",
        "          verbose=1,\n",
        "          validation_data=(xx_val, np.array(yy_val)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1299 samples, validate on 975 samples\n",
            "Epoch 1/100\n",
            "1299/1299 [==============================] - 3s 2ms/step - loss: 2.7854 - accuracy: 0.1447 - val_loss: 2.6337 - val_accuracy: 0.0738\n",
            "Epoch 2/100\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 2.3464 - accuracy: 0.2540 - val_loss: 2.6374 - val_accuracy: 0.0738\n",
            "Epoch 3/100\n",
            "1299/1299 [==============================] - 1s 453us/step - loss: 2.0114 - accuracy: 0.3510 - val_loss: 2.6495 - val_accuracy: 0.0738\n",
            "Epoch 4/100\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 1.8586 - accuracy: 0.4126 - val_loss: 2.6616 - val_accuracy: 0.0738\n",
            "Epoch 5/100\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 1.7332 - accuracy: 0.4604 - val_loss: 2.7004 - val_accuracy: 0.0738\n",
            "Epoch 6/100\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 1.6778 - accuracy: 0.4927 - val_loss: 2.7245 - val_accuracy: 0.0738\n",
            "Epoch 7/100\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 1.5500 - accuracy: 0.5350 - val_loss: 2.7524 - val_accuracy: 0.0738\n",
            "Epoch 8/100\n",
            "1299/1299 [==============================] - 1s 446us/step - loss: 1.4954 - accuracy: 0.5396 - val_loss: 2.8129 - val_accuracy: 0.0738\n",
            "Epoch 9/100\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 1.4405 - accuracy: 0.5727 - val_loss: 2.8701 - val_accuracy: 0.0738\n",
            "Epoch 10/100\n",
            "1299/1299 [==============================] - 1s 454us/step - loss: 1.3738 - accuracy: 0.5958 - val_loss: 2.9059 - val_accuracy: 0.0738\n",
            "Epoch 11/100\n",
            "1299/1299 [==============================] - 1s 487us/step - loss: 1.3564 - accuracy: 0.5912 - val_loss: 2.9469 - val_accuracy: 0.0738\n",
            "Epoch 12/100\n",
            "1299/1299 [==============================] - 1s 466us/step - loss: 1.3047 - accuracy: 0.6082 - val_loss: 3.0169 - val_accuracy: 0.0738\n",
            "Epoch 13/100\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 1.2335 - accuracy: 0.6274 - val_loss: 3.0578 - val_accuracy: 0.0738\n",
            "Epoch 14/100\n",
            "1299/1299 [==============================] - 1s 466us/step - loss: 1.2497 - accuracy: 0.6328 - val_loss: 3.0954 - val_accuracy: 0.0738\n",
            "Epoch 15/100\n",
            "1299/1299 [==============================] - 1s 460us/step - loss: 1.1805 - accuracy: 0.6397 - val_loss: 3.1021 - val_accuracy: 0.0738\n",
            "Epoch 16/100\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.1232 - accuracy: 0.6628 - val_loss: 3.1356 - val_accuracy: 0.0738\n",
            "Epoch 17/100\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 1.1319 - accuracy: 0.6505 - val_loss: 3.1934 - val_accuracy: 0.0738\n",
            "Epoch 18/100\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 1.0900 - accuracy: 0.6644 - val_loss: 3.2814 - val_accuracy: 0.0738\n",
            "Epoch 19/100\n",
            "1299/1299 [==============================] - 1s 468us/step - loss: 1.0468 - accuracy: 0.6851 - val_loss: 3.1587 - val_accuracy: 0.0738\n",
            "Epoch 20/100\n",
            "1299/1299 [==============================] - 1s 480us/step - loss: 1.0695 - accuracy: 0.6782 - val_loss: 3.0689 - val_accuracy: 0.0738\n",
            "Epoch 21/100\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 1.0293 - accuracy: 0.6859 - val_loss: 3.1731 - val_accuracy: 0.0800\n",
            "Epoch 22/100\n",
            "1299/1299 [==============================] - 1s 467us/step - loss: 0.9987 - accuracy: 0.6982 - val_loss: 2.9440 - val_accuracy: 0.0831\n",
            "Epoch 23/100\n",
            "1299/1299 [==============================] - 1s 499us/step - loss: 0.9657 - accuracy: 0.7167 - val_loss: 2.6569 - val_accuracy: 0.0862\n",
            "Epoch 24/100\n",
            "1299/1299 [==============================] - 1s 478us/step - loss: 0.9491 - accuracy: 0.7075 - val_loss: 2.6983 - val_accuracy: 0.0841\n",
            "Epoch 25/100\n",
            "1299/1299 [==============================] - 1s 469us/step - loss: 0.9117 - accuracy: 0.7313 - val_loss: 2.5233 - val_accuracy: 0.1621\n",
            "Epoch 26/100\n",
            "1299/1299 [==============================] - 1s 457us/step - loss: 0.8998 - accuracy: 0.7190 - val_loss: 2.9079 - val_accuracy: 0.1231\n",
            "Epoch 27/100\n",
            "1299/1299 [==============================] - 1s 459us/step - loss: 0.8674 - accuracy: 0.7306 - val_loss: 2.8226 - val_accuracy: 0.1005\n",
            "Epoch 28/100\n",
            "1299/1299 [==============================] - 1s 470us/step - loss: 0.8121 - accuracy: 0.7598 - val_loss: 2.5681 - val_accuracy: 0.1805\n",
            "Epoch 29/100\n",
            "1299/1299 [==============================] - 1s 470us/step - loss: 0.8265 - accuracy: 0.7521 - val_loss: 2.2847 - val_accuracy: 0.2862\n",
            "Epoch 30/100\n",
            "1299/1299 [==============================] - 1s 450us/step - loss: 0.8043 - accuracy: 0.7683 - val_loss: 2.4354 - val_accuracy: 0.2677\n",
            "Epoch 31/100\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 0.7854 - accuracy: 0.7598 - val_loss: 2.3488 - val_accuracy: 0.2041\n",
            "Epoch 32/100\n",
            "1299/1299 [==============================] - 1s 466us/step - loss: 0.8088 - accuracy: 0.7667 - val_loss: 1.9132 - val_accuracy: 0.3815\n",
            "Epoch 33/100\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 0.7615 - accuracy: 0.7590 - val_loss: 1.8756 - val_accuracy: 0.3805\n",
            "Epoch 34/100\n",
            "1299/1299 [==============================] - 1s 478us/step - loss: 0.7890 - accuracy: 0.7490 - val_loss: 1.7431 - val_accuracy: 0.4646\n",
            "Epoch 35/100\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 0.7223 - accuracy: 0.7829 - val_loss: 1.4973 - val_accuracy: 0.4872\n",
            "Epoch 36/100\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 0.7083 - accuracy: 0.7721 - val_loss: 1.3155 - val_accuracy: 0.5867\n",
            "Epoch 37/100\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 0.6790 - accuracy: 0.7906 - val_loss: 1.7594 - val_accuracy: 0.5159\n",
            "Epoch 38/100\n",
            "1299/1299 [==============================] - 1s 460us/step - loss: 0.6670 - accuracy: 0.8199 - val_loss: 1.3613 - val_accuracy: 0.5682\n",
            "Epoch 39/100\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 0.6682 - accuracy: 0.7937 - val_loss: 0.9821 - val_accuracy: 0.6892\n",
            "Epoch 40/100\n",
            "1299/1299 [==============================] - 1s 453us/step - loss: 0.6029 - accuracy: 0.8129 - val_loss: 1.0669 - val_accuracy: 0.6667\n",
            "Epoch 41/100\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 0.5813 - accuracy: 0.8268 - val_loss: 0.9014 - val_accuracy: 0.6903\n",
            "Epoch 42/100\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 0.6310 - accuracy: 0.8145 - val_loss: 0.7879 - val_accuracy: 0.7262\n",
            "Epoch 43/100\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 0.6338 - accuracy: 0.8145 - val_loss: 0.9340 - val_accuracy: 0.7159\n",
            "Epoch 44/100\n",
            "1299/1299 [==============================] - 1s 457us/step - loss: 0.6017 - accuracy: 0.8253 - val_loss: 0.7986 - val_accuracy: 0.7703\n",
            "Epoch 45/100\n",
            "1299/1299 [==============================] - 1s 451us/step - loss: 0.5642 - accuracy: 0.8360 - val_loss: 0.7585 - val_accuracy: 0.7774\n",
            "Epoch 46/100\n",
            "1299/1299 [==============================] - 1s 491us/step - loss: 0.5129 - accuracy: 0.8553 - val_loss: 0.8126 - val_accuracy: 0.7221\n",
            "Epoch 47/100\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 0.5415 - accuracy: 0.8422 - val_loss: 0.8550 - val_accuracy: 0.7200\n",
            "Epoch 48/100\n",
            "1299/1299 [==============================] - 1s 452us/step - loss: 0.5381 - accuracy: 0.8507 - val_loss: 0.7350 - val_accuracy: 0.7600\n",
            "Epoch 49/100\n",
            "1299/1299 [==============================] - 1s 467us/step - loss: 0.5110 - accuracy: 0.8383 - val_loss: 0.6128 - val_accuracy: 0.8051\n",
            "Epoch 50/100\n",
            "1299/1299 [==============================] - 1s 448us/step - loss: 0.5131 - accuracy: 0.8468 - val_loss: 0.6518 - val_accuracy: 0.7774\n",
            "Epoch 51/100\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 0.5008 - accuracy: 0.8437 - val_loss: 0.6471 - val_accuracy: 0.7754\n",
            "Epoch 52/100\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 0.5025 - accuracy: 0.8437 - val_loss: 0.6049 - val_accuracy: 0.8072\n",
            "Epoch 53/100\n",
            "1299/1299 [==============================] - 1s 458us/step - loss: 0.4743 - accuracy: 0.8599 - val_loss: 0.6075 - val_accuracy: 0.7897\n",
            "Epoch 54/100\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 0.5100 - accuracy: 0.8468 - val_loss: 0.9969 - val_accuracy: 0.6697\n",
            "Epoch 55/100\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 0.5055 - accuracy: 0.8545 - val_loss: 0.5765 - val_accuracy: 0.8144\n",
            "Epoch 56/100\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 0.4504 - accuracy: 0.8591 - val_loss: 0.7596 - val_accuracy: 0.7651\n",
            "Epoch 57/100\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 0.5339 - accuracy: 0.8399 - val_loss: 0.5637 - val_accuracy: 0.8164\n",
            "Epoch 58/100\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 0.4296 - accuracy: 0.8737 - val_loss: 0.5662 - val_accuracy: 0.8103\n",
            "Epoch 59/100\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 0.4592 - accuracy: 0.8637 - val_loss: 0.5012 - val_accuracy: 0.8369\n",
            "Epoch 60/100\n",
            "1299/1299 [==============================] - 1s 454us/step - loss: 0.4266 - accuracy: 0.8730 - val_loss: 0.6277 - val_accuracy: 0.7918\n",
            "Epoch 61/100\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 0.3993 - accuracy: 0.8799 - val_loss: 0.5028 - val_accuracy: 0.8349\n",
            "Epoch 62/100\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 0.3706 - accuracy: 0.8945 - val_loss: 0.7647 - val_accuracy: 0.7497\n",
            "Epoch 63/100\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 0.3861 - accuracy: 0.8915 - val_loss: 0.6320 - val_accuracy: 0.8185\n",
            "Epoch 64/100\n",
            "1299/1299 [==============================] - 1s 480us/step - loss: 0.4302 - accuracy: 0.8737 - val_loss: 0.3848 - val_accuracy: 0.8728\n",
            "Epoch 65/100\n",
            "1299/1299 [==============================] - 1s 454us/step - loss: 0.3932 - accuracy: 0.8915 - val_loss: 0.4316 - val_accuracy: 0.8585\n",
            "Epoch 66/100\n",
            "1299/1299 [==============================] - 1s 459us/step - loss: 0.3630 - accuracy: 0.8915 - val_loss: 0.5842 - val_accuracy: 0.8174\n",
            "Epoch 67/100\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 0.4151 - accuracy: 0.8699 - val_loss: 0.5171 - val_accuracy: 0.8277\n",
            "Epoch 68/100\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 0.3514 - accuracy: 0.8984 - val_loss: 0.8870 - val_accuracy: 0.7333\n",
            "Epoch 69/100\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 0.3459 - accuracy: 0.9045 - val_loss: 0.4330 - val_accuracy: 0.8564\n",
            "Epoch 70/100\n",
            "1299/1299 [==============================] - 1s 450us/step - loss: 0.3164 - accuracy: 0.9053 - val_loss: 0.3882 - val_accuracy: 0.8759\n",
            "Epoch 71/100\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 0.2971 - accuracy: 0.9246 - val_loss: 0.4147 - val_accuracy: 0.8605\n",
            "Epoch 72/100\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 0.3414 - accuracy: 0.9022 - val_loss: 0.4282 - val_accuracy: 0.8595\n",
            "Epoch 73/100\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 0.3497 - accuracy: 0.8984 - val_loss: 0.4647 - val_accuracy: 0.8421\n",
            "Epoch 74/100\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 0.3348 - accuracy: 0.9007 - val_loss: 0.3939 - val_accuracy: 0.8697\n",
            "Epoch 75/100\n",
            "1299/1299 [==============================] - 1s 457us/step - loss: 0.3328 - accuracy: 0.9045 - val_loss: 0.3905 - val_accuracy: 0.8749\n",
            "Epoch 76/100\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 0.2889 - accuracy: 0.9207 - val_loss: 0.3703 - val_accuracy: 0.8790\n",
            "Epoch 77/100\n",
            "1299/1299 [==============================] - 1s 470us/step - loss: 0.2834 - accuracy: 0.9230 - val_loss: 0.3660 - val_accuracy: 0.8790\n",
            "Epoch 78/100\n",
            "1299/1299 [==============================] - 1s 457us/step - loss: 0.2817 - accuracy: 0.9292 - val_loss: 0.4041 - val_accuracy: 0.8728\n",
            "Epoch 79/100\n",
            "1299/1299 [==============================] - 1s 451us/step - loss: 0.2390 - accuracy: 0.9430 - val_loss: 0.4316 - val_accuracy: 0.8595\n",
            "Epoch 80/100\n",
            "1299/1299 [==============================] - 1s 460us/step - loss: 0.2578 - accuracy: 0.9330 - val_loss: 0.4365 - val_accuracy: 0.8708\n",
            "Epoch 81/100\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 0.2651 - accuracy: 0.9284 - val_loss: 0.3715 - val_accuracy: 0.8769\n",
            "Epoch 82/100\n",
            "1299/1299 [==============================] - 1s 477us/step - loss: 0.2507 - accuracy: 0.9376 - val_loss: 0.4106 - val_accuracy: 0.8718\n",
            "Epoch 83/100\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 0.2806 - accuracy: 0.9184 - val_loss: 0.4649 - val_accuracy: 0.8472\n",
            "Epoch 84/100\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 0.2328 - accuracy: 0.9446 - val_loss: 0.5048 - val_accuracy: 0.8318\n",
            "Epoch 85/100\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 0.2549 - accuracy: 0.9284 - val_loss: 0.4382 - val_accuracy: 0.8513\n",
            "Epoch 86/100\n",
            "1299/1299 [==============================] - 1s 461us/step - loss: 0.2562 - accuracy: 0.9276 - val_loss: 0.3948 - val_accuracy: 0.8687\n",
            "Epoch 87/100\n",
            "1299/1299 [==============================] - 1s 455us/step - loss: 0.2417 - accuracy: 0.9330 - val_loss: 0.7089 - val_accuracy: 0.7908\n",
            "Epoch 88/100\n",
            "1299/1299 [==============================] - 1s 459us/step - loss: 0.2297 - accuracy: 0.9392 - val_loss: 0.5434 - val_accuracy: 0.8390\n",
            "Epoch 89/100\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 0.2463 - accuracy: 0.9407 - val_loss: 0.4507 - val_accuracy: 0.8626\n",
            "Epoch 90/100\n",
            "1299/1299 [==============================] - 1s 465us/step - loss: 0.2231 - accuracy: 0.9384 - val_loss: 0.4025 - val_accuracy: 0.8851\n",
            "Epoch 91/100\n",
            "1299/1299 [==============================] - 1s 462us/step - loss: 0.2159 - accuracy: 0.9492 - val_loss: 0.3801 - val_accuracy: 0.8851\n",
            "Epoch 92/100\n",
            "1299/1299 [==============================] - 1s 470us/step - loss: 0.2169 - accuracy: 0.9461 - val_loss: 0.5802 - val_accuracy: 0.8410\n",
            "Epoch 93/100\n",
            "1299/1299 [==============================] - 1s 464us/step - loss: 0.2606 - accuracy: 0.9207 - val_loss: 0.5835 - val_accuracy: 0.8328\n",
            "Epoch 94/100\n",
            "1299/1299 [==============================] - 1s 456us/step - loss: 0.2124 - accuracy: 0.9423 - val_loss: 0.5506 - val_accuracy: 0.8287\n",
            "Epoch 95/100\n",
            "1299/1299 [==============================] - 1s 469us/step - loss: 0.2482 - accuracy: 0.9369 - val_loss: 0.7289 - val_accuracy: 0.7815\n",
            "Epoch 96/100\n",
            "1299/1299 [==============================] - 1s 459us/step - loss: 0.2553 - accuracy: 0.9261 - val_loss: 0.6422 - val_accuracy: 0.8021\n",
            "Epoch 97/100\n",
            "1299/1299 [==============================] - 1s 457us/step - loss: 0.2466 - accuracy: 0.9299 - val_loss: 0.6324 - val_accuracy: 0.8287\n",
            "Epoch 98/100\n",
            "1299/1299 [==============================] - 1s 463us/step - loss: 0.2486 - accuracy: 0.9292 - val_loss: 0.9253 - val_accuracy: 0.7313\n",
            "Epoch 99/100\n",
            "1299/1299 [==============================] - 1s 474us/step - loss: 0.2423 - accuracy: 0.9299 - val_loss: 0.7814 - val_accuracy: 0.7682\n",
            "Epoch 100/100\n",
            "1299/1299 [==============================] - 1s 460us/step - loss: 0.2506 - accuracy: 0.9276 - val_loss: 0.4207 - val_accuracy: 0.8821\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fcf393f1c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSGrC7sxNWhx",
        "colab_type": "code",
        "outputId": "2f136e77-e4b4-490c-862a-cadc2e9d8283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "score = model.evaluate(xx_test, yy_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "974/974 [==============================] - 0s 158us/step\n",
            "Test loss: 0.33087883360332043\n",
            "Test accuracy: 0.9014373421669006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbIwG9dgjk-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if len(np.array(y_test).shape) == 1:\n",
        "  y_test = [x+1 for x in y_test]\n",
        "  y_train = [x+1 for x in y_train]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9zjzu4ArF-O",
        "colab_type": "code",
        "outputId": "d698234c-05e4-40d6-8b34-a660f9069ca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install spectral"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spectral in /usr/local/lib/python3.6/dist-packages (0.21)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from spectral) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf5wCQc3q7ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spectral as sp\n",
        "prediction = model.predict(X)\n",
        "\n",
        "if not len(prediction.shape) == 2:\n",
        "    y_test = [x + 1 for x in y_test]\n",
        "    y_train = [x + 1 for x in y_train]\n",
        "\n",
        "if len(prediction.shape) == 2:\n",
        "    predicted_gt_1 = np.argmax(prediction, axis=1)\n",
        "    predicted_gt_1_list = list(predicted_gt_1)\n",
        "    predicted_gt_1_list = [x + 1 for x in predicted_gt_1_list]\n",
        "else:\n",
        "    predicted_gt_1_list = prediction\n",
        "\n",
        "for i in zero_data:\n",
        "    predicted_gt_1_list.insert(i, 0)\n",
        "\n",
        "predicted_gt_1_list = np.array(predicted_gt_1_list).reshape(image.shape[0], image.shape[1])\n",
        "sp.save_rgb('predicted_gt.jpg', predicted_gt_1_list, colors=sp.spy_colors)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}